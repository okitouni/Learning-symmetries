{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T03:08:09.388080Z",
     "start_time": "2020-11-25T03:08:08.129634Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from itertools import permutations\n",
    "cmap = plt.cm.RdBu\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "#plt.style.use(\"dark_paper\")\n",
    "import sys\n",
    "#sys.path.append(['/home/nwkamp/Classes/Learning-symmetries/'])\n",
    "from sym.models.perm_models import PIN1,PIN2,PIN3,SNN1,SNN2,SNN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    ret = np.zeros(len(x))\n",
    "    for i,dat in enumerate(x):\n",
    "        #ret[i] = 2*(len(dat[dat>0.5]) % 2) - 1\n",
    "        #ret[i] = 2*(np.prod(dat) >= 0.5**(len(dat))) - 1\n",
    "        ret[i] = np.sum(dat) + (np.prod(dat)/(0.5**len(dat)))\n",
    "    return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T03:08:09.461304Z",
     "start_time": "2020-11-25T03:08:09.390192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_list = [3,4,5]\n",
    "M = int(10000)\n",
    "BS = 1000\n",
    "np.random.seed(7)\n",
    "xtrain_dict = {}\n",
    "ytrain_dict = {}\n",
    "xval_dict = {}\n",
    "yval_dict = {}\n",
    "trainloader_dict = {}\n",
    "valloader_dict = {}\n",
    "for N in N_list:\n",
    "\n",
    "    xtrain = np.random.rand(M,N)\n",
    "    xval = np.random.rand(M,N)\n",
    "\n",
    "    ytrain = f(xtrain)\n",
    "    yval = f(xval)\n",
    "\n",
    "    xtrain_dict[N] = torch.from_numpy(xtrain).float()\n",
    "    ytrain_dict[N] = torch.from_numpy(ytrain).float().view(-1,1)\n",
    "    xval_dict[N] = torch.from_numpy(xval).float()\n",
    "    yval_dict[N] = torch.from_numpy(yval).float().view(-1,1)\n",
    "\n",
    "    trainset = torch.utils.data.TensorDataset(xtrain_dict[N],ytrain_dict[N])\n",
    "    trainloader_dict[N] = torch.utils.data.DataLoader(trainset,\n",
    "                                                      batch_size=BS,\n",
    "                                                      shuffle=True)\n",
    "\n",
    "    valset = torch.utils.data.TensorDataset(xval_dict[N],yval_dict[N])\n",
    "    valloader_dict[N] = torch.utils.data.DataLoader(valset,batch_size=BS)\n",
    "\n",
    "\n",
    "    plt.hist(yval_dict[N].detach().numpy(),range=(0,10),bins=50)\n",
    "    plt.title(N)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T03:08:11.735627Z",
     "start_time": "2020-11-25T03:08:11.731840Z"
    }
   },
   "outputs": [],
   "source": [
    "decayRate = 0.99\n",
    "lr = 1e-2\n",
    "criterion = torch.nn.MSELoss(reduction=\"mean\")\n",
    "mlp = {}\n",
    "pin = {}\n",
    "optimizer_mlp = {}\n",
    "optimizer_pin = {}\n",
    "lrdecay_mlp = {}\n",
    "lrdecay_pin = {}\n",
    "for N in N_list:\n",
    "    mlp[N] = {'1':SNN1(N),'2':SNN2(N),'3':SNN3(N)}\n",
    "    pin[N] = {'1':PIN1(N),'2':PIN2(N),'3':PIN3(N)}\n",
    "    optimizer_mlp[N] = {}\n",
    "    optimizer_pin[N] = {}\n",
    "    lrdecay_mlp[N] = {}\n",
    "    lrdecay_pin[N] = {}\n",
    "    for i in ['1','2','3']:\n",
    "        optimizer_mlp[N][i] = torch.optim.SGD(mlp[N][i].parameters(),lr=lr)\n",
    "        lrdecay_mlp[N][i] = torch.optim.lr_scheduler.ExponentialLR(optimizer_mlp[N][i],gamma=decayRate)\n",
    "        optimizer_pin[N][i] = torch.optim.SGD(pin[N][i].parameters(),lr=lr)\n",
    "        lrdecay_pin[N][i] = torch.optim.lr_scheduler.ExponentialLR(optimizer_pin[N][i],gamma=decayRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T03:08:11.745849Z",
     "start_time": "2020-11-25T03:08:11.736743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0043,  0.3097, -0.4752],\n",
      "        [-0.4249, -0.2224,  0.1548],\n",
      "        [-0.0114,  0.4578, -0.0512]], requires_grad=True)\n",
      "tensor(0.0075)\n",
      "tensor([[ 0.3217, -0.1406,  0.1662],\n",
      "        [-0.1406,  0.2540, -0.1049],\n",
      "        [ 0.1662, -0.1049,  0.2123]])\n",
      "torch.return_types.eig(\n",
      "eigenvalues=tensor([[0.5470, 0.0000],\n",
      "        [0.0920, 0.0000],\n",
      "        [0.1491, 0.0000]]),\n",
      "eigenvectors=tensor([[-0.6935,  0.5719,  0.4383],\n",
      "        [ 0.5136, -0.0342,  0.8573],\n",
      "        [-0.5053, -0.8196,  0.2700]]))\n",
      "tensor([[ 5.7229,  1.6568, -3.6610],\n",
      "        [ 1.6568,  5.4263,  1.3834],\n",
      "        [-3.6610,  1.3834,  8.2587]])\n",
      "tensor([[ 1.0000e+00,  7.3443e-09, -1.0207e-07],\n",
      "        [-4.4864e-08,  1.0000e+00, -8.1595e-09],\n",
      "        [-1.2474e-07, -3.8688e-08,  1.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# Define training and validation functions\n",
    "def train(model,optimizer,x,y):\n",
    "    model.train()\n",
    "    yhat = model(x)\n",
    "    loss = criterion(yhat,y.view(-1,1))\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss.item()\n",
    "def validate(model,x,y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        yhat = model(x)\n",
    "        loss = criterion(yhat,y.view(-1,1))\n",
    "        return loss.item()\n",
    "# Define early stopping function\n",
    "def earlyStop(loss_vec,N,eps=1e-6):\n",
    "    for i in range(N):\n",
    "        if loss_vec[-i-2] > loss_vec[-i-1]*(1+eps): return False\n",
    "    return True\n",
    "\n",
    "def projBv(B,v):\n",
    "    return torch.matmul(torch.outer(v,v),B)/torch.matmul(v,v)\n",
    "\n",
    "def Misalignment(A,B):\n",
    "    d = A.size(0)\n",
    "    evalA,evecA = torch.eig(A,True)\n",
    "    M = 0\n",
    "    for evec in evecA:\n",
    "        tr1 = projBv(B,evec)\n",
    "        tr2 = projBv(torch.inverse(B),evec)\n",
    "        M += torch.sqrt(torch.trace(tr1)*torch.trace(tr2))\n",
    "    return M-d\n",
    "\n",
    "def Misalignment2(A,B):\n",
    "    evalA,evecA = torch.eig(A,True)\n",
    "    M = 0\n",
    "    for evec in evecA:\n",
    "        a = torch.dot(evec,torch.matmul(B,evec))\n",
    "        b = torch.dot(evec,torch.matmul(torch.inverse(B),evec))\n",
    "        M += torch.sqrt(a*b)\n",
    "    return M\n",
    "\n",
    "def Mmod(mlp_model,pin_model):\n",
    "    modules_mlp = list(mlp_model.modules())\n",
    "    modules_pin = list(pin_model.modules())\n",
    "    mlpW = modules_mlp[0].mlp[0].weight\n",
    "    phi = modules_pin[0].phi[0].weight\n",
    "    phiW = torch.ones(phi.size(0),phi.size(0)-1)\n",
    "    for i in range(phiW.size(0)):\n",
    "        phiW[i]*=phi[i]\n",
    "    B = torch.matmul(mlpW,mlpW.transpose(0,1))\n",
    "    A = torch.matmul(phiW,phiW.transpose(0,1))\n",
    "    return Misalignment2(A,B),torch.det(B),torch.det(A)\n",
    "\n",
    "def Frob(mlp_model,pin_model):\n",
    "    modules_mlp = list(mlp_model.modules())\n",
    "    modules_pin = list(pin_model.modules())\n",
    "    mlpW = modules_mlp[0].mlp[0].weight\n",
    "    phi = modules_pin[0].phi[0].weight\n",
    "    phiW = torch.ones(phi.size(0),phi.size(0)-1)\n",
    "    for i in range(phiW.size(0)):\n",
    "        phiW[i]*=phi[i]\n",
    "    return torch.trace(torch.matmul(mlpW.T,phiW))\n",
    "    \n",
    "\n",
    "with torch.no_grad():\n",
    "    modules_mlp = list(mlp[3]['1'].modules())\n",
    "    modules_pin = list(pin[3]['1'].modules())\n",
    "    mlpW = modules_mlp[0].mlp[0].weight.to('cpu')\n",
    "    phi = modules_pin[0].phi[0].weight.to('cpu')\n",
    "    phiW = torch.ones(phi.size(0),phi.size(0)-1)\n",
    "    for i in range(phiW.size(0)):\n",
    "        phiW[i]*=phi[i]\n",
    "    \n",
    "    A = torch.matmul(mlpW,mlpW.transpose(0,1))\n",
    "    B = torch.matmul(phiW,phiW.T)\n",
    "    Ainv = torch.inverse(A)\n",
    "    Binv = torch.inverse(B)\n",
    "    print(mlpW)\n",
    "    print(torch.det(A))\n",
    "    print(A)\n",
    "    print(torch.eig(A,True))\n",
    "    print(Ainv)\n",
    "    print(torch.matmul(Ainv,A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelkeys = ['1']\n",
    "Nkeys = [3,4,5]\n",
    "losses_train_mlp = {N:{i:[] for i in modelkeys} for N in Nkeys}\n",
    "losses_val_mlp = {N:{i:[] for i in modelkeys} for N in Nkeys}\n",
    "losses_train_pin = {N:{i:[] for i in modelkeys} for N in Nkeys}\n",
    "losses_val_pin = {N:{i:[] for i in modelkeys} for N in Nkeys}\n",
    "\n",
    "M_dict = {N:[] for N in Nkeys}\n",
    "det_dict = {N:[] for N in Nkeys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T03:08:12.341247Z",
     "start_time": "2020-11-25T03:08:11.747023Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 001/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 7.812489/7.307229\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 11.269973/11.146202\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 12.344950/6.923105\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.4132009\n",
      "det: 0.0071422337\n",
      "Validation loss mlp/pin: 6.832834/6.452428\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.3866453\n",
      "det: 0.0079746675\n",
      "Validation loss mlp/pin: 8.411135/9.786027\n",
      "###### N,i = 5,1 #####\n",
      "M: 42.0891\n",
      "det: 1.3075769e-06\n",
      "Validation loss mlp/pin: 6.611179/3.913944\n",
      "\n",
      "Epoch 002/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 5.973900/5.684478\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 5.998887/8.589049\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 4.840718/3.805233\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.4983578\n",
      "det: 0.0066035963\n",
      "Validation loss mlp/pin: 5.430192/5.211050\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.1211886\n",
      "det: 0.012237927\n",
      "Validation loss mlp/pin: 3.986638/7.877071\n",
      "###### N,i = 5,1 #####\n",
      "M: 121.04348\n",
      "det: 2.811436e-06\n",
      "Validation loss mlp/pin: 3.723491/3.525413\n",
      "\n",
      "Epoch 003/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 4.841266/4.667422\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 3.010346/7.015531\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 3.709455/3.415557\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5286953\n",
      "det: 0.006391673\n",
      "Validation loss mlp/pin: 4.519445/4.381575\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.2657757\n",
      "det: 0.01534711\n",
      "Validation loss mlp/pin: 2.564369/6.603406\n",
      "###### N,i = 5,1 #####\n",
      "M: 89.10103\n",
      "det: 9.834333e-06\n",
      "Validation loss mlp/pin: 3.578359/3.144180\n",
      "\n",
      "Epoch 004/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 4.100585/3.990548\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 2.355261/5.967641\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 3.601065/3.040164\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.544318\n",
      "det: 0.0062895482\n",
      "Validation loss mlp/pin: 3.914048/3.825372\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.4567637\n",
      "det: 0.016621575\n",
      "Validation loss mlp/pin: 2.367630/5.749493\n",
      "###### N,i = 5,1 #####\n",
      "M: 55.18802\n",
      "det: 1.883561e-05\n",
      "Validation loss mlp/pin: 3.494219/2.771313\n",
      "\n",
      "Epoch 005/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 3.608070/3.537833\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 2.247854/5.266848\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 3.517229/2.690540\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5552063\n",
      "det: 0.006225015\n",
      "Validation loss mlp/pin: 3.506195/3.449266\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.725154\n",
      "det: 0.017189557\n",
      "Validation loss mlp/pin: 2.293743/5.174736\n",
      "###### N,i = 5,1 #####\n",
      "M: 44.941822\n",
      "det: 2.9884448e-05\n",
      "Validation loss mlp/pin: 3.409683/2.430335\n",
      "\n",
      "Epoch 006/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 3.277913/3.233642\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 2.181979/4.796504\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 3.432945/2.356425\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5650167\n",
      "det: 0.0061719315\n",
      "Validation loss mlp/pin: 3.229947/3.194149\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.7418766\n",
      "det: 0.017594263\n",
      "Validation loss mlp/pin: 2.226861/4.785164\n",
      "###### N,i = 5,1 #####\n",
      "M: 21.679876\n",
      "det: 4.2848205e-05\n",
      "Validation loss mlp/pin: 3.326103/2.151267\n",
      "\n",
      "Epoch 007/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 3.055747/3.028911\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 2.117784/4.479638\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 3.348556/2.087104\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.575647\n",
      "det: 0.0061179977\n",
      "Validation loss mlp/pin: 3.041692/3.020375\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.670348\n",
      "det: 0.01790788\n",
      "Validation loss mlp/pin: 2.161414/4.520494\n",
      "###### N,i = 5,1 #####\n",
      "M: 27.573444\n",
      "det: 5.7107365e-05\n",
      "Validation loss mlp/pin: 3.244965/1.922949\n",
      "\n",
      "Epoch 008/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.905051/2.890320\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 2.053605/4.265263\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 3.266599/1.888449\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5869508\n",
      "det: 0.0060633267\n",
      "Validation loss mlp/pin: 2.911852/2.900828\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.669274\n",
      "det: 0.018177181\n",
      "Validation loss mlp/pin: 2.097017/4.338824\n",
      "###### N,i = 5,1 #####\n",
      "M: 28.710205\n",
      "det: 7.110964e-05\n",
      "Validation loss mlp/pin: 3.161620/1.755174\n",
      "\n",
      "Epoch 009/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.802109/2.796138\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.991050/4.117655\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 3.186563/1.751940\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5994744\n",
      "det: 0.006003877\n",
      "Validation loss mlp/pin: 2.821836/2.818476\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.327386\n",
      "det: 0.018506745\n",
      "Validation loss mlp/pin: 2.031775/4.210678\n",
      "###### N,i = 5,1 #####\n",
      "M: 33.116627\n",
      "det: 8.5491876e-05\n",
      "Validation loss mlp/pin: 3.082115/1.651759\n",
      "\n",
      "Epoch 010/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.731139/2.731952\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.928264/4.013553\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 3.107867/1.687362\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6136165\n",
      "det: 0.005936566\n",
      "Validation loss mlp/pin: 2.758261/2.761073\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.433546\n",
      "det: 0.018803472\n",
      "Validation loss mlp/pin: 1.967731/4.119072\n",
      "###### N,i = 5,1 #####\n",
      "M: 27.35468\n",
      "det: 9.9227684e-05\n",
      "Validation loss mlp/pin: 3.003780/1.668973\n",
      "\n",
      "Epoch 011/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.681423/2.687932\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.866424/3.940306\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 3.030793/1.848905\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6287491\n",
      "det: 0.005865388\n",
      "Validation loss mlp/pin: 2.712859/2.721038\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.567547\n",
      "det: 0.019039225\n",
      "Validation loss mlp/pin: 1.905202/4.054327\n",
      "###### N,i = 5,1 #####\n",
      "M: 36.007442\n",
      "det: 0.000111701374\n",
      "Validation loss mlp/pin: 2.928330/1.678233\n",
      "\n",
      "Epoch 012/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.645957/2.657713\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.806221/3.888623\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.955521/1.856959\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6456692\n",
      "det: 0.0057842047\n",
      "Validation loss mlp/pin: 2.679577/2.692834\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.3939953\n",
      "det: 0.019285845\n",
      "Validation loss mlp/pin: 1.843393/4.007226\n",
      "###### N,i = 5,1 #####\n",
      "M: 29.06882\n",
      "det: 0.00012233517\n",
      "Validation loss mlp/pin: 2.855344/1.860778\n",
      "\n",
      "Epoch 013/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.619865/2.636893\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.746168/3.850856\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.882914/2.111482\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.662798\n",
      "det: 0.0057026544\n",
      "Validation loss mlp/pin: 2.654526/2.672869\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.335952\n",
      "det: 0.019471046\n",
      "Validation loss mlp/pin: 1.783626/3.971816\n",
      "###### N,i = 5,1 #####\n",
      "M: 27.189932\n",
      "det: 0.00013159036\n",
      "Validation loss mlp/pin: 2.783450/1.969034\n",
      "\n",
      "Epoch 014/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.600037/2.622534\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.688132/3.822124\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.811131/1.651201\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.679396\n",
      "det: 0.005624572\n",
      "Validation loss mlp/pin: 2.634994/2.658626\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.175194\n",
      "det: 0.019719714\n",
      "Validation loss mlp/pin: 1.724009/3.943845\n",
      "###### N,i = 5,1 #####\n",
      "M: 23.267313\n",
      "det: 0.00013899305\n",
      "Validation loss mlp/pin: 2.712997/1.525420\n",
      "\n",
      "Epoch 015/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.584475/2.612677\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.631752/3.799063\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.742376/1.571622\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6947274\n",
      "det: 0.005554596\n",
      "Validation loss mlp/pin: 2.619406/2.648499\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.973091\n",
      "det: 0.019918725\n",
      "Validation loss mlp/pin: 1.666593/3.920590\n",
      "###### N,i = 5,1 #####\n",
      "M: 41.317913\n",
      "det: 0.0001450882\n",
      "Validation loss mlp/pin: 2.645555/1.679635\n",
      "\n",
      "Epoch 016/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.571590/2.605686\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.576653/3.779192\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.674325/1.607368\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7059326\n",
      "det: 0.0055099525\n",
      "Validation loss mlp/pin: 2.606261/2.640953\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.587983\n",
      "det: 0.02012149\n",
      "Validation loss mlp/pin: 1.610784/3.899896\n",
      "###### N,i = 5,1 #####\n",
      "M: 31.407133\n",
      "det: 0.00014964238\n",
      "Validation loss mlp/pin: 2.579054/1.536273\n",
      "\n",
      "Epoch 017/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.560668/2.600772\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.523743/3.760668\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.608503/1.571397\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7146602\n",
      "det: 0.0054785754\n",
      "Validation loss mlp/pin: 2.595132/2.635518\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.333925\n",
      "det: 0.020276144\n",
      "Validation loss mlp/pin: 1.557261/3.880109\n",
      "###### N,i = 5,1 #####\n",
      "M: 46.683178\n",
      "det: 0.0001528178\n",
      "Validation loss mlp/pin: 2.514514/1.515682\n",
      "\n",
      "Epoch 018/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.551123/2.597400\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.472826/3.742217\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.544703/1.556697\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7190073\n",
      "det: 0.0054731625\n",
      "Validation loss mlp/pin: 2.585434/2.631523\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.691921\n",
      "det: 0.0204303\n",
      "Validation loss mlp/pin: 1.505679/3.860200\n",
      "###### N,i = 5,1 #####\n",
      "M: 36.26906\n",
      "det: 0.0001550946\n",
      "Validation loss mlp/pin: 2.451514/1.574006\n",
      "\n",
      "Epoch 019/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.542721/2.594993\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.423707/3.722712\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.482998/1.664821\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7168822\n",
      "det: 0.0055107516\n",
      "Validation loss mlp/pin: 2.576880/2.628513\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.399405\n",
      "det: 0.020568939\n",
      "Validation loss mlp/pin: 1.456306/3.838877\n",
      "###### N,i = 5,1 #####\n",
      "M: 49.36747\n",
      "det: 0.00015621631\n",
      "Validation loss mlp/pin: 2.390549/1.714020\n",
      "\n",
      "Epoch 020/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.535274/2.593291\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.376889/3.701330\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.423915/1.680493\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7090292\n",
      "det: 0.005589068\n",
      "Validation loss mlp/pin: 2.569210/2.626268\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.1954956\n",
      "det: 0.020747675\n",
      "Validation loss mlp/pin: 1.408600/3.815431\n",
      "###### N,i = 5,1 #####\n",
      "M: 37.96137\n",
      "det: 0.00015665921\n",
      "Validation loss mlp/pin: 2.331716/1.510393\n",
      "\n",
      "Epoch 021/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.528383/2.592099\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.332357/3.677339\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.364215/1.556999\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6971462\n",
      "det: 0.005696938\n",
      "Validation loss mlp/pin: 2.561953/2.624560\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.964395\n",
      "det: 0.020853462\n",
      "Validation loss mlp/pin: 1.363796/3.789447\n",
      "###### N,i = 5,1 #####\n",
      "M: 34.024403\n",
      "det: 0.00015604851\n",
      "Validation loss mlp/pin: 2.275334/1.510337\n",
      "\n",
      "Epoch 022/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.521720/2.591210\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.290670/3.650422\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.307970/1.550357\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6805477\n",
      "det: 0.005844109\n",
      "Validation loss mlp/pin: 2.554998/2.623240\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.951918\n",
      "det: 0.020939132\n",
      "Validation loss mlp/pin: 1.321556/3.760236\n",
      "###### N,i = 5,1 #####\n",
      "M: 29.164421\n",
      "det: 0.00015445573\n",
      "Validation loss mlp/pin: 2.220856/1.515130\n",
      "\n",
      "Epoch 023/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.515293/2.590609\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.250340/3.619638\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.254363/1.544474\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6611767\n",
      "det: 0.0060198084\n",
      "Validation loss mlp/pin: 2.548159/2.622207\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.7707415\n",
      "det: 0.021077702\n",
      "Validation loss mlp/pin: 1.280828/3.727304\n",
      "###### N,i = 5,1 #####\n",
      "M: 31.41406\n",
      "det: 0.00015201271\n",
      "Validation loss mlp/pin: 2.169219/1.527107\n",
      "\n",
      "Epoch 024/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.508849/2.590163\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.212604/3.585139\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.203251/1.551490\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6406267\n",
      "det: 0.006215503\n",
      "Validation loss mlp/pin: 2.541391/2.621411\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.506223\n",
      "det: 0.021192422\n",
      "Validation loss mlp/pin: 1.242618/3.690610\n",
      "###### N,i = 5,1 #####\n",
      "M: 33.685406\n",
      "det: 0.00014882738\n",
      "Validation loss mlp/pin: 2.118865/1.503142\n",
      "\n",
      "Epoch 025/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.502344/2.589853\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.177284/3.546840\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.153897/1.561349\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.619478\n",
      "det: 0.0064247595\n",
      "Validation loss mlp/pin: 2.534557/2.620797\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.758989\n",
      "det: 0.021266295\n",
      "Validation loss mlp/pin: 1.207060/3.650003\n",
      "###### N,i = 5,1 #####\n",
      "M: 28.908518\n",
      "det: 0.00014568602\n",
      "Validation loss mlp/pin: 2.071374/1.510127\n",
      "\n",
      "Epoch 026/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.495658/2.589636\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.144031/3.504402\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.106384/1.544413\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5967226\n",
      "det: 0.0066639027\n",
      "Validation loss mlp/pin: 2.527560/2.620311\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.344336\n",
      "det: 0.021378906\n",
      "Validation loss mlp/pin: 1.173155/3.605494\n",
      "###### N,i = 5,1 #####\n",
      "M: 37.917587\n",
      "det: 0.00014214657\n",
      "Validation loss mlp/pin: 2.026380/1.530013\n",
      "\n",
      "Epoch 027/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.488768/2.589482\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.112775/3.458263\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.062393/1.562102\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5741668\n",
      "det: 0.0069139297\n",
      "Validation loss mlp/pin: 2.520350/2.619903\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.667825\n",
      "det: 0.021486029\n",
      "Validation loss mlp/pin: 1.141438/3.557434\n",
      "###### N,i = 5,1 #####\n",
      "M: 40.690784\n",
      "det: 0.00013847317\n",
      "Validation loss mlp/pin: 1.984350/1.502710\n",
      "\n",
      "Epoch 028/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.481549/2.589353\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.083548/3.408570\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 2.020178/1.568234\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5520144\n",
      "det: 0.0071718055\n",
      "Validation loss mlp/pin: 2.512884/2.619579\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.174143\n",
      "det: 0.021576166\n",
      "Validation loss mlp/pin: 1.111949/3.506241\n",
      "###### N,i = 5,1 #####\n",
      "M: 29.831732\n",
      "det: 0.00013442714\n",
      "Validation loss mlp/pin: 1.943729/1.589066\n",
      "\n",
      "Epoch 029/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.473981/2.589254\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.056441/3.355588\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.980472/1.577625\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5297496\n",
      "det: 0.007448086\n",
      "Validation loss mlp/pin: 2.505104/2.619303\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.281347\n",
      "det: 0.021621305\n",
      "Validation loss mlp/pin: 1.084889/3.452104\n",
      "###### N,i = 5,1 #####\n",
      "M: 35.535458\n",
      "det: 0.00013017535\n",
      "Validation loss mlp/pin: 1.905951/1.544832\n",
      "\n",
      "Epoch 030/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.466099/2.589207\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.031311/3.300010\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.943154/1.546936\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.50798\n",
      "det: 0.0077328836\n",
      "Validation loss mlp/pin: 2.496979/2.619068\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.0320835\n",
      "det: 0.021711092\n",
      "Validation loss mlp/pin: 1.059195/3.394783\n",
      "###### N,i = 5,1 #####\n",
      "M: 34.855297\n",
      "det: 0.00012587717\n",
      "Validation loss mlp/pin: 1.870691/1.524874\n",
      "\n",
      "Epoch 031/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.457771/2.589132\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 1.007825/3.242030\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.908934/1.540890\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.487019\n",
      "det: 0.008022478\n",
      "Validation loss mlp/pin: 2.488538/2.618889\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.14372\n",
      "det: 0.02178348\n",
      "Validation loss mlp/pin: 1.035462/3.335918\n",
      "###### N,i = 5,1 #####\n",
      "M: 52.086308\n",
      "det: 0.000121586825\n",
      "Validation loss mlp/pin: 1.837629/1.503280\n",
      "\n",
      "Epoch 032/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.449043/2.589108\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.986176/3.182373\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.875243/1.538126\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.4667938\n",
      "det: 0.0083159255\n",
      "Validation loss mlp/pin: 2.479695/2.618741\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.042671\n",
      "det: 0.021883426\n",
      "Validation loss mlp/pin: 1.013145/3.275115\n",
      "###### N,i = 5,1 #####\n",
      "M: 46.800896\n",
      "det: 0.0001173653\n",
      "Validation loss mlp/pin: 1.806797/1.502295\n",
      "\n",
      "Epoch 033/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.439894/2.589087\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.965776/3.121329\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.844998/1.543570\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.4468107\n",
      "det: 0.008624233\n",
      "Validation loss mlp/pin: 2.470400/2.618612\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.042511\n",
      "det: 0.021931764\n",
      "Validation loss mlp/pin: 0.992871/3.213570\n",
      "###### N,i = 5,1 #####\n",
      "M: 29.448122\n",
      "det: 0.00011314451\n",
      "Validation loss mlp/pin: 1.778216/1.512627\n",
      "\n",
      "Epoch 034/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.430240/2.589047\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.947185/3.059697\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.816504/1.541221\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.4275894\n",
      "det: 0.008937223\n",
      "Validation loss mlp/pin: 2.460677/2.618524\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.335519\n",
      "det: 0.021986602\n",
      "Validation loss mlp/pin: 0.974064/3.151418\n",
      "###### N,i = 5,1 #####\n",
      "M: 68.28338\n",
      "det: 0.00010901543\n",
      "Validation loss mlp/pin: 1.751770/1.502812\n",
      "\n",
      "Epoch 035/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.420257/2.589091\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.929978/2.997295\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.790509/1.538941\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.4088807\n",
      "det: 0.009261702\n",
      "Validation loss mlp/pin: 2.450499/2.618444\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.107443\n",
      "det: 0.022065004\n",
      "Validation loss mlp/pin: 0.956310/3.088654\n",
      "###### N,i = 5,1 #####\n",
      "M: 41.183926\n",
      "det: 0.00010520662\n",
      "Validation loss mlp/pin: 1.727388/1.504780\n",
      "\n",
      "Epoch 036/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.409652/2.589059\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.914006/2.935146\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.766825/1.547374\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.3905146\n",
      "det: 0.009601409\n",
      "Validation loss mlp/pin: 2.439840/2.618373\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.327126\n",
      "det: 0.0221359\n",
      "Validation loss mlp/pin: 0.939970/3.026287\n",
      "###### N,i = 5,1 #####\n",
      "M: 26.58983\n",
      "det: 0.00010132832\n",
      "Validation loss mlp/pin: 1.704800/1.503612\n",
      "\n",
      "Epoch 037/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.398579/2.589054\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.899406/2.873464\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.744441/1.555844\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.372991\n",
      "det: 0.009942042\n",
      "Validation loss mlp/pin: 2.428720/2.618310\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.3108606\n",
      "det: 0.022242358\n",
      "Validation loss mlp/pin: 0.924489/2.963792\n",
      "###### N,i = 5,1 #####\n",
      "M: 44.330723\n",
      "det: 9.743507e-05\n",
      "Validation loss mlp/pin: 1.684333/1.507653\n",
      "\n",
      "Epoch 038/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.386945/2.589018\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.885497/2.812226\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.723322/1.541233\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.3562956\n",
      "det: 0.010283079\n",
      "Validation loss mlp/pin: 2.417132/2.618271\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.568833\n",
      "det: 0.0223078\n",
      "Validation loss mlp/pin: 0.910459/2.902167\n",
      "###### N,i = 5,1 #####\n",
      "M: 30.193256\n",
      "det: 9.373237e-05\n",
      "Validation loss mlp/pin: 1.665124/1.507068\n",
      "\n",
      "Epoch 039/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.374867/2.589047\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.872899/2.752175\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.704319/1.536926\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.3395884\n",
      "det: 0.010658858\n",
      "Validation loss mlp/pin: 2.404916/2.618215\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.158334\n",
      "det: 0.022346554\n",
      "Validation loss mlp/pin: 0.897670/2.841347\n",
      "###### N,i = 5,1 #####\n",
      "M: 33.193512\n",
      "det: 9.012941e-05\n",
      "Validation loss mlp/pin: 1.647842/1.502126\n",
      "\n",
      "Epoch 040/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.362281/2.589056\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.861328/2.693062\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.687320/1.538524\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.3239553\n",
      "det: 0.011040262\n",
      "Validation loss mlp/pin: 2.392210/2.618165\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.255969\n",
      "det: 0.022427037\n",
      "Validation loss mlp/pin: 0.885493/2.781530\n",
      "###### N,i = 5,1 #####\n",
      "M: 29.280216\n",
      "det: 8.6396256e-05\n",
      "Validation loss mlp/pin: 1.632258/1.502723\n",
      "\n",
      "Epoch 041/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.349116/2.589025\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.850063/2.635180\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.671111/1.538227\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.3097005\n",
      "det: 0.011389024\n",
      "Validation loss mlp/pin: 2.379083/2.618155\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.010265\n",
      "det: 0.022492692\n",
      "Validation loss mlp/pin: 0.874324/2.723049\n",
      "###### N,i = 5,1 #####\n",
      "M: 41.66482\n",
      "det: 8.313291e-05\n",
      "Validation loss mlp/pin: 1.617347/1.510575\n",
      "\n",
      "Epoch 042/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.335434/2.589018\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.839957/2.578660\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.656769/1.537086\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2955198\n",
      "det: 0.011771269\n",
      "Validation loss mlp/pin: 2.365308/2.618129\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.95961\n",
      "det: 0.022558741\n",
      "Validation loss mlp/pin: 0.863949/2.666141\n",
      "###### N,i = 5,1 #####\n",
      "M: 60.958656\n",
      "det: 7.967617e-05\n",
      "Validation loss mlp/pin: 1.604689/1.509701\n",
      "\n",
      "Epoch 043/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.321142/2.588998\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.830474/2.523635\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.643703/1.541693\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.282218\n",
      "det: 0.012143405\n",
      "Validation loss mlp/pin: 2.351012/2.618109\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.938548\n",
      "det: 0.022611998\n",
      "Validation loss mlp/pin: 0.854473/2.610686\n",
      "###### N,i = 5,1 #####\n",
      "M: 60.33654\n",
      "det: 7.657288e-05\n",
      "Validation loss mlp/pin: 1.592157/1.503620\n",
      "\n",
      "Epoch 044/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.306330/2.589012\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.821890/2.470248\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.631123/1.540155\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.269534\n",
      "det: 0.012524966\n",
      "Validation loss mlp/pin: 2.336176/2.618097\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.4705877\n",
      "det: 0.022682907\n",
      "Validation loss mlp/pin: 0.845535/2.556631\n",
      "###### N,i = 5,1 #####\n",
      "M: 34.755688\n",
      "det: 7.33624e-05\n",
      "Validation loss mlp/pin: 1.581990/1.519015\n",
      "\n",
      "Epoch 045/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.290960/2.589006\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.813772/2.418540\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.620475/1.543144\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.257458\n",
      "det: 0.01293049\n",
      "Validation loss mlp/pin: 2.320773/2.618079\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.607962\n",
      "det: 0.022731967\n",
      "Validation loss mlp/pin: 0.837436/2.504609\n",
      "###### N,i = 5,1 #####\n",
      "M: 39.688004\n",
      "det: 7.0612885e-05\n",
      "Validation loss mlp/pin: 1.571549/1.502371\n",
      "\n",
      "Epoch 046/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.275100/2.589009\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.806390/2.368495\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.611893/1.540687\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.246305\n",
      "det: 0.013331626\n",
      "Validation loss mlp/pin: 2.304956/2.618064\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.966232\n",
      "det: 0.022782832\n",
      "Validation loss mlp/pin: 0.829977/2.453846\n",
      "###### N,i = 5,1 #####\n",
      "M: 57.52062\n",
      "det: 6.7769564e-05\n",
      "Validation loss mlp/pin: 1.562490/1.501862\n",
      "\n",
      "Epoch 047/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.258743/2.589023\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.799468/2.320163\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.601535/1.538912\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2359474\n",
      "det: 0.01374739\n",
      "Validation loss mlp/pin: 2.288658/2.618057\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.338239\n",
      "det: 0.02288308\n",
      "Validation loss mlp/pin: 0.822431/2.404884\n",
      "###### N,i = 5,1 #####\n",
      "M: 69.028946\n",
      "det: 6.5000764e-05\n",
      "Validation loss mlp/pin: 1.554295/1.513195\n",
      "\n",
      "Epoch 048/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.241898/2.589005\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.792877/2.273613\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.593468/1.542446\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2264612\n",
      "det: 0.014193583\n",
      "Validation loss mlp/pin: 2.271861/2.618048\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.0570803\n",
      "det: 0.022966424\n",
      "Validation loss mlp/pin: 0.815649/2.357275\n",
      "###### N,i = 5,1 #####\n",
      "M: 91.58574\n",
      "det: 6.2247906e-05\n",
      "Validation loss mlp/pin: 1.547143/1.503786\n",
      "\n",
      "Epoch 049/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.224615/2.588994\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.786878/2.228687\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.585599/1.538057\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.217942\n",
      "det: 0.014640273\n",
      "Validation loss mlp/pin: 2.254674/2.618041\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.092947\n",
      "det: 0.023036312\n",
      "Validation loss mlp/pin: 0.809431/2.311852\n",
      "###### N,i = 5,1 #####\n",
      "M: 93.14404\n",
      "det: 5.9717106e-05\n",
      "Validation loss mlp/pin: 1.540603/1.506738\n",
      "\n",
      "Epoch 050/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.206949/2.589011\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.781354/2.185411\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.578956/1.546931\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2103262\n",
      "det: 0.015098538\n",
      "Validation loss mlp/pin: 2.237065/2.618035\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.290029\n",
      "det: 0.023108544\n",
      "Validation loss mlp/pin: 0.803626/2.268077\n",
      "###### N,i = 5,1 #####\n",
      "M: 50.844803\n",
      "det: 5.734633e-05\n",
      "Validation loss mlp/pin: 1.534344/1.502275\n",
      "\n",
      "Epoch 051/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.188853/2.589030\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.776061/2.143791\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.572527/1.542214\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2037024\n",
      "det: 0.01557168\n",
      "Validation loss mlp/pin: 2.219053/2.618017\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.132725\n",
      "det: 0.023190606\n",
      "Validation loss mlp/pin: 0.798136/2.225537\n",
      "###### N,i = 5,1 #####\n",
      "M: 75.74601\n",
      "det: 5.5045406e-05\n",
      "Validation loss mlp/pin: 1.528937/1.502930\n",
      "\n",
      "Epoch 052/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.170345/2.589027\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.771291/2.103977\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.566579/1.537176\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.1978683\n",
      "det: 0.016026646\n",
      "Validation loss mlp/pin: 2.200746/2.618018\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.798501\n",
      "det: 0.023246624\n",
      "Validation loss mlp/pin: 0.793085/2.184976\n",
      "###### N,i = 5,1 #####\n",
      "M: 116.407425\n",
      "det: 5.2795192e-05\n",
      "Validation loss mlp/pin: 1.524313/1.506002\n",
      "\n",
      "Epoch 053/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.151505/2.589044\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.766580/2.065653\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.561868/1.538391\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.1930313\n",
      "det: 0.016503995\n",
      "Validation loss mlp/pin: 2.182061/2.618017\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.8727\n",
      "det: 0.023311099\n",
      "Validation loss mlp/pin: 0.788317/2.146039\n",
      "###### N,i = 5,1 #####\n",
      "M: 41.093346\n",
      "det: 5.074914e-05\n",
      "Validation loss mlp/pin: 1.519710/1.504738\n",
      "\n",
      "Epoch 054/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.132277/2.589009\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.762186/2.028805\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.556994/1.537597\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.1891427\n",
      "det: 0.016992234\n",
      "Validation loss mlp/pin: 2.163041/2.618020\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.400999\n",
      "det: 0.023355162\n",
      "Validation loss mlp/pin: 0.784015/2.108663\n",
      "###### N,i = 5,1 #####\n",
      "M: 143.15219\n",
      "det: 4.8666003e-05\n",
      "Validation loss mlp/pin: 1.515842/1.512867\n",
      "\n",
      "Epoch 055/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.112811/2.589007\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.758260/1.993528\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.552771/1.540774\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.18615\n",
      "det: 0.017487846\n",
      "Validation loss mlp/pin: 2.143694/2.618019\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.3069973\n",
      "det: 0.023427002\n",
      "Validation loss mlp/pin: 0.779745/2.072846\n",
      "###### N,i = 5,1 #####\n",
      "M: 47.529934\n",
      "det: 4.6618963e-05\n",
      "Validation loss mlp/pin: 1.512409/1.503460\n",
      "\n",
      "Epoch 056/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.092966/2.589012\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.754368/1.959664\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.549398/1.542401\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.1841917\n",
      "det: 0.018010862\n",
      "Validation loss mlp/pin: 2.123993/2.618011\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.684347\n",
      "det: 0.023514321\n",
      "Validation loss mlp/pin: 0.775611/2.038040\n",
      "###### N,i = 5,1 #####\n",
      "M: 78.636246\n",
      "det: 4.4700653e-05\n",
      "Validation loss mlp/pin: 1.508994/1.524504\n",
      "\n",
      "Epoch 057/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.072921/2.589005\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.750766/1.927199\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.545449/1.541019\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.182878\n",
      "det: 0.018514367\n",
      "Validation loss mlp/pin: 2.104115/2.618011\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.726165\n",
      "det: 0.02357754\n",
      "Validation loss mlp/pin: 0.771885/2.005020\n",
      "###### N,i = 5,1 #####\n",
      "M: 181.90883\n",
      "det: 4.2857897e-05\n",
      "Validation loss mlp/pin: 1.506053/1.501665\n",
      "\n",
      "Epoch 058/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.052594/2.588999\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.747523/1.896276\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.542065/1.534827\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.1822376\n",
      "det: 0.01901249\n",
      "Validation loss mlp/pin: 2.084026/2.618010\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.221634\n",
      "det: 0.023642423\n",
      "Validation loss mlp/pin: 0.768334/1.973321\n",
      "###### N,i = 5,1 #####\n",
      "M: 93.310394\n",
      "det: 4.1061132e-05\n",
      "Validation loss mlp/pin: 1.504272/1.504638\n",
      "\n",
      "Epoch 059/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.032108/2.589006\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.744279/1.866454\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.539992/1.539300\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.1825387\n",
      "det: 0.019528836\n",
      "Validation loss mlp/pin: 2.063699/2.618001\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.275347\n",
      "det: 0.023728719\n",
      "Validation loss mlp/pin: 0.764847/1.942776\n",
      "###### N,i = 5,1 #####\n",
      "M: 60.572857\n",
      "det: 3.9486767e-05\n",
      "Validation loss mlp/pin: 1.501079/1.505846\n",
      "\n",
      "Epoch 060/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 2.011404/2.589003\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.741302/1.838022\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.536876/1.536605\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.183443\n",
      "det: 0.020042228\n",
      "Validation loss mlp/pin: 2.043196/2.618000\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.535023\n",
      "det: 0.023789713\n",
      "Validation loss mlp/pin: 0.761675/1.913671\n",
      "###### N,i = 5,1 #####\n",
      "M: 98.96828\n",
      "det: 3.7870253e-05\n",
      "Validation loss mlp/pin: 1.499020/1.501604\n",
      "\n",
      "Epoch 061/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.990512/2.589014\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.738486/1.810654\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.534886/1.537256\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.1852155\n",
      "det: 0.020573435\n",
      "Validation loss mlp/pin: 2.022492/2.617997\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.600689\n",
      "det: 0.023850698\n",
      "Validation loss mlp/pin: 0.758665/1.885600\n",
      "###### N,i = 5,1 #####\n",
      "M: 146.74199\n",
      "det: 3.633023e-05\n",
      "Validation loss mlp/pin: 1.497258/1.501624\n",
      "\n",
      "Epoch 062/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.969498/2.589015\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.735613/1.784518\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.532368/1.536156\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.1875455\n",
      "det: 0.021096924\n",
      "Validation loss mlp/pin: 2.001685/2.617994\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.156153\n",
      "det: 0.023930855\n",
      "Validation loss mlp/pin: 0.755667/1.858799\n",
      "###### N,i = 5,1 #####\n",
      "M: 80.57586\n",
      "det: 3.470116e-05\n",
      "Validation loss mlp/pin: 1.495801/1.502297\n",
      "\n",
      "Epoch 063/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.948360/2.589003\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.732955/1.759435\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.531273/1.539812\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.1906192\n",
      "det: 0.021629723\n",
      "Validation loss mlp/pin: 1.980736/2.617992\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.386566\n",
      "det: 0.023971025\n",
      "Validation loss mlp/pin: 0.753047/1.833356\n",
      "###### N,i = 5,1 #####\n",
      "M: 150.80536\n",
      "det: 3.3277756e-05\n",
      "Validation loss mlp/pin: 1.493826/1.502185\n",
      "\n",
      "Epoch 064/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.927145/2.589030\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.730565/1.735547\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.529668/1.544280\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.1944811\n",
      "det: 0.02217495\n",
      "Validation loss mlp/pin: 1.959682/2.617986\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.711948\n",
      "det: 0.024045113\n",
      "Validation loss mlp/pin: 0.750302/1.808511\n",
      "###### N,i = 5,1 #####\n",
      "M: 191.08658\n",
      "det: 3.186836e-05\n",
      "Validation loss mlp/pin: 1.492284/1.501665\n",
      "\n",
      "Epoch 065/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.905804/2.589003\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.728067/1.712490\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.527348/1.538253\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.1984987\n",
      "det: 0.022692354\n",
      "Validation loss mlp/pin: 1.938642/2.617990\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.418709\n",
      "det: 0.024112089\n",
      "Validation loss mlp/pin: 0.747725/1.785365\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.23512\n",
      "det: 3.0546216e-05\n",
      "Validation loss mlp/pin: 1.491004/1.501770\n",
      "\n",
      "Epoch 066/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.884488/2.589006\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.725778/1.690609\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.525881/1.537753\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2036216\n",
      "det: 0.02324777\n",
      "Validation loss mlp/pin: 1.917467/2.617987\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.21269\n",
      "det: 0.024192788\n",
      "Validation loss mlp/pin: 0.745141/1.762240\n",
      "###### N,i = 5,1 #####\n",
      "M: 54.121437\n",
      "det: 2.9244138e-05\n",
      "Validation loss mlp/pin: 1.489821/1.501720\n",
      "\n",
      "Epoch 067/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.863071/2.588996\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.723383/1.669525\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.524583/1.538683\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2096105\n",
      "det: 0.023824513\n",
      "Validation loss mlp/pin: 1.896217/2.617982\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.221087\n",
      "det: 0.024254747\n",
      "Validation loss mlp/pin: 0.742768/1.740526\n",
      "###### N,i = 5,1 #####\n",
      "M: 166.50381\n",
      "det: 2.797397e-05\n",
      "Validation loss mlp/pin: 1.488851/1.501604\n",
      "\n",
      "Epoch 068/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.841693/2.589001\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.721274/1.649423\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.523209/1.536918\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2156267\n",
      "det: 0.024370244\n",
      "Validation loss mlp/pin: 1.875049/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.624141\n",
      "det: 0.024343718\n",
      "Validation loss mlp/pin: 0.740314/1.719679\n",
      "###### N,i = 5,1 #####\n",
      "M: 153.35963\n",
      "det: 2.6759977e-05\n",
      "Validation loss mlp/pin: 1.487813/1.502435\n",
      "\n",
      "Epoch 069/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.820360/2.589012\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.719205/1.630046\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.522254/1.540473\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2216363\n",
      "det: 0.024887385\n",
      "Validation loss mlp/pin: 1.853990/2.617981\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.3489895\n",
      "det: 0.024384147\n",
      "Validation loss mlp/pin: 0.738219/1.699759\n",
      "###### N,i = 5,1 #####\n",
      "M: 132.90773\n",
      "det: 2.5558957e-05\n",
      "Validation loss mlp/pin: 1.487101/1.504214\n",
      "\n",
      "Epoch 070/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.799072/2.589007\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.717008/1.611408\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.521857/1.541784\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2281947\n",
      "det: 0.025411114\n",
      "Validation loss mlp/pin: 1.832971/2.617987\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.21007\n",
      "det: 0.024446363\n",
      "Validation loss mlp/pin: 0.736086/1.680727\n",
      "###### N,i = 5,1 #####\n",
      "M: 98.4065\n",
      "det: 2.4418297e-05\n",
      "Validation loss mlp/pin: 1.486249/1.506077\n",
      "\n",
      "Epoch 071/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.777900/2.589013\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.714981/1.593757\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.520336/1.536893\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2356563\n",
      "det: 0.025962714\n",
      "Validation loss mlp/pin: 1.811945/2.617989\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.2196093\n",
      "det: 0.024509832\n",
      "Validation loss mlp/pin: 0.733978/1.662195\n",
      "###### N,i = 5,1 #####\n",
      "M: 198.34735\n",
      "det: 2.3319564e-05\n",
      "Validation loss mlp/pin: 1.485431/1.512885\n",
      "\n",
      "Epoch 072/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.756790/2.589010\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.713168/1.576690\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.519505/1.539759\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2438192\n",
      "det: 0.026530566\n",
      "Validation loss mlp/pin: 1.790965/2.617987\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.519185\n",
      "det: 0.024575926\n",
      "Validation loss mlp/pin: 0.731900/1.644423\n",
      "###### N,i = 5,1 #####\n",
      "M: 143.91476\n",
      "det: 2.2294016e-05\n",
      "Validation loss mlp/pin: 1.484707/1.502089\n",
      "\n",
      "Epoch 073/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.735755/2.588999\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.710993/1.560219\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.518469/1.537138\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.252453\n",
      "det: 0.027102625\n",
      "Validation loss mlp/pin: 1.770077/2.617987\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.90796\n",
      "det: 0.02466021\n",
      "Validation loss mlp/pin: 0.729735/1.627432\n",
      "###### N,i = 5,1 #####\n",
      "M: 120.75935\n",
      "det: 2.1308604e-05\n",
      "Validation loss mlp/pin: 1.484086/1.501581\n",
      "\n",
      "Epoch 074/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.714856/2.589004\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.709132/1.544454\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.517708/1.536995\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2608702\n",
      "det: 0.027642215\n",
      "Validation loss mlp/pin: 1.749399/2.617987\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.5549192\n",
      "det: 0.024726931\n",
      "Validation loss mlp/pin: 0.727767/1.611203\n",
      "###### N,i = 5,1 #####\n",
      "M: 205.74614\n",
      "det: 2.0357313e-05\n",
      "Validation loss mlp/pin: 1.483517/1.506063\n",
      "\n",
      "Epoch 075/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.694085/2.588997\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.707269/1.529381\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.517201/1.538286\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2699883\n",
      "det: 0.02820015\n",
      "Validation loss mlp/pin: 1.728821/2.617986\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.930847\n",
      "det: 0.024761247\n",
      "Validation loss mlp/pin: 0.726132/1.595342\n",
      "###### N,i = 5,1 #####\n",
      "M: 102.841\n",
      "det: 1.9447156e-05\n",
      "Validation loss mlp/pin: 1.482991/1.508879\n",
      "\n",
      "Epoch 076/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.673490/2.589000\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.705525/1.514810\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.516698/1.541943\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.2794948\n",
      "det: 0.02876062\n",
      "Validation loss mlp/pin: 1.708406/2.617981\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.534041\n",
      "det: 0.024844239\n",
      "Validation loss mlp/pin: 0.724059/1.580485\n",
      "###### N,i = 5,1 #####\n",
      "M: 131.21373\n",
      "det: 1.856531e-05\n",
      "Validation loss mlp/pin: 1.482792/1.504735\n",
      "\n",
      "Epoch 077/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.653068/2.588999\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.703726/1.500920\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.515806/1.535180\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.289225\n",
      "det: 0.029316071\n",
      "Validation loss mlp/pin: 1.688195/2.617981\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.436728\n",
      "det: 0.024883188\n",
      "Validation loss mlp/pin: 0.722437/1.565801\n",
      "###### N,i = 5,1 #####\n",
      "M: 214.30109\n",
      "det: 1.7763157e-05\n",
      "Validation loss mlp/pin: 1.482261/1.505181\n",
      "\n",
      "Epoch 078/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.632850/2.589002\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.702028/1.487537\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.515071/1.536624\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.299489\n",
      "det: 0.029883064\n",
      "Validation loss mlp/pin: 1.668183/2.617977\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.58418\n",
      "det: 0.024955671\n",
      "Validation loss mlp/pin: 0.720501/1.551702\n",
      "###### N,i = 5,1 #####\n",
      "M: 126.45646\n",
      "det: 1.6994123e-05\n",
      "Validation loss mlp/pin: 1.481657/1.502041\n",
      "\n",
      "Epoch 079/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.612868/2.589005\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.700366/1.474584\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.514578/1.536737\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.3089433\n",
      "det: 0.03039457\n",
      "Validation loss mlp/pin: 1.648467/2.617981\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.234881\n",
      "det: 0.025023058\n",
      "Validation loss mlp/pin: 0.718635/1.538241\n",
      "###### N,i = 5,1 #####\n",
      "M: 83.39508\n",
      "det: 1.6220116e-05\n",
      "Validation loss mlp/pin: 1.481279/1.502605\n",
      "\n",
      "Epoch 080/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.593102/2.589003\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.698725/1.462176\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.513973/1.535331\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.319551\n",
      "det: 0.030950895\n",
      "Validation loss mlp/pin: 1.628902/2.617976\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.938064\n",
      "det: 0.025082558\n",
      "Validation loss mlp/pin: 0.716886/1.525262\n",
      "###### N,i = 5,1 #####\n",
      "M: 224.934\n",
      "det: 1.544898e-05\n",
      "Validation loss mlp/pin: 1.480944/1.502198\n",
      "\n",
      "Epoch 081/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.573604/2.588998\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.696973/1.450230\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.513499/1.535124\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.3298154\n",
      "det: 0.031477947\n",
      "Validation loss mlp/pin: 1.609625/2.617979\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.212366\n",
      "det: 0.025135998\n",
      "Validation loss mlp/pin: 0.715181/1.512713\n",
      "###### N,i = 5,1 #####\n",
      "M: 135.88385\n",
      "det: 1.4737341e-05\n",
      "Validation loss mlp/pin: 1.480671/1.504706\n",
      "\n",
      "Epoch 082/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.554353/2.589006\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.695444/1.438658\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.513766/1.537607\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.3396626\n",
      "det: 0.031973563\n",
      "Validation loss mlp/pin: 1.590638/2.617982\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.099109\n",
      "det: 0.02521917\n",
      "Validation loss mlp/pin: 0.713259/1.500760\n",
      "###### N,i = 5,1 #####\n",
      "M: 193.35947\n",
      "det: 1.4015799e-05\n",
      "Validation loss mlp/pin: 1.480283/1.505062\n",
      "\n",
      "Epoch 083/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.535351/2.588994\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.693760/1.427541\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.512884/1.537426\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.350483\n",
      "det: 0.032505978\n",
      "Validation loss mlp/pin: 1.571823/2.617981\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.970402\n",
      "det: 0.025257131\n",
      "Validation loss mlp/pin: 0.711699/1.489130\n",
      "###### N,i = 5,1 #####\n",
      "M: 262.58304\n",
      "det: 1.3339041e-05\n",
      "Validation loss mlp/pin: 1.479999/1.502455\n",
      "\n",
      "Epoch 084/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.516650/2.589018\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.692124/1.416814\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.512355/1.535461\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.3614051\n",
      "det: 0.03303333\n",
      "Validation loss mlp/pin: 1.553270/2.617977\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.976744\n",
      "det: 0.025323726\n",
      "Validation loss mlp/pin: 0.709924/1.477828\n",
      "###### N,i = 5,1 #####\n",
      "M: 291.19034\n",
      "det: 1.2684718e-05\n",
      "Validation loss mlp/pin: 1.479719/1.502938\n",
      "\n",
      "Epoch 085/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.498186/2.588997\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.690677/1.406524\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.512298/1.537526\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.3719752\n",
      "det: 0.033535257\n",
      "Validation loss mlp/pin: 1.535025/2.617979\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.3587055\n",
      "det: 0.025375366\n",
      "Validation loss mlp/pin: 0.708293/1.467039\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.56824\n",
      "det: 1.20434315e-05\n",
      "Validation loss mlp/pin: 1.479482/1.501569\n",
      "\n",
      "Epoch 086/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.480033/2.589008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.688957/1.396621\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.511730/1.536159\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.3829072\n",
      "det: 0.03404634\n",
      "Validation loss mlp/pin: 1.517035/2.617981\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.3902445\n",
      "det: 0.025428994\n",
      "Validation loss mlp/pin: 0.706667/1.456638\n",
      "###### N,i = 5,1 #####\n",
      "M: 237.50055\n",
      "det: 1.1415436e-05\n",
      "Validation loss mlp/pin: 1.479303/1.502452\n",
      "\n",
      "Epoch 087/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.462147/2.589010\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.687414/1.387011\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.511361/1.536968\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.3944871\n",
      "det: 0.03458053\n",
      "Validation loss mlp/pin: 1.499285/2.617979\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.148824\n",
      "det: 0.025509087\n",
      "Validation loss mlp/pin: 0.704885/1.446482\n",
      "###### N,i = 5,1 #####\n",
      "M: 256.0105\n",
      "det: 1.0854992e-05\n",
      "Validation loss mlp/pin: 1.478995/1.501779\n",
      "\n",
      "Epoch 088/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.444535/2.589002\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.685707/1.377673\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.511144/1.537574\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.405818\n",
      "det: 0.035095986\n",
      "Validation loss mlp/pin: 1.481850/2.617981\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.917544\n",
      "det: 0.025540618\n",
      "Validation loss mlp/pin: 0.703409/1.436767\n",
      "###### N,i = 5,1 #####\n",
      "M: 179.74591\n",
      "det: 1.0280252e-05\n",
      "Validation loss mlp/pin: 1.478934/1.502257\n",
      "\n",
      "Epoch 089/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.427230/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.684201/1.368763\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.511054/1.540681\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.4171822\n",
      "det: 0.03560614\n",
      "Validation loss mlp/pin: 1.464709/2.617980\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.170455\n",
      "det: 0.025581151\n",
      "Validation loss mlp/pin: 0.701919/1.427446\n",
      "###### N,i = 5,1 #####\n",
      "M: 506.49203\n",
      "det: 9.736791e-06\n",
      "Validation loss mlp/pin: 1.478812/1.503845\n",
      "\n",
      "Epoch 090/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.410221/2.588995\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.682865/1.360078\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.510570/1.535701\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.428319\n",
      "det: 0.036099926\n",
      "Validation loss mlp/pin: 1.447886/2.617980\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.134771\n",
      "det: 0.025624195\n",
      "Validation loss mlp/pin: 0.700436/1.418200\n",
      "###### N,i = 5,1 #####\n",
      "M: 241.04916\n",
      "det: 9.211942e-06\n",
      "Validation loss mlp/pin: 1.478390/1.502974\n",
      "\n",
      "Epoch 091/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.393529/2.589004\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.681386/1.351709\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.510308/1.534322\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.439577\n",
      "det: 0.036594395\n",
      "Validation loss mlp/pin: 1.431354/2.617981\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.308275\n",
      "det: 0.025679627\n",
      "Validation loss mlp/pin: 0.698822/1.409424\n",
      "###### N,i = 5,1 #####\n",
      "M: 235.27188\n",
      "det: 8.6924865e-06\n",
      "Validation loss mlp/pin: 1.478525/1.505993\n",
      "\n",
      "Epoch 092/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.377133/2.589012\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.679843/1.343600\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.510211/1.538106\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.4506912\n",
      "det: 0.037077703\n",
      "Validation loss mlp/pin: 1.415133/2.617983\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.746599\n",
      "det: 0.025760323\n",
      "Validation loss mlp/pin: 0.697035/1.400861\n",
      "###### N,i = 5,1 #####\n",
      "M: 118.73988\n",
      "det: 8.211438e-06\n",
      "Validation loss mlp/pin: 1.478034/1.501947\n",
      "\n",
      "Epoch 093/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.361043/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.678207/1.335675\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.509707/1.536231\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.4616897\n",
      "det: 0.037551463\n",
      "Validation loss mlp/pin: 1.399222/2.617983\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.5826225\n",
      "det: 0.025806762\n",
      "Validation loss mlp/pin: 0.695502/1.392616\n",
      "###### N,i = 5,1 #####\n",
      "M: 294.82623\n",
      "det: 7.731313e-06\n",
      "Validation loss mlp/pin: 1.478032/1.507638\n",
      "\n",
      "Epoch 094/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.345298/2.589009\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.676840/1.328175\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.509483/1.537361\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.4732916\n",
      "det: 0.038048703\n",
      "Validation loss mlp/pin: 1.383570/2.617981\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.650692\n",
      "det: 0.025844138\n",
      "Validation loss mlp/pin: 0.694028/1.384631\n",
      "###### N,i = 5,1 #####\n",
      "M: 195.76413\n",
      "det: 7.265115e-06\n",
      "Validation loss mlp/pin: 1.477848/1.502132\n",
      "\n",
      "Epoch 095/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.329836/2.589010\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.675361/1.320706\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.509755/1.538472\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.48447\n",
      "det: 0.0385234\n",
      "Validation loss mlp/pin: 1.368246/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.8885393\n",
      "det: 0.02589857\n",
      "Validation loss mlp/pin: 0.692442/1.376920\n",
      "###### N,i = 5,1 #####\n",
      "M: 284.35583\n",
      "det: 6.8295e-06\n",
      "Validation loss mlp/pin: 1.477552/1.505058\n",
      "\n",
      "Epoch 096/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.314665/2.588999\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.673843/1.313625\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.509099/1.537341\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.495798\n",
      "det: 0.03900139\n",
      "Validation loss mlp/pin: 1.353208/2.617975\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.391634\n",
      "det: 0.025952112\n",
      "Validation loss mlp/pin: 0.690865/1.369392\n",
      "###### N,i = 5,1 #####\n",
      "M: 428.3551\n",
      "det: 6.4147657e-06\n",
      "Validation loss mlp/pin: 1.477385/1.501840\n",
      "\n",
      "Epoch 097/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.299811/2.589016\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.672366/1.306612\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.508856/1.536423\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5064697\n",
      "det: 0.039448254\n",
      "Validation loss mlp/pin: 1.338507/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.903009\n",
      "det: 0.025990803\n",
      "Validation loss mlp/pin: 0.689349/1.362126\n",
      "###### N,i = 5,1 #####\n",
      "M: 358.1956\n",
      "det: 6.005864e-06\n",
      "Validation loss mlp/pin: 1.477393/1.502558\n",
      "\n",
      "Epoch 098/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.285243/2.589000\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.670922/1.299989\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.508630/1.536271\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5174167\n",
      "det: 0.039905287\n",
      "Validation loss mlp/pin: 1.324085/2.617975\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.130337\n",
      "det: 0.026011836\n",
      "Validation loss mlp/pin: 0.687930/1.355114\n",
      "###### N,i = 5,1 #####\n",
      "M: 184.97913\n",
      "det: 5.626868e-06\n",
      "Validation loss mlp/pin: 1.477095/1.505256\n",
      "\n",
      "Epoch 099/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.270980/2.589001\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.669432/1.293386\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.508395/1.536478\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5281425\n",
      "det: 0.040350415\n",
      "Validation loss mlp/pin: 1.309963/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.371947\n",
      "det: 0.026043672\n",
      "Validation loss mlp/pin: 0.686448/1.348282\n",
      "###### N,i = 5,1 #####\n",
      "M: 268.40927\n",
      "det: 5.235676e-06\n",
      "Validation loss mlp/pin: 1.476993/1.501966\n",
      "\n",
      "Epoch 100/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.257033/2.589004\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.667992/1.287095\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.508200/1.535852\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.539425\n",
      "det: 0.04081931\n",
      "Validation loss mlp/pin: 1.296103/2.617979\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.389048\n",
      "det: 0.026085392\n",
      "Validation loss mlp/pin: 0.684894/1.341650\n",
      "###### N,i = 5,1 #####\n",
      "M: 337.93896\n",
      "det: 4.863448e-06\n",
      "Validation loss mlp/pin: 1.476935/1.502071\n",
      "\n",
      "Epoch 101/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.243364/2.588994\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.666468/1.280870\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.507976/1.536254\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5501702\n",
      "det: 0.041262604\n",
      "Validation loss mlp/pin: 1.282555/2.617980\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.549273\n",
      "det: 0.026134\n",
      "Validation loss mlp/pin: 0.683308/1.335194\n",
      "###### N,i = 5,1 #####\n",
      "M: 340.93933\n",
      "det: 4.514578e-06\n",
      "Validation loss mlp/pin: 1.476691/1.501994\n",
      "\n",
      "Epoch 102/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.230000/2.588998\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.665064/1.274922\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.507762/1.535781\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5611238\n",
      "det: 0.04171405\n",
      "Validation loss mlp/pin: 1.269279/2.617979\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.118351\n",
      "det: 0.026169512\n",
      "Validation loss mlp/pin: 0.681800/1.328952\n",
      "###### N,i = 5,1 #####\n",
      "M: 149.59264\n",
      "det: 4.1699345e-06\n",
      "Validation loss mlp/pin: 1.476563/1.501562\n",
      "\n",
      "Epoch 103/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.216934/2.589002\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.663590/1.269113\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.507669/1.536508\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.571777\n",
      "det: 0.042151324\n",
      "Validation loss mlp/pin: 1.256297/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.7626915\n",
      "det: 0.026201107\n",
      "Validation loss mlp/pin: 0.680318/1.322832\n",
      "###### N,i = 5,1 #####\n",
      "M: 388.02246\n",
      "det: 3.8439985e-06\n",
      "Validation loss mlp/pin: 1.476488/1.501682\n",
      "\n",
      "Epoch 104/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.204126/2.589003\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.662232/1.263440\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.507274/1.534397\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.5820818\n",
      "det: 0.04257236\n",
      "Validation loss mlp/pin: 1.243603/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.63686\n",
      "det: 0.02623637\n",
      "Validation loss mlp/pin: 0.678797/1.316927\n",
      "###### N,i = 5,1 #####\n",
      "M: 263.64502\n",
      "det: 3.523201e-06\n",
      "Validation loss mlp/pin: 1.476348/1.504192\n",
      "\n",
      "Epoch 105/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.191629/2.588995\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.660733/1.258000\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.507349/1.536206\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.592362\n",
      "det: 0.042992566\n",
      "Validation loss mlp/pin: 1.231185/2.617976\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.530178\n",
      "det: 0.026261147\n",
      "Validation loss mlp/pin: 0.677340/1.311161\n",
      "###### N,i = 5,1 #####\n",
      "M: 462.57913\n",
      "det: 3.2260139e-06\n",
      "Validation loss mlp/pin: 1.476270/1.501581\n",
      "\n",
      "Epoch 106/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.179395/2.588998\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.659277/1.252606\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.507084/1.535299\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6027503\n",
      "det: 0.043417912\n",
      "Validation loss mlp/pin: 1.219035/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.590772\n",
      "det: 0.026287874\n",
      "Validation loss mlp/pin: 0.675871/1.305629\n",
      "###### N,i = 5,1 #####\n",
      "M: 659.11816\n",
      "det: 2.946244e-06\n",
      "Validation loss mlp/pin: 1.476297/1.502388\n",
      "\n",
      "Epoch 107/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.167461/2.589004\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.657884/1.247431\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.507062/1.536440\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.612483\n",
      "det: 0.043814275\n",
      "Validation loss mlp/pin: 1.207174/2.617981\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.839195\n",
      "det: 0.026327675\n",
      "Validation loss mlp/pin: 0.674317/1.300283\n",
      "###### N,i = 5,1 #####\n",
      "M: 432.63013\n",
      "det: 2.6732196e-06\n",
      "Validation loss mlp/pin: 1.476026/1.501585\n",
      "\n",
      "Epoch 108/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.155763/2.588999\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.656656/1.242407\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.506734/1.535489\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6226583\n",
      "det: 0.044229385\n",
      "Validation loss mlp/pin: 1.195553/2.617979\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.430942\n",
      "det: 0.026365655\n",
      "Validation loss mlp/pin: 0.672793/1.294870\n",
      "###### N,i = 5,1 #####\n",
      "M: 361.26154\n",
      "det: 2.4135918e-06\n",
      "Validation loss mlp/pin: 1.475941/1.501811\n",
      "\n",
      "Epoch 109/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.144335/2.589003\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.655015/1.237444\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.506692/1.536427\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6326025\n",
      "det: 0.044634998\n",
      "Validation loss mlp/pin: 1.184196/2.617977\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.154949\n",
      "det: 0.026377793\n",
      "Validation loss mlp/pin: 0.671384/1.289761\n",
      "###### N,i = 5,1 #####\n",
      "M: 898.80585\n",
      "det: 2.16702e-06\n",
      "Validation loss mlp/pin: 1.475844/1.501849\n",
      "\n",
      "Epoch 110/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.133172/2.588995\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.653607/1.232727\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.506461/1.535410\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6423063\n",
      "det: 0.04503007\n",
      "Validation loss mlp/pin: 1.173097/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.52374\n",
      "det: 0.026396325\n",
      "Validation loss mlp/pin: 0.669951/1.284715\n",
      "###### N,i = 5,1 #####\n",
      "M: 238.06235\n",
      "det: 1.945024e-06\n",
      "Validation loss mlp/pin: 1.475710/1.502097\n",
      "\n",
      "Epoch 111/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.122285/2.589011\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.652271/1.227959\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.506239/1.535050\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6516984\n",
      "det: 0.045412354\n",
      "Validation loss mlp/pin: 1.162253/2.617980\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.634838\n",
      "det: 0.026423024\n",
      "Validation loss mlp/pin: 0.668467/1.279889\n",
      "###### N,i = 5,1 #####\n",
      "M: 453.15707\n",
      "det: 1.7319848e-06\n",
      "Validation loss mlp/pin: 1.475525/1.501997\n",
      "\n",
      "Epoch 112/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.111626/2.589008\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.650892/1.223409\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.506357/1.536973\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.660961\n",
      "det: 0.045789417\n",
      "Validation loss mlp/pin: 1.151653/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.851977\n",
      "det: 0.026431637\n",
      "Validation loss mlp/pin: 0.667079/1.275153\n",
      "###### N,i = 5,1 #####\n",
      "M: 437.851\n",
      "det: 1.5289094e-06\n",
      "Validation loss mlp/pin: 1.475480/1.502520\n",
      "\n",
      "Epoch 113/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.101190/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.649762/1.219018\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.506394/1.536522\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.669962\n",
      "det: 0.046155386\n",
      "Validation loss mlp/pin: 1.141297/2.617980\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.402751\n",
      "det: 0.026449168\n",
      "Validation loss mlp/pin: 0.665656/1.270518\n",
      "###### N,i = 5,1 #####\n",
      "M: 761.0007\n",
      "det: 1.3335012e-06\n",
      "Validation loss mlp/pin: 1.475320/1.506508\n",
      "\n",
      "Epoch 114/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.091035/2.589011\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.648105/1.214591\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.505868/1.536084\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6787853\n",
      "det: 0.04651406\n",
      "Validation loss mlp/pin: 1.131178/2.617981\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.298665\n",
      "det: 0.026473364\n",
      "Validation loss mlp/pin: 0.664179/1.265990\n",
      "###### N,i = 5,1 #####\n",
      "M: 569.0331\n",
      "det: 1.1584883e-06\n",
      "Validation loss mlp/pin: 1.475224/1.502209\n",
      "\n",
      "Epoch 115/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.081095/2.588996\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.646832/1.210378\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.505935/1.536043\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6877851\n",
      "det: 0.046880845\n",
      "Validation loss mlp/pin: 1.121275/2.617983\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.599312\n",
      "det: 0.026506888\n",
      "Validation loss mlp/pin: 0.662663/1.261578\n",
      "###### N,i = 5,1 #####\n",
      "M: 1306.2587\n",
      "det: 9.903499e-07\n",
      "Validation loss mlp/pin: 1.475239/1.503701\n",
      "\n",
      "Epoch 116/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.071381/2.588999\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.645413/1.206283\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.506005/1.537704\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.6967573\n",
      "det: 0.047247022\n",
      "Validation loss mlp/pin: 1.111593/2.617983\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.168908\n",
      "det: 0.026501996\n",
      "Validation loss mlp/pin: 0.661329/1.257414\n",
      "###### N,i = 5,1 #####\n",
      "M: 373.97876\n",
      "det: 8.473724e-07\n",
      "Validation loss mlp/pin: 1.475042/1.501528\n",
      "\n",
      "Epoch 117/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.061883/2.589005\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.644035/1.202261\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.505460/1.535437\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7059953\n",
      "det: 0.04762568\n",
      "Validation loss mlp/pin: 1.102121/2.617979\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.9384637\n",
      "det: 0.026509581\n",
      "Validation loss mlp/pin: 0.659953/1.253173\n",
      "###### N,i = 5,1 #####\n",
      "M: 849.15564\n",
      "det: 7.0873665e-07\n",
      "Validation loss mlp/pin: 1.475032/1.501890\n",
      "\n",
      "Epoch 118/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.052618/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.642762/1.198361\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.505418/1.535936\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7141442\n",
      "det: 0.04795776\n",
      "Validation loss mlp/pin: 1.092891/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.451146\n",
      "det: 0.026531227\n",
      "Validation loss mlp/pin: 0.658488/1.249086\n",
      "###### N,i = 5,1 #####\n",
      "M: 762.4572\n",
      "det: 5.927503e-07\n",
      "Validation loss mlp/pin: 1.474859/1.501537\n",
      "\n",
      "Epoch 119/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.043565/2.588996\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.641368/1.194589\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.505208/1.535431\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7223697\n",
      "det: 0.04829395\n",
      "Validation loss mlp/pin: 1.083866/2.617979\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.040108\n",
      "det: 0.026551617\n",
      "Validation loss mlp/pin: 0.657035/1.245053\n",
      "###### N,i = 5,1 #####\n",
      "M: 914.12036\n",
      "det: 4.771808e-07\n",
      "Validation loss mlp/pin: 1.474728/1.502133\n",
      "\n",
      "Epoch 120/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.034719/2.588993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.639996/1.190839\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.505328/1.536676\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7309773\n",
      "det: 0.048647452\n",
      "Validation loss mlp/pin: 1.075032/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.071464\n",
      "det: 0.026553206\n",
      "Validation loss mlp/pin: 0.655685/1.241348\n",
      "###### N,i = 5,1 #####\n",
      "M: 1220.202\n",
      "det: 3.805494e-07\n",
      "Validation loss mlp/pin: 1.474656/1.504582\n",
      "\n",
      "Epoch 121/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.026076/2.588997\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.638684/1.187249\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.505081/1.535900\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7388372\n",
      "det: 0.048970304\n",
      "Validation loss mlp/pin: 1.066417/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.313057\n",
      "det: 0.026558693\n",
      "Validation loss mlp/pin: 0.654320/1.237542\n",
      "###### N,i = 5,1 #####\n",
      "M: 974.2568\n",
      "det: 2.91975e-07\n",
      "Validation loss mlp/pin: 1.474572/1.503054\n",
      "\n",
      "Epoch 122/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.017637/2.588999\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.637388/1.183711\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.504773/1.535013\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7464929\n",
      "det: 0.049285226\n",
      "Validation loss mlp/pin: 1.058005/2.617979\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.070307\n",
      "det: 0.026577195\n",
      "Validation loss mlp/pin: 0.652866/1.233774\n",
      "###### N,i = 5,1 #####\n",
      "M: 1114.7285\n",
      "det: 2.215933e-07\n",
      "Validation loss mlp/pin: 1.474407/1.502749\n",
      "\n",
      "Epoch 123/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.009384/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.636031/1.180251\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.504721/1.535632\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7541635\n",
      "det: 0.04960172\n",
      "Validation loss mlp/pin: 1.049776/2.617979\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.989094\n",
      "det: 0.026581973\n",
      "Validation loss mlp/pin: 0.651502/1.230187\n",
      "###### N,i = 5,1 #####\n",
      "M: 3205.002\n",
      "det: 1.461203e-07\n",
      "Validation loss mlp/pin: 1.474344/1.501542\n",
      "\n",
      "Epoch 124/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 1.001332/2.589000\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.634749/1.176876\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.504819/1.536770\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7618723\n",
      "det: 0.049920786\n",
      "Validation loss mlp/pin: 1.041725/2.617979\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.122075\n",
      "det: 0.026588485\n",
      "Validation loss mlp/pin: 0.650102/1.226714\n",
      "###### N,i = 5,1 #####\n",
      "M: 1135.5051\n",
      "det: 9.830895e-08\n",
      "Validation loss mlp/pin: 1.474296/1.501709\n",
      "\n",
      "Epoch 125/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.993459/2.589002\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.633380/1.173568\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.504404/1.535208\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7693007\n",
      "det: 0.05022846\n",
      "Validation loss mlp/pin: 1.033862/2.617979\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.379566\n",
      "det: 0.026593477\n",
      "Validation loss mlp/pin: 0.648710/1.223247\n",
      "###### N,i = 5,1 #####\n",
      "M: 2671.2627\n",
      "det: 6.271183e-08\n",
      "Validation loss mlp/pin: 1.474215/1.501916\n",
      "\n",
      "Epoch 126/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.985760/2.588996\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.632135/1.170323\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.504276/1.535114\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.7767224\n",
      "det: 0.050536565\n",
      "Validation loss mlp/pin: 1.026172/2.617980\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.8264256\n",
      "det: 0.026592074\n",
      "Validation loss mlp/pin: 0.647352/1.219904\n",
      "###### N,i = 5,1 #####\n",
      "M: 3833.819\n",
      "det: 2.5921633e-08\n",
      "Validation loss mlp/pin: 1.474074/1.501529\n",
      "\n",
      "Epoch 127/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.978246/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.630751/1.167188\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.504284/1.535288\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.784347\n",
      "det: 0.050854694\n",
      "Validation loss mlp/pin: 1.018645/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.50533\n",
      "det: 0.026586512\n",
      "Validation loss mlp/pin: 0.646030/1.216624\n",
      "###### N,i = 5,1 #####\n",
      "M: 7079.291\n",
      "det: 3.5041512e-09\n",
      "Validation loss mlp/pin: 1.473929/1.501578\n",
      "\n",
      "Epoch 128/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.970896/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.629470/1.164068\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.504144/1.535318\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.791451\n",
      "det: 0.051151335\n",
      "Validation loss mlp/pin: 1.011302/2.617977\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.129156\n",
      "det: 0.026585732\n",
      "Validation loss mlp/pin: 0.644679/1.213532\n",
      "###### N,i = 5,1 #####\n",
      "M: 16663.758\n",
      "det: 1.7556678e-09\n",
      "Validation loss mlp/pin: 1.473892/1.501893\n",
      "\n",
      "Epoch 129/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.963738/2.589004\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.628160/1.161110\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.503965/1.535213\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.798698\n",
      "det: 0.051455215\n",
      "Validation loss mlp/pin: 1.004117/2.617975\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.78427\n",
      "det: 0.026595125\n",
      "Validation loss mlp/pin: 0.643276/1.210263\n",
      "###### N,i = 5,1 #####\n",
      "M: 7530.1846\n",
      "det: 7.397154e-09\n",
      "Validation loss mlp/pin: 1.473861/1.501555\n",
      "\n",
      "Epoch 130/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.956723/2.588996\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.626871/1.158100\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.503774/1.534990\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8053675\n",
      "det: 0.05173506\n",
      "Validation loss mlp/pin: 0.997106/2.617976\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.28681\n",
      "det: 0.026585335\n",
      "Validation loss mlp/pin: 0.641977/1.207234\n",
      "###### N,i = 5,1 #####\n",
      "M: 4646.084\n",
      "det: 1.7978952e-08\n",
      "Validation loss mlp/pin: 1.473710/1.501530\n",
      "\n",
      "Epoch 131/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.949864/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.625588/1.155245\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.503738/1.534999\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8124177\n",
      "det: 0.05203271\n",
      "Validation loss mlp/pin: 0.990242/2.617975\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.01393\n",
      "det: 0.026582003\n",
      "Validation loss mlp/pin: 0.640646/1.204265\n",
      "###### N,i = 5,1 #####\n",
      "M: 1831.565\n",
      "det: 4.8527845e-08\n",
      "Validation loss mlp/pin: 1.473619/1.501802\n",
      "\n",
      "Epoch 132/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.943184/2.589008\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.624367/1.152402\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.503901/1.535577\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8192937\n",
      "det: 0.052324098\n",
      "Validation loss mlp/pin: 0.983535/2.617975\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.180176\n",
      "det: 0.026568552\n",
      "Validation loss mlp/pin: 0.639379/1.201312\n",
      "###### N,i = 5,1 #####\n",
      "M: 1812.4236\n",
      "det: 8.409428e-08\n",
      "Validation loss mlp/pin: 1.473537/1.501592\n",
      "\n",
      "Epoch 133/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.936624/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.623111/1.149593\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.504174/1.537445\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8259048\n",
      "det: 0.05260459\n",
      "Validation loss mlp/pin: 0.976979/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.188234\n",
      "det: 0.026561072\n",
      "Validation loss mlp/pin: 0.638076/1.198493\n",
      "###### N,i = 5,1 #####\n",
      "M: 1217.7179\n",
      "det: 1.3102527e-07\n",
      "Validation loss mlp/pin: 1.473370/1.504213\n",
      "\n",
      "Epoch 134/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.930247/2.588995\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.621746/1.146946\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.503521/1.536262\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8318787\n",
      "det: 0.052858848\n",
      "Validation loss mlp/pin: 0.970578/2.617975\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.413013\n",
      "det: 0.026561879\n",
      "Validation loss mlp/pin: 0.636727/1.195678\n",
      "###### N,i = 5,1 #####\n",
      "M: 1757.8846\n",
      "det: 1.8809726e-07\n",
      "Validation loss mlp/pin: 1.473281/1.501863\n",
      "\n",
      "Epoch 135/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.923975/2.589002\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.620545/1.144270\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.503322/1.534975\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8379655\n",
      "det: 0.053118788\n",
      "Validation loss mlp/pin: 0.964315/2.617976\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.422571\n",
      "det: 0.026544658\n",
      "Validation loss mlp/pin: 0.635486/1.193013\n",
      "###### N,i = 5,1 #####\n",
      "M: 950.7055\n",
      "det: 2.511272e-07\n",
      "Validation loss mlp/pin: 1.473200/1.501700\n",
      "\n",
      "Epoch 136/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.917869/2.589000\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.619366/1.141714\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.503284/1.536017\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8440666\n",
      "det: 0.053380385\n",
      "Validation loss mlp/pin: 0.958188/2.617977\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.452232\n",
      "det: 0.026536843\n",
      "Validation loss mlp/pin: 0.634189/1.190320\n",
      "###### N,i = 5,1 #####\n",
      "M: 1242.2406\n",
      "det: 3.1704678e-07\n",
      "Validation loss mlp/pin: 1.473157/1.501550\n",
      "\n",
      "Epoch 137/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.911894/2.588994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.618175/1.139135\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.503232/1.535925\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8500032\n",
      "det: 0.053635657\n",
      "Validation loss mlp/pin: 0.952195/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.359084\n",
      "det: 0.026526017\n",
      "Validation loss mlp/pin: 0.632914/1.187645\n",
      "###### N,i = 5,1 #####\n",
      "M: 1086.6599\n",
      "det: 4.0185418e-07\n",
      "Validation loss mlp/pin: 1.473047/1.501815\n",
      "\n",
      "Epoch 138/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.906056/2.588998\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.616869/1.136639\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.503088/1.535615\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8559666\n",
      "det: 0.053893525\n",
      "Validation loss mlp/pin: 0.946334/2.617978\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.82\n",
      "det: 0.026518451\n",
      "Validation loss mlp/pin: 0.631620/1.185121\n",
      "###### N,i = 5,1 #####\n",
      "M: 1134.1256\n",
      "det: 4.9232113e-07\n",
      "Validation loss mlp/pin: 1.472953/1.501527\n",
      "\n",
      "Epoch 139/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.900348/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.615686/1.134254\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.502927/1.535626\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8618214\n",
      "det: 0.054147404\n",
      "Validation loss mlp/pin: 0.940600/2.617977\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.828519\n",
      "det: 0.02650807\n",
      "Validation loss mlp/pin: 0.630339/1.182627\n",
      "###### N,i = 5,1 #####\n",
      "M: 829.8598\n",
      "det: 5.8834405e-07\n",
      "Validation loss mlp/pin: 1.472889/1.501574\n",
      "\n",
      "Epoch 140/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.894757/2.588998\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.614438/1.131778\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.502991/1.535963\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8675337\n",
      "det: 0.054396417\n",
      "Validation loss mlp/pin: 0.934992/2.617977\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.0908155\n",
      "det: 0.026497608\n",
      "Validation loss mlp/pin: 0.629067/1.180152\n",
      "###### N,i = 5,1 #####\n",
      "M: 953.56165\n",
      "det: 6.956546e-07\n",
      "Validation loss mlp/pin: 1.472778/1.503603\n",
      "\n",
      "Epoch 141/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.889299/2.588997\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.613245/1.129450\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.502662/1.535687\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8731346\n",
      "det: 0.05464158\n",
      "Validation loss mlp/pin: 0.929506/2.617976\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.639497\n",
      "det: 0.026481507\n",
      "Validation loss mlp/pin: 0.627830/1.177711\n",
      "###### N,i = 5,1 #####\n",
      "M: 870.7954\n",
      "det: 8.089649e-07\n",
      "Validation loss mlp/pin: 1.472735/1.502023\n",
      "\n",
      "Epoch 142/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.883954/2.588993\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.612003/1.127165\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.502766/1.535327\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.878425\n",
      "det: 0.05487391\n",
      "Validation loss mlp/pin: 0.924142/2.617976\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.5955\n",
      "det: 0.026470412\n",
      "Validation loss mlp/pin: 0.626566/1.175350\n",
      "###### N,i = 5,1 #####\n",
      "M: 1229.3848\n",
      "det: 9.3065154e-07\n",
      "Validation loss mlp/pin: 1.472610/1.502945\n",
      "\n",
      "Epoch 143/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.878724/2.588994\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.610831/1.124945\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.502677/1.536224\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8837702\n",
      "det: 0.05510967\n",
      "Validation loss mlp/pin: 0.918890/2.617975\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.768385\n",
      "det: 0.026462672\n",
      "Validation loss mlp/pin: 0.625286/1.172972\n",
      "###### N,i = 5,1 #####\n",
      "M: 1074.4231\n",
      "det: 1.0585068e-06\n",
      "Validation loss mlp/pin: 1.472615/1.503761\n",
      "\n",
      "Epoch 144/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.873623/2.588998\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.609618/1.122760\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.502709/1.537332\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.889097\n",
      "det: 0.05534519\n",
      "Validation loss mlp/pin: 0.913749/2.617975\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.989334\n",
      "det: 0.026447905\n",
      "Validation loss mlp/pin: 0.624049/1.170719\n",
      "###### N,i = 5,1 #####\n",
      "M: 618.6841\n",
      "det: 1.2033079e-06\n",
      "Validation loss mlp/pin: 1.472530/1.501667\n",
      "\n",
      "Epoch 145/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.868611/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.608446/1.120556\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.502590/1.536571\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8941522\n",
      "det: 0.055570442\n",
      "Validation loss mlp/pin: 0.908722/2.617975\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.655724\n",
      "det: 0.026421828\n",
      "Validation loss mlp/pin: 0.622880/1.168615\n",
      "###### N,i = 5,1 #####\n",
      "M: 415.88995\n",
      "det: 1.3598394e-06\n",
      "Validation loss mlp/pin: 1.472451/1.502386\n",
      "\n",
      "Epoch 146/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.863720/2.588995\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.607246/1.118459\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.502276/1.535351\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.8991437\n",
      "det: 0.055793982\n",
      "Validation loss mlp/pin: 0.903801/2.617975\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.481113\n",
      "det: 0.026413754\n",
      "Validation loss mlp/pin: 0.621606/1.166379\n",
      "###### N,i = 5,1 #####\n",
      "M: 457.33014\n",
      "det: 1.5174815e-06\n",
      "Validation loss mlp/pin: 1.472333/1.501641\n",
      "\n",
      "Epoch 147/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.858928/2.588996\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.606049/1.116359\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.502180/1.535469\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9042592\n",
      "det: 0.056023687\n",
      "Validation loss mlp/pin: 0.898981/2.617975\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.886341\n",
      "det: 0.026403146\n",
      "Validation loss mlp/pin: 0.620352/1.164183\n",
      "###### N,i = 5,1 #####\n",
      "M: 861.13983\n",
      "det: 1.6758338e-06\n",
      "Validation loss mlp/pin: 1.472259/1.501755\n",
      "\n",
      "Epoch 148/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.854244/2.588993\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.604947/1.114400\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.502120/1.535025\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9088361\n",
      "det: 0.056230377\n",
      "Validation loss mlp/pin: 0.894268/2.617975\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.366289\n",
      "det: 0.02639144\n",
      "Validation loss mlp/pin: 0.619115/1.162038\n",
      "###### N,i = 5,1 #####\n",
      "M: 607.08514\n",
      "det: 1.8482054e-06\n",
      "Validation loss mlp/pin: 1.472208/1.502846\n",
      "\n",
      "Epoch 149/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.849669/2.588994\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.603742/1.112373\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.501936/1.534970\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9133558\n",
      "det: 0.056435425\n",
      "Validation loss mlp/pin: 0.889653/2.617975\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.567557\n",
      "det: 0.026358211\n",
      "Validation loss mlp/pin: 0.617989/1.160086\n",
      "###### N,i = 5,1 #####\n",
      "M: 488.79486\n",
      "det: 2.0336317e-06\n",
      "Validation loss mlp/pin: 1.472267/1.503341\n",
      "\n",
      "Epoch 150/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.845169/2.588995\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.602598/1.110372\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.501886/1.535612\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9185681\n",
      "det: 0.0566718\n",
      "Validation loss mlp/pin: 0.885129/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.3883095\n",
      "det: 0.026347734\n",
      "Validation loss mlp/pin: 0.616756/1.158041\n",
      "###### N,i = 5,1 #####\n",
      "M: 459.49173\n",
      "det: 2.224259e-06\n",
      "Validation loss mlp/pin: 1.472078/1.501539\n",
      "\n",
      "Epoch 151/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.840777/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.601447/1.108481\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.501884/1.535554\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9231858\n",
      "det: 0.056883197\n",
      "Validation loss mlp/pin: 0.880705/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.221076\n",
      "det: 0.026328737\n",
      "Validation loss mlp/pin: 0.615574/1.156034\n",
      "###### N,i = 5,1 #####\n",
      "M: 432.1674\n",
      "det: 2.41699e-06\n",
      "Validation loss mlp/pin: 1.471922/1.501648\n",
      "\n",
      "Epoch 152/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.836480/2.588999\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.600345/1.106574\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.501722/1.535682\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9274588\n",
      "det: 0.057079952\n",
      "Validation loss mlp/pin: 0.876373/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.461481\n",
      "det: 0.026300622\n",
      "Validation loss mlp/pin: 0.614434/1.154083\n",
      "###### N,i = 5,1 #####\n",
      "M: 352.4253\n",
      "det: 2.6078208e-06\n",
      "Validation loss mlp/pin: 1.471907/1.501752\n",
      "\n",
      "Epoch 153/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.832268/2.588994\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.599277/1.104794\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.501544/1.534673\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.931889\n",
      "det: 0.057284184\n",
      "Validation loss mlp/pin: 0.872130/2.617971\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.757971\n",
      "det: 0.026290964\n",
      "Validation loss mlp/pin: 0.613223/1.152213\n",
      "###### N,i = 5,1 #####\n",
      "M: 445.18292\n",
      "det: 2.8160491e-06\n",
      "Validation loss mlp/pin: 1.471933/1.502572\n",
      "\n",
      "Epoch 154/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.828152/2.588993\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.598157/1.102942\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.501512/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.936199\n",
      "det: 0.05748388\n",
      "Validation loss mlp/pin: 0.867974/2.617971\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.081855\n",
      "det: 0.026262648\n",
      "Validation loss mlp/pin: 0.612088/1.150359\n",
      "###### N,i = 5,1 #####\n",
      "M: 377.86044\n",
      "det: 3.0352444e-06\n",
      "Validation loss mlp/pin: 1.471740/1.501535\n",
      "\n",
      "Epoch 155/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.824113/2.588997\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.597027/1.101150\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.501471/1.535361\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9401898\n",
      "det: 0.05767045\n",
      "Validation loss mlp/pin: 0.863904/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.867931\n",
      "det: 0.026236339\n",
      "Validation loss mlp/pin: 0.610949/1.148516\n",
      "###### N,i = 5,1 #####\n",
      "M: 382.4917\n",
      "det: 3.2491469e-06\n",
      "Validation loss mlp/pin: 1.471685/1.501646\n",
      "\n",
      "Epoch 156/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.820174/2.589000\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.595939/1.099438\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.501474/1.535594\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9442906\n",
      "det: 0.057862554\n",
      "Validation loss mlp/pin: 0.859916/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.117022\n",
      "det: 0.02620775\n",
      "Validation loss mlp/pin: 0.609831/1.146709\n",
      "###### N,i = 5,1 #####\n",
      "M: 756.526\n",
      "det: 3.4810841e-06\n",
      "Validation loss mlp/pin: 1.471574/1.502712\n",
      "\n",
      "Epoch 157/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.816288/2.588995\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.594878/1.097715\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.501318/1.535910\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9483256\n",
      "det: 0.058052253\n",
      "Validation loss mlp/pin: 0.856009/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.171946\n",
      "det: 0.026179178\n",
      "Validation loss mlp/pin: 0.608730/1.145008\n",
      "###### N,i = 5,1 #####\n",
      "M: 262.9845\n",
      "det: 3.705122e-06\n",
      "Validation loss mlp/pin: 1.471537/1.502106\n",
      "\n",
      "Epoch 158/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.812492/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.593792/1.096080\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.501260/1.535091\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9523015\n",
      "det: 0.058239777\n",
      "Validation loss mlp/pin: 0.852181/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.728683\n",
      "det: 0.026159\n",
      "Validation loss mlp/pin: 0.607588/1.143193\n",
      "###### N,i = 5,1 #####\n",
      "M: 712.5547\n",
      "det: 3.943342e-06\n",
      "Validation loss mlp/pin: 1.471415/1.502899\n",
      "\n",
      "Epoch 159/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.808774/2.589005\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.592741/1.094398\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.501371/1.536872\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9561563\n",
      "det: 0.05842251\n",
      "Validation loss mlp/pin: 0.848428/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.904937\n",
      "det: 0.026130494\n",
      "Validation loss mlp/pin: 0.606498/1.141500\n",
      "###### N,i = 5,1 #####\n",
      "M: 373.71878\n",
      "det: 4.1928533e-06\n",
      "Validation loss mlp/pin: 1.471337/1.502715\n",
      "\n",
      "Epoch 160/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.805134/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.591649/1.092815\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.501092/1.535531\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9599347\n",
      "det: 0.058602344\n",
      "Validation loss mlp/pin: 0.844749/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.328963\n",
      "det: 0.026109489\n",
      "Validation loss mlp/pin: 0.605377/1.139795\n",
      "###### N,i = 5,1 #####\n",
      "M: 266.5294\n",
      "det: 4.4163985e-06\n",
      "Validation loss mlp/pin: 1.471327/1.502263\n",
      "\n",
      "Epoch 161/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.801579/2.588998\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.590531/1.091189\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.501018/1.535504\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9634218\n",
      "det: 0.058769844\n",
      "Validation loss mlp/pin: 0.841144/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.319069\n",
      "det: 0.026081456\n",
      "Validation loss mlp/pin: 0.604291/1.138194\n",
      "###### N,i = 5,1 #####\n",
      "M: 290.4027\n",
      "det: 4.669311e-06\n",
      "Validation loss mlp/pin: 1.471357/1.503769\n",
      "\n",
      "Epoch 162/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.798065/2.588995\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.589501/1.089626\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500811/1.535174\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9670653\n",
      "det: 0.058944628\n",
      "Validation loss mlp/pin: 0.837610/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.550741\n",
      "det: 0.026050508\n",
      "Validation loss mlp/pin: 0.603230/1.136622\n",
      "###### N,i = 5,1 #####\n",
      "M: 305.6117\n",
      "det: 4.9286537e-06\n",
      "Validation loss mlp/pin: 1.471210/1.501542\n",
      "\n",
      "Epoch 163/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.794648/2.588996\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.588466/1.088124\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500811/1.535422\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.970662\n",
      "det: 0.05911802\n",
      "Validation loss mlp/pin: 0.834145/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.554188\n",
      "det: 0.02602365\n",
      "Validation loss mlp/pin: 0.602141/1.135014\n",
      "###### N,i = 5,1 #####\n",
      "M: 268.34647\n",
      "det: 5.1860243e-06\n",
      "Validation loss mlp/pin: 1.471163/1.501727\n",
      "\n",
      "Epoch 164/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.791276/2.588997\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.587370/1.086580\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500872/1.535967\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9741402\n",
      "det: 0.059286572\n",
      "Validation loss mlp/pin: 0.830746/2.617971\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.188758\n",
      "det: 0.025990302\n",
      "Validation loss mlp/pin: 0.601098/1.133437\n",
      "###### N,i = 5,1 #####\n",
      "M: 559.4799\n",
      "det: 5.455358e-06\n",
      "Validation loss mlp/pin: 1.471054/1.501606\n",
      "\n",
      "Epoch 165/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.787980/2.588997\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.586289/1.085084\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500620/1.535239\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9775372\n",
      "det: 0.059452184\n",
      "Validation loss mlp/pin: 0.827414/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.764551\n",
      "det: 0.025970073\n",
      "Validation loss mlp/pin: 0.599978/1.131872\n",
      "###### N,i = 5,1 #####\n",
      "M: 159.33765\n",
      "det: 5.712608e-06\n",
      "Validation loss mlp/pin: 1.471029/1.501885\n",
      "\n",
      "Epoch 166/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.784757/2.589000\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.585268/1.083686\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500512/1.535186\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9808795\n",
      "det: 0.05961583\n",
      "Validation loss mlp/pin: 0.824148/2.617971\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.0458364\n",
      "det: 0.025941651\n",
      "Validation loss mlp/pin: 0.598916/1.130383\n",
      "###### N,i = 5,1 #####\n",
      "M: 652.5648\n",
      "det: 5.9835543e-06\n",
      "Validation loss mlp/pin: 1.470937/1.501558\n",
      "\n",
      "Epoch 167/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.781581/2.588998\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.584148/1.082229\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500623/1.535840\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9842381\n",
      "det: 0.059780437\n",
      "Validation loss mlp/pin: 0.820943/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.999674\n",
      "det: 0.02591718\n",
      "Validation loss mlp/pin: 0.597837/1.128869\n",
      "###### N,i = 5,1 #####\n",
      "M: 391.4895\n",
      "det: 6.2469453e-06\n",
      "Validation loss mlp/pin: 1.470926/1.501806\n",
      "\n",
      "Epoch 168/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.778475/2.588993\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.583088/1.080791\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500488/1.535454\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9872894\n",
      "det: 0.05993183\n",
      "Validation loss mlp/pin: 0.817800/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.034142\n",
      "det: 0.025889141\n",
      "Validation loss mlp/pin: 0.596789/1.127453\n",
      "###### N,i = 5,1 #####\n",
      "M: 264.3175\n",
      "det: 6.5238455e-06\n",
      "Validation loss mlp/pin: 1.470782/1.501558\n",
      "\n",
      "Epoch 169/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.775435/2.589000\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.582076/1.079460\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500329/1.534900\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9904213\n",
      "det: 0.060087096\n",
      "Validation loss mlp/pin: 0.814715/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.50032\n",
      "det: 0.025866307\n",
      "Validation loss mlp/pin: 0.595712/1.125977\n",
      "###### N,i = 5,1 #####\n",
      "M: 331.9813\n",
      "det: 6.806586e-06\n",
      "Validation loss mlp/pin: 1.470683/1.502677\n",
      "\n",
      "Epoch 170/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.772440/2.588997\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.581038/1.078058\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500400/1.536395\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9933014\n",
      "det: 0.06023155\n",
      "Validation loss mlp/pin: 0.811688/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.489519\n",
      "det: 0.02583519\n",
      "Validation loss mlp/pin: 0.594690/1.124617\n",
      "###### N,i = 5,1 #####\n",
      "M: 487.13617\n",
      "det: 7.076606e-06\n",
      "Validation loss mlp/pin: 1.470625/1.501642\n",
      "\n",
      "Epoch 171/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.769505/2.588997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.579988/1.076719\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500153/1.535161\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9964595\n",
      "det: 0.0603891\n",
      "Validation loss mlp/pin: 0.808716/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.095703\n",
      "det: 0.025805073\n",
      "Validation loss mlp/pin: 0.593665/1.123251\n",
      "###### N,i = 5,1 #####\n",
      "M: 330.4647\n",
      "det: 7.3554706e-06\n",
      "Validation loss mlp/pin: 1.470589/1.501789\n",
      "\n",
      "Epoch 172/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.766620/2.588997\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.578946/1.075388\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500179/1.535040\n",
      "###### N,i = 3,1 #####\n",
      "M: 3.9992156\n",
      "det: 0.060528938\n",
      "Validation loss mlp/pin: 0.805802/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.212589\n",
      "det: 0.025777174\n",
      "Validation loss mlp/pin: 0.592632/1.121858\n",
      "###### N,i = 5,1 #####\n",
      "M: 395.10443\n",
      "det: 7.624477e-06\n",
      "Validation loss mlp/pin: 1.470626/1.503216\n",
      "\n",
      "Epoch 173/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.763792/2.588996\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.577912/1.074123\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500059/1.535288\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.002114\n",
      "det: 0.060675688\n",
      "Validation loss mlp/pin: 0.802941/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.8265915\n",
      "det: 0.025746327\n",
      "Validation loss mlp/pin: 0.591626/1.120543\n",
      "###### N,i = 5,1 #####\n",
      "M: 494.9165\n",
      "det: 7.924072e-06\n",
      "Validation loss mlp/pin: 1.470537/1.501981\n",
      "\n",
      "Epoch 174/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.761020/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.576943/1.072814\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500194/1.536322\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0048785\n",
      "det: 0.06081672\n",
      "Validation loss mlp/pin: 0.800134/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.428597\n",
      "det: 0.025724558\n",
      "Validation loss mlp/pin: 0.590573/1.119189\n",
      "###### N,i = 5,1 #####\n",
      "M: 522.95374\n",
      "det: 8.206673e-06\n",
      "Validation loss mlp/pin: 1.470494/1.501811\n",
      "\n",
      "Epoch 175/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.758300/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.575902/1.071585\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.500086/1.536017\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.007745\n",
      "det: 0.06096253\n",
      "Validation loss mlp/pin: 0.797380/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.198711\n",
      "det: 0.025695128\n",
      "Validation loss mlp/pin: 0.589586/1.117934\n",
      "###### N,i = 5,1 #####\n",
      "M: 411.11835\n",
      "det: 8.494751e-06\n",
      "Validation loss mlp/pin: 1.470434/1.502268\n",
      "\n",
      "Epoch 176/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.755633/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.574930/1.070408\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.499948/1.535640\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0106196\n",
      "det: 0.06110916\n",
      "Validation loss mlp/pin: 0.794677/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.47617\n",
      "det: 0.025671557\n",
      "Validation loss mlp/pin: 0.588568/1.116632\n",
      "###### N,i = 5,1 #####\n",
      "M: 138.51178\n",
      "det: 8.792414e-06\n",
      "Validation loss mlp/pin: 1.470342/1.501842\n",
      "\n",
      "Epoch 177/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.753023/2.588995\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.573978/1.069160\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.499882/1.535688\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.013407\n",
      "det: 0.061252303\n",
      "Validation loss mlp/pin: 0.792024/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.646438\n",
      "det: 0.025644798\n",
      "Validation loss mlp/pin: 0.587582/1.115391\n",
      "###### N,i = 5,1 #####\n",
      "M: 349.81714\n",
      "det: 9.082705e-06\n",
      "Validation loss mlp/pin: 1.470235/1.501546\n",
      "\n",
      "Epoch 178/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.750446/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.572918/1.067963\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.499703/1.535219\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.016078\n",
      "det: 0.061390474\n",
      "Validation loss mlp/pin: 0.789419/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.61871\n",
      "det: 0.025616616\n",
      "Validation loss mlp/pin: 0.586616/1.114202\n",
      "###### N,i = 5,1 #####\n",
      "M: 180.35318\n",
      "det: 9.375566e-06\n",
      "Validation loss mlp/pin: 1.470179/1.501772\n",
      "\n",
      "Epoch 179/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.747925/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.571968/1.066807\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.499602/1.535135\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0185714\n",
      "det: 0.061520845\n",
      "Validation loss mlp/pin: 0.786861/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.339586\n",
      "det: 0.025593294\n",
      "Validation loss mlp/pin: 0.585630/1.112980\n",
      "###### N,i = 5,1 #####\n",
      "M: 273.59375\n",
      "det: 9.669745e-06\n",
      "Validation loss mlp/pin: 1.470125/1.501582\n",
      "\n",
      "Epoch 180/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.745462/2.589003\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.571017/1.065645\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.499518/1.535032\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.021248\n",
      "det: 0.061659835\n",
      "Validation loss mlp/pin: 0.784350/2.617968\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.055941\n",
      "det: 0.02556922\n",
      "Validation loss mlp/pin: 0.584661/1.111757\n",
      "###### N,i = 5,1 #####\n",
      "M: 227.02628\n",
      "det: 9.965823e-06\n",
      "Validation loss mlp/pin: 1.470058/1.501547\n",
      "\n",
      "Epoch 181/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.743022/2.588993\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.570065/1.064501\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.499645/1.535964\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0236225\n",
      "det: 0.061785553\n",
      "Validation loss mlp/pin: 0.781883/2.617968\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.953753\n",
      "det: 0.025542483\n",
      "Validation loss mlp/pin: 0.583716/1.110582\n",
      "###### N,i = 5,1 #####\n",
      "M: 336.0699\n",
      "det: 1.0265934e-05\n",
      "Validation loss mlp/pin: 1.470027/1.502457\n",
      "\n",
      "Epoch 182/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.740642/2.588996\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.569086/1.063419\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.499391/1.535192\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.026125\n",
      "det: 0.061917253\n",
      "Validation loss mlp/pin: 0.779461/2.617968\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.710331\n",
      "det: 0.025514144\n",
      "Validation loss mlp/pin: 0.582784/1.109482\n",
      "###### N,i = 5,1 #####\n",
      "M: 157.42932\n",
      "det: 1.056483e-05\n",
      "Validation loss mlp/pin: 1.469974/1.501690\n",
      "\n",
      "Epoch 183/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.738294/2.588993\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.568163/1.062347\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.499358/1.535326\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0284934\n",
      "det: 0.06204304\n",
      "Validation loss mlp/pin: 0.777081/2.617968\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.299255\n",
      "det: 0.025487488\n",
      "Validation loss mlp/pin: 0.581852/1.108321\n",
      "###### N,i = 5,1 #####\n",
      "M: 208.06807\n",
      "det: 1.0856275e-05\n",
      "Validation loss mlp/pin: 1.469908/1.501544\n",
      "\n",
      "Epoch 184/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.735997/2.589001\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.567273/1.061255\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.499315/1.535396\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.030945\n",
      "det: 0.06217262\n",
      "Validation loss mlp/pin: 0.774744/2.617967\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.755433\n",
      "det: 0.025465904\n",
      "Validation loss mlp/pin: 0.580904/1.107213\n",
      "###### N,i = 5,1 #####\n",
      "M: 306.975\n",
      "det: 1.1166763e-05\n",
      "Validation loss mlp/pin: 1.469836/1.501590\n",
      "\n",
      "Epoch 185/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.733731/2.588993\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.566318/1.060208\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.499258/1.535381\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0331926\n",
      "det: 0.06229316\n",
      "Validation loss mlp/pin: 0.772446/2.617967\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.300943\n",
      "det: 0.025433633\n",
      "Validation loss mlp/pin: 0.580032/1.106180\n",
      "###### N,i = 5,1 #####\n",
      "M: 345.04782\n",
      "det: 1.1481525e-05\n",
      "Validation loss mlp/pin: 1.469793/1.501543\n",
      "\n",
      "Epoch 186/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.731509/2.588998\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.565400/1.059154\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.499185/1.535188\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0353475\n",
      "det: 0.062409546\n",
      "Validation loss mlp/pin: 0.770188/2.617968\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.1989775\n",
      "det: 0.025407521\n",
      "Validation loss mlp/pin: 0.579124/1.105129\n",
      "###### N,i = 5,1 #####\n",
      "M: 204.88554\n",
      "det: 1.1805667e-05\n",
      "Validation loss mlp/pin: 1.469767/1.502309\n",
      "\n",
      "Epoch 187/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.729327/2.588994\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.564522/1.058131\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.499095/1.535305\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0375957\n",
      "det: 0.06253058\n",
      "Validation loss mlp/pin: 0.767972/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.993561\n",
      "det: 0.025380384\n",
      "Validation loss mlp/pin: 0.578237/1.104017\n",
      "###### N,i = 5,1 #####\n",
      "M: 179.9652\n",
      "det: 1.2149328e-05\n",
      "Validation loss mlp/pin: 1.469700/1.501880\n",
      "\n",
      "Epoch 188/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.727184/2.588997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.563617/1.057134\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.499241/1.536016\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.039736\n",
      "det: 0.06264703\n",
      "Validation loss mlp/pin: 0.765794/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.611742\n",
      "det: 0.025356961\n",
      "Validation loss mlp/pin: 0.577330/1.102971\n",
      "###### N,i = 5,1 #####\n",
      "M: 339.60547\n",
      "det: 1.2490466e-05\n",
      "Validation loss mlp/pin: 1.469619/1.501658\n",
      "\n",
      "Epoch 189/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.725080/2.588995\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.562693/1.056123\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498939/1.534747\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.041958\n",
      "det: 0.06276722\n",
      "Validation loss mlp/pin: 0.763656/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.279987\n",
      "det: 0.025330102\n",
      "Validation loss mlp/pin: 0.576456/1.101945\n",
      "###### N,i = 5,1 #####\n",
      "M: 125.31147\n",
      "det: 1.2826674e-05\n",
      "Validation loss mlp/pin: 1.469616/1.502620\n",
      "\n",
      "Epoch 190/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.723012/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.561833/1.055208\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498847/1.534887\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.044103\n",
      "det: 0.06288404\n",
      "Validation loss mlp/pin: 0.761554/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.644545\n",
      "det: 0.02530424\n",
      "Validation loss mlp/pin: 0.575587/1.100985\n",
      "###### N,i = 5,1 #####\n",
      "M: 153.89911\n",
      "det: 1.317672e-05\n",
      "Validation loss mlp/pin: 1.469530/1.501567\n",
      "\n",
      "Epoch 191/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.720979/2.588993\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.560981/1.054241\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498851/1.535274\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0462184\n",
      "det: 0.062999696\n",
      "Validation loss mlp/pin: 0.759488/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.554687\n",
      "det: 0.025275458\n",
      "Validation loss mlp/pin: 0.574751/1.099982\n",
      "###### N,i = 5,1 #####\n",
      "M: 409.31342\n",
      "det: 1.3504408e-05\n",
      "Validation loss mlp/pin: 1.469479/1.501651\n",
      "\n",
      "Epoch 192/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.718995/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.560099/1.053301\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498745/1.535065\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0483327\n",
      "det: 0.0631156\n",
      "Validation loss mlp/pin: 0.757458/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.712406\n",
      "det: 0.025250817\n",
      "Validation loss mlp/pin: 0.573889/1.098958\n",
      "###### N,i = 5,1 #####\n",
      "M: 236.0344\n",
      "det: 1.3862439e-05\n",
      "Validation loss mlp/pin: 1.469416/1.501565\n",
      "\n",
      "Epoch 193/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.717020/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.559238/1.052363\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498800/1.535564\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.050312\n",
      "det: 0.06322547\n",
      "Validation loss mlp/pin: 0.755462/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.420704\n",
      "det: 0.025225308\n",
      "Validation loss mlp/pin: 0.573039/1.098015\n",
      "###### N,i = 5,1 #####\n",
      "M: 209.55032\n",
      "det: 1.4201526e-05\n",
      "Validation loss mlp/pin: 1.469365/1.501602\n",
      "\n",
      "Epoch 194/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.715090/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.558414/1.051440\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498753/1.535557\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0523605\n",
      "det: 0.06333863\n",
      "Validation loss mlp/pin: 0.753500/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.066521\n",
      "det: 0.025196493\n",
      "Validation loss mlp/pin: 0.572217/1.097058\n",
      "###### N,i = 5,1 #####\n",
      "M: 300.3695\n",
      "det: 1.4543021e-05\n",
      "Validation loss mlp/pin: 1.469290/1.501567\n",
      "\n",
      "Epoch 195/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.713201/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.557570/1.050555\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498613/1.535245\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.054366\n",
      "det: 0.06345009\n",
      "Validation loss mlp/pin: 0.751572/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.14892\n",
      "det: 0.025169842\n",
      "Validation loss mlp/pin: 0.571395/1.096101\n",
      "###### N,i = 5,1 #####\n",
      "M: 199.1665\n",
      "det: 1.4892358e-05\n",
      "Validation loss mlp/pin: 1.469244/1.501614\n",
      "\n",
      "Epoch 196/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.711336/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.556785/1.049679\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498622/1.534876\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0562205\n",
      "det: 0.06355456\n",
      "Validation loss mlp/pin: 0.749674/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.725952\n",
      "det: 0.025144113\n",
      "Validation loss mlp/pin: 0.570574/1.095231\n",
      "###### N,i = 5,1 #####\n",
      "M: 281.9265\n",
      "det: 1.5225724e-05\n",
      "Validation loss mlp/pin: 1.469273/1.503554\n",
      "\n",
      "Epoch 197/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.709499/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.555920/1.048788\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498493/1.535389\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0579777\n",
      "det: 0.06365491\n",
      "Validation loss mlp/pin: 0.747808/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.57722\n",
      "det: 0.025120605\n",
      "Validation loss mlp/pin: 0.569743/1.094322\n",
      "###### N,i = 5,1 #####\n",
      "M: 335.05142\n",
      "det: 1.5588386e-05\n",
      "Validation loss mlp/pin: 1.469221/1.502242\n",
      "\n",
      "Epoch 198/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.707698/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.555157/1.047984\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498495/1.535178\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.05977\n",
      "det: 0.06375689\n",
      "Validation loss mlp/pin: 0.745974/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.0838757\n",
      "det: 0.025096187\n",
      "Validation loss mlp/pin: 0.568928/1.093394\n",
      "###### N,i = 5,1 #####\n",
      "M: 190.17972\n",
      "det: 1.5934973e-05\n",
      "Validation loss mlp/pin: 1.469101/1.501953\n",
      "\n",
      "Epoch 199/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.705925/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.554348/1.047122\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498383/1.535166\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.061523\n",
      "det: 0.06385708\n",
      "Validation loss mlp/pin: 0.744169/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.8333116\n",
      "det: 0.025070954\n",
      "Validation loss mlp/pin: 0.568126/1.092539\n",
      "###### N,i = 5,1 #####\n",
      "M: 192.84183\n",
      "det: 1.6276565e-05\n",
      "Validation loss mlp/pin: 1.469082/1.501937\n",
      "\n",
      "Epoch 200/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.704181/2.588996\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.553533/1.046276\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498392/1.535525\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.063245\n",
      "det: 0.063955754\n",
      "Validation loss mlp/pin: 0.742394/2.617968\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.528582\n",
      "det: 0.025043203\n",
      "Validation loss mlp/pin: 0.567354/1.091674\n",
      "###### N,i = 5,1 #####\n",
      "M: 264.69302\n",
      "det: 1.6621532e-05\n",
      "Validation loss mlp/pin: 1.469050/1.502039\n",
      "\n",
      "Epoch 201/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.702462/2.588996\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.552860/1.045473\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498288/1.535279\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.064928\n",
      "det: 0.06405263\n",
      "Validation loss mlp/pin: 0.740648/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.006767\n",
      "det: 0.025015919\n",
      "Validation loss mlp/pin: 0.566580/1.090800\n",
      "###### N,i = 5,1 #####\n",
      "M: 215.98796\n",
      "det: 1.6980008e-05\n",
      "Validation loss mlp/pin: 1.468964/1.501545\n",
      "\n",
      "Epoch 202/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.700780/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.552015/1.044629\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498194/1.535189\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0665836\n",
      "det: 0.06414816\n",
      "Validation loss mlp/pin: 0.738931/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.554431\n",
      "det: 0.024995321\n",
      "Validation loss mlp/pin: 0.565772/1.089974\n",
      "###### N,i = 5,1 #####\n",
      "M: 145.68466\n",
      "det: 1.733066e-05\n",
      "Validation loss mlp/pin: 1.468919/1.501697\n",
      "\n",
      "Epoch 203/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.699116/2.588993\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.551209/1.043835\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498173/1.535384\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.068242\n",
      "det: 0.064243525\n",
      "Validation loss mlp/pin: 0.737242/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.23477\n",
      "det: 0.024968328\n",
      "Validation loss mlp/pin: 0.565010/1.089128\n",
      "###### N,i = 5,1 #####\n",
      "M: 73.99524\n",
      "det: 1.7679413e-05\n",
      "Validation loss mlp/pin: 1.468865/1.501558\n",
      "\n",
      "Epoch 204/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.697490/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.550483/1.043066\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498096/1.535117\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.069942\n",
      "det: 0.06434115\n",
      "Validation loss mlp/pin: 0.735580/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.282084\n",
      "det: 0.024943309\n",
      "Validation loss mlp/pin: 0.564242/1.088332\n",
      "###### N,i = 5,1 #####\n",
      "M: 129.55685\n",
      "det: 1.804745e-05\n",
      "Validation loss mlp/pin: 1.468798/1.501571\n",
      "\n",
      "Epoch 205/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.695885/2.588993\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.549706/1.042262\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.498029/1.534851\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.071663\n",
      "det: 0.06443945\n",
      "Validation loss mlp/pin: 0.733947/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.759811\n",
      "det: 0.024917781\n",
      "Validation loss mlp/pin: 0.563484/1.087534\n",
      "###### N,i = 5,1 #####\n",
      "M: 116.06593\n",
      "det: 1.841338e-05\n",
      "Validation loss mlp/pin: 1.468734/1.501721\n",
      "\n",
      "Epoch 206/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.694304/2.588997\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.548974/1.041519\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497967/1.535035\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0732317\n",
      "det: 0.06453111\n",
      "Validation loss mlp/pin: 0.732339/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.015419\n",
      "det: 0.024888065\n",
      "Validation loss mlp/pin: 0.562755/1.086758\n",
      "###### N,i = 5,1 #####\n",
      "M: 286.48483\n",
      "det: 1.8764815e-05\n",
      "Validation loss mlp/pin: 1.468680/1.501744\n",
      "\n",
      "Epoch 207/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.692747/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.548189/1.040744\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497895/1.535072\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.074829\n",
      "det: 0.06462372\n",
      "Validation loss mlp/pin: 0.730758/2.617969\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.594407\n",
      "det: 0.02486208\n",
      "Validation loss mlp/pin: 0.562008/1.085967\n",
      "###### N,i = 5,1 #####\n",
      "M: 172.65599\n",
      "det: 1.9123274e-05\n",
      "Validation loss mlp/pin: 1.468641/1.501550\n",
      "\n",
      "Epoch 208/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.691216/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.547457/1.039998\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497870/1.535095\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0763493\n",
      "det: 0.06471299\n",
      "Validation loss mlp/pin: 0.729201/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.9053335\n",
      "det: 0.024836048\n",
      "Validation loss mlp/pin: 0.561264/1.085198\n",
      "###### N,i = 5,1 #####\n",
      "M: 179.59482\n",
      "det: 1.9488434e-05\n",
      "Validation loss mlp/pin: 1.468607/1.501547\n",
      "\n",
      "Epoch 209/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.689710/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.546717/1.039303\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497795/1.535053\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0778275\n",
      "det: 0.0648003\n",
      "Validation loss mlp/pin: 0.727669/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.917955\n",
      "det: 0.024810962\n",
      "Validation loss mlp/pin: 0.560525/1.084437\n",
      "###### N,i = 5,1 #####\n",
      "M: 182.48055\n",
      "det: 1.9844045e-05\n",
      "Validation loss mlp/pin: 1.468575/1.501633\n",
      "\n",
      "Epoch 210/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.688234/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.546024/1.038567\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497936/1.535662\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.079312\n",
      "det: 0.064887986\n",
      "Validation loss mlp/pin: 0.726161/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.113419\n",
      "det: 0.024784008\n",
      "Validation loss mlp/pin: 0.559806/1.083679\n",
      "###### N,i = 5,1 #####\n",
      "M: 266.043\n",
      "det: 2.0205454e-05\n",
      "Validation loss mlp/pin: 1.468551/1.501909\n",
      "\n",
      "Epoch 211/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.686775/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.545281/1.037836\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497680/1.534883\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.080737\n",
      "det: 0.06497302\n",
      "Validation loss mlp/pin: 0.724679/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.943312\n",
      "det: 0.024757454\n",
      "Validation loss mlp/pin: 0.559092/1.082963\n",
      "###### N,i = 5,1 #####\n",
      "M: 236.04903\n",
      "det: 2.0568492e-05\n",
      "Validation loss mlp/pin: 1.468511/1.501936\n",
      "\n",
      "Epoch 212/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.685346/2.588993\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.544564/1.037143\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497660/1.534661\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.082091\n",
      "det: 0.06505471\n",
      "Validation loss mlp/pin: 0.723218/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.626088\n",
      "det: 0.024732573\n",
      "Validation loss mlp/pin: 0.558376/1.082246\n",
      "###### N,i = 5,1 #####\n",
      "M: 345.82022\n",
      "det: 2.0932135e-05\n",
      "Validation loss mlp/pin: 1.468425/1.501836\n",
      "\n",
      "Epoch 213/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.683931/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.543850/1.036453\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497664/1.535553\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0834246\n",
      "det: 0.06513557\n",
      "Validation loss mlp/pin: 0.721779/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.970955\n",
      "det: 0.024710497\n",
      "Validation loss mlp/pin: 0.557647/1.081499\n",
      "###### N,i = 5,1 #####\n",
      "M: 246.4745\n",
      "det: 2.1297788e-05\n",
      "Validation loss mlp/pin: 1.468384/1.501548\n",
      "\n",
      "Epoch 214/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.682544/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.543138/1.035777\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497576/1.535151\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0847416\n",
      "det: 0.065215744\n",
      "Validation loss mlp/pin: 0.720363/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.361874\n",
      "det: 0.024687022\n",
      "Validation loss mlp/pin: 0.556936/1.080794\n",
      "###### N,i = 5,1 #####\n",
      "M: 183.38641\n",
      "det: 2.1643205e-05\n",
      "Validation loss mlp/pin: 1.468357/1.501640\n",
      "\n",
      "Epoch 215/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.681171/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.542472/1.035083\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497640/1.535638\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.086112\n",
      "det: 0.06529814\n",
      "Validation loss mlp/pin: 0.718969/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.157101\n",
      "det: 0.024662416\n",
      "Validation loss mlp/pin: 0.556240/1.080099\n",
      "###### N,i = 5,1 #####\n",
      "M: 256.1896\n",
      "det: 2.2004928e-05\n",
      "Validation loss mlp/pin: 1.468328/1.501691\n",
      "\n",
      "Epoch 216/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.679822/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.541749/1.034425\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497558/1.535209\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0873575\n",
      "det: 0.06537478\n",
      "Validation loss mlp/pin: 0.717596/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.150347\n",
      "det: 0.024638563\n",
      "Validation loss mlp/pin: 0.555547/1.079410\n",
      "###### N,i = 5,1 #####\n",
      "M: 247.57738\n",
      "det: 2.235887e-05\n",
      "Validation loss mlp/pin: 1.468255/1.501716\n",
      "\n",
      "Epoch 217/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.678503/2.588994\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.541088/1.033774\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497382/1.535023\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.08864\n",
      "det: 0.06545286\n",
      "Validation loss mlp/pin: 0.716243/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.724545\n",
      "det: 0.024613328\n",
      "Validation loss mlp/pin: 0.554868/1.078725\n",
      "###### N,i = 5,1 #####\n",
      "M: 136.28003\n",
      "det: 2.2712957e-05\n",
      "Validation loss mlp/pin: 1.468210/1.501573\n",
      "\n",
      "Epoch 218/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.677193/2.588998\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.540390/1.033119\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497446/1.535491\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0899506\n",
      "det: 0.06553222\n",
      "Validation loss mlp/pin: 0.714912/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.41775\n",
      "det: 0.02458924\n",
      "Validation loss mlp/pin: 0.554192/1.078054\n",
      "###### N,i = 5,1 #####\n",
      "M: 139.26993\n",
      "det: 2.3055454e-05\n",
      "Validation loss mlp/pin: 1.468183/1.501556\n",
      "\n",
      "Epoch 219/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.675907/2.588995\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.539729/1.032503\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497331/1.535063\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.09123\n",
      "det: 0.065609984\n",
      "Validation loss mlp/pin: 0.713602/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.314707\n",
      "det: 0.024563888\n",
      "Validation loss mlp/pin: 0.553532/1.077413\n",
      "###### N,i = 5,1 #####\n",
      "M: 260.09628\n",
      "det: 2.3411065e-05\n",
      "Validation loss mlp/pin: 1.468153/1.501844\n",
      "\n",
      "Epoch 220/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.674638/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.539053/1.031929\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497263/1.534939\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.092453\n",
      "det: 0.065685146\n",
      "Validation loss mlp/pin: 0.712311/2.617970\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.210083\n",
      "det: 0.024539422\n",
      "Validation loss mlp/pin: 0.552870/1.076758\n",
      "###### N,i = 5,1 #####\n",
      "M: 135.70436\n",
      "det: 2.3762117e-05\n",
      "Validation loss mlp/pin: 1.468106/1.501561\n",
      "\n",
      "Epoch 221/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.673390/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.538433/1.031264\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497221/1.534998\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.093657\n",
      "det: 0.06575944\n",
      "Validation loss mlp/pin: 0.711040/2.617971\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.280609\n",
      "det: 0.024512807\n",
      "Validation loss mlp/pin: 0.552231/1.076141\n",
      "###### N,i = 5,1 #####\n",
      "M: 234.2913\n",
      "det: 2.4110917e-05\n",
      "Validation loss mlp/pin: 1.468076/1.501600\n",
      "\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.672168/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.537762/1.030651\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497166/1.534955\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.094789\n",
      "det: 0.06583043\n",
      "Validation loss mlp/pin: 0.709788/2.617971\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.643901\n",
      "det: 0.024492202\n",
      "Validation loss mlp/pin: 0.551560/1.075486\n",
      "###### N,i = 5,1 #####\n",
      "M: 240.14209\n",
      "det: 2.4467274e-05\n",
      "Validation loss mlp/pin: 1.468027/1.501548\n",
      "\n",
      "Epoch 223/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.670960/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.537127/1.030037\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497155/1.535145\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.095934\n",
      "det: 0.06590206\n",
      "Validation loss mlp/pin: 0.708555/2.617971\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.680573\n",
      "det: 0.024466936\n",
      "Validation loss mlp/pin: 0.550928/1.074874\n",
      "###### N,i = 5,1 #####\n",
      "M: 253.59268\n",
      "det: 2.4817662e-05\n",
      "Validation loss mlp/pin: 1.467985/1.501559\n",
      "\n",
      "Epoch 224/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.669765/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.536479/1.029427\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497115/1.534986\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.09716\n",
      "det: 0.06597753\n",
      "Validation loss mlp/pin: 0.707342/2.617971\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.774355\n",
      "det: 0.024443077\n",
      "Validation loss mlp/pin: 0.550291/1.074288\n",
      "###### N,i = 5,1 #####\n",
      "M: 149.00366\n",
      "det: 2.5157387e-05\n",
      "Validation loss mlp/pin: 1.467927/1.501640\n",
      "\n",
      "Epoch 225/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.668589/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.535896/1.028897\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497040/1.535090\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0983367\n",
      "det: 0.06605073\n",
      "Validation loss mlp/pin: 0.706147/2.617971\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.782095\n",
      "det: 0.024421033\n",
      "Validation loss mlp/pin: 0.549651/1.073642\n",
      "###### N,i = 5,1 #####\n",
      "M: 101.91713\n",
      "det: 2.5514259e-05\n",
      "Validation loss mlp/pin: 1.467892/1.501551\n",
      "\n",
      "Epoch 226/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.667437/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.535261/1.028270\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496973/1.534978\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.0994835\n",
      "det: 0.06612245\n",
      "Validation loss mlp/pin: 0.704969/2.617971\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.104569\n",
      "det: 0.024399893\n",
      "Validation loss mlp/pin: 0.549013/1.073037\n",
      "###### N,i = 5,1 #####\n",
      "M: 176.77641\n",
      "det: 2.5859665e-05\n",
      "Validation loss mlp/pin: 1.467863/1.501598\n",
      "\n",
      "Epoch 227/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.666302/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.534638/1.027709\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496977/1.535166\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1005516\n",
      "det: 0.066190556\n",
      "Validation loss mlp/pin: 0.703808/2.617971\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.805446\n",
      "det: 0.024377637\n",
      "Validation loss mlp/pin: 0.548390/1.072448\n",
      "###### N,i = 5,1 #####\n",
      "M: 319.72916\n",
      "det: 2.619594e-05\n",
      "Validation loss mlp/pin: 1.467827/1.501595\n",
      "\n",
      "Epoch 228/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.665182/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.534044/1.027143\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496915/1.535078\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1015925\n",
      "det: 0.06625739\n",
      "Validation loss mlp/pin: 0.702665/2.617971\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.883755\n",
      "det: 0.024354931\n",
      "Validation loss mlp/pin: 0.547777/1.071874\n",
      "###### N,i = 5,1 #####\n",
      "M: 137.17902\n",
      "det: 2.6538193e-05\n",
      "Validation loss mlp/pin: 1.467801/1.501678\n",
      "\n",
      "Epoch 229/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.664078/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.533449/1.026584\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.497028/1.535645\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.102682\n",
      "det: 0.06632634\n",
      "Validation loss mlp/pin: 0.701539/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.839684\n",
      "det: 0.024331117\n",
      "Validation loss mlp/pin: 0.547177/1.071281\n",
      "###### N,i = 5,1 #####\n",
      "M: 292.97687\n",
      "det: 2.686729e-05\n",
      "Validation loss mlp/pin: 1.467771/1.501884\n",
      "\n",
      "Epoch 230/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.662990/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.532864/1.026049\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496790/1.534913\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.103786\n",
      "det: 0.06639613\n",
      "Validation loss mlp/pin: 0.700430/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.393032\n",
      "det: 0.02431022\n",
      "Validation loss mlp/pin: 0.546569/1.070712\n",
      "###### N,i = 5,1 #####\n",
      "M: 208.90315\n",
      "det: 2.7199367e-05\n",
      "Validation loss mlp/pin: 1.467736/1.501606\n",
      "\n",
      "Epoch 231/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.661931/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.532257/1.025524\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496807/1.535149\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1047826\n",
      "det: 0.066460855\n",
      "Validation loss mlp/pin: 0.699335/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.445961\n",
      "det: 0.024288343\n",
      "Validation loss mlp/pin: 0.545974/1.070149\n",
      "###### N,i = 5,1 #####\n",
      "M: 139.20728\n",
      "det: 2.7539816e-05\n",
      "Validation loss mlp/pin: 1.467701/1.501619\n",
      "\n",
      "Epoch 232/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.660864/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.531724/1.024986\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496750/1.535111\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1057568\n",
      "det: 0.06652453\n",
      "Validation loss mlp/pin: 0.698257/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.07154\n",
      "det: 0.024268297\n",
      "Validation loss mlp/pin: 0.545378/1.069589\n",
      "###### N,i = 5,1 #####\n",
      "M: 126.911835\n",
      "det: 2.7868804e-05\n",
      "Validation loss mlp/pin: 1.467673/1.501894\n",
      "\n",
      "Epoch 233/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.659822/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.531130/1.024477\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496732/1.535118\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.10676\n",
      "det: 0.06658941\n",
      "Validation loss mlp/pin: 0.697193/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.580501\n",
      "det: 0.024245858\n",
      "Validation loss mlp/pin: 0.544804/1.069061\n",
      "###### N,i = 5,1 #####\n",
      "M: 132.99307\n",
      "det: 2.8206614e-05\n",
      "Validation loss mlp/pin: 1.467620/1.501601\n",
      "\n",
      "Epoch 234/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.658797/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.530552/1.023938\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496677/1.535163\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1077576\n",
      "det: 0.06665389\n",
      "Validation loss mlp/pin: 0.696145/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.502037\n",
      "det: 0.024224851\n",
      "Validation loss mlp/pin: 0.544230/1.068529\n",
      "###### N,i = 5,1 #####\n",
      "M: 151.55919\n",
      "det: 2.8553548e-05\n",
      "Validation loss mlp/pin: 1.467586/1.501655\n",
      "\n",
      "Epoch 235/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.657788/2.588994\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.530023/1.023450\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496634/1.535008\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.108696\n",
      "det: 0.06671563\n",
      "Validation loss mlp/pin: 0.695113/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.808155\n",
      "det: 0.024203563\n",
      "Validation loss mlp/pin: 0.543664/1.067997\n",
      "###### N,i = 5,1 #####\n",
      "M: 119.409935\n",
      "det: 2.8882541e-05\n",
      "Validation loss mlp/pin: 1.467562/1.501888\n",
      "\n",
      "Epoch 236/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.656787/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.529439/1.022921\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496577/1.535002\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.109617\n",
      "det: 0.066776514\n",
      "Validation loss mlp/pin: 0.694094/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.0620637\n",
      "det: 0.024183206\n",
      "Validation loss mlp/pin: 0.543101/1.067484\n",
      "###### N,i = 5,1 #####\n",
      "M: 128.44531\n",
      "det: 2.9218238e-05\n",
      "Validation loss mlp/pin: 1.467513/1.501553\n",
      "\n",
      "Epoch 237/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.655806/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.528909/1.022451\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496614/1.535368\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1105294\n",
      "det: 0.06683688\n",
      "Validation loss mlp/pin: 0.693090/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.664034\n",
      "det: 0.02416332\n",
      "Validation loss mlp/pin: 0.542541/1.066945\n",
      "###### N,i = 5,1 #####\n",
      "M: 145.93108\n",
      "det: 2.9550909e-05\n",
      "Validation loss mlp/pin: 1.467468/1.501576\n",
      "\n",
      "Epoch 238/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.654837/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.528379/1.021955\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496516/1.535221\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1114025\n",
      "det: 0.066895366\n",
      "Validation loss mlp/pin: 0.692100/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.984639\n",
      "det: 0.024143768\n",
      "Validation loss mlp/pin: 0.541982/1.066434\n",
      "###### N,i = 5,1 #####\n",
      "M: 92.88062\n",
      "det: 2.9895704e-05\n",
      "Validation loss mlp/pin: 1.467432/1.501563\n",
      "\n",
      "Epoch 239/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.653881/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.527826/1.021484\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496496/1.535013\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1122785\n",
      "det: 0.066953935\n",
      "Validation loss mlp/pin: 0.691125/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.970695\n",
      "det: 0.024123058\n",
      "Validation loss mlp/pin: 0.541434/1.065939\n",
      "###### N,i = 5,1 #####\n",
      "M: 166.81377\n",
      "det: 3.0207622e-05\n",
      "Validation loss mlp/pin: 1.467419/1.502094\n",
      "\n",
      "Epoch 240/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.652946/2.588997\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.527341/1.020990\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496427/1.535198\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1130705\n",
      "det: 0.06700852\n",
      "Validation loss mlp/pin: 0.690162/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.084831\n",
      "det: 0.024104206\n",
      "Validation loss mlp/pin: 0.540884/1.065455\n",
      "###### N,i = 5,1 #####\n",
      "M: 117.76005\n",
      "det: 3.051584e-05\n",
      "Validation loss mlp/pin: 1.467398/1.501991\n",
      "\n",
      "Epoch 241/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.652019/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.526788/1.020532\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496362/1.535034\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.113963\n",
      "det: 0.06706768\n",
      "Validation loss mlp/pin: 0.689214/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.802894\n",
      "det: 0.024084484\n",
      "Validation loss mlp/pin: 0.540345/1.064965\n",
      "###### N,i = 5,1 #####\n",
      "M: 90.48985\n",
      "det: 3.0840143e-05\n",
      "Validation loss mlp/pin: 1.467358/1.501602\n",
      "\n",
      "Epoch 242/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.651098/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.526299/1.020076\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496313/1.534903\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1147556\n",
      "det: 0.06712213\n",
      "Validation loss mlp/pin: 0.688279/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.598122\n",
      "det: 0.024064023\n",
      "Validation loss mlp/pin: 0.539819/1.064482\n",
      "###### N,i = 5,1 #####\n",
      "M: 175.2609\n",
      "det: 3.1164105e-05\n",
      "Validation loss mlp/pin: 1.467319/1.501558\n",
      "\n",
      "Epoch 243/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.650193/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.525783/1.019637\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496335/1.535094\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1155353\n",
      "det: 0.067175925\n",
      "Validation loss mlp/pin: 0.687356/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.120004\n",
      "det: 0.0240454\n",
      "Validation loss mlp/pin: 0.539287/1.063990\n",
      "###### N,i = 5,1 #####\n",
      "M: 258.9437\n",
      "det: 3.1476102e-05\n",
      "Validation loss mlp/pin: 1.467291/1.501668\n",
      "\n",
      "Epoch 244/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.649305/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.525282/1.019171\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496320/1.535257\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.116368\n",
      "det: 0.06723208\n",
      "Validation loss mlp/pin: 0.686448/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.043244\n",
      "det: 0.0240244\n",
      "Validation loss mlp/pin: 0.538776/1.063535\n",
      "###### N,i = 5,1 #####\n",
      "M: 148.42242\n",
      "det: 3.178963e-05\n",
      "Validation loss mlp/pin: 1.467263/1.501820\n",
      "\n",
      "Epoch 245/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.648423/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.524758/1.018721\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496276/1.535144\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.11719\n",
      "det: 0.06728764\n",
      "Validation loss mlp/pin: 0.685552/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.195715\n",
      "det: 0.02400641\n",
      "Validation loss mlp/pin: 0.538257/1.063058\n",
      "###### N,i = 5,1 #####\n",
      "M: 144.13864\n",
      "det: 3.2106884e-05\n",
      "Validation loss mlp/pin: 1.467215/1.501557\n",
      "\n",
      "Epoch 246/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.647559/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.524305/1.018310\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496165/1.534947\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1179814\n",
      "det: 0.06734182\n",
      "Validation loss mlp/pin: 0.684668/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.903179\n",
      "det: 0.023988662\n",
      "Validation loss mlp/pin: 0.537742/1.062590\n",
      "###### N,i = 5,1 #####\n",
      "M: 237.4747\n",
      "det: 3.2413824e-05\n",
      "Validation loss mlp/pin: 1.467181/1.501578\n",
      "\n",
      "Epoch 247/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.646708/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.523816/1.017869\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496260/1.535572\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1188264\n",
      "det: 0.06739823\n",
      "Validation loss mlp/pin: 0.683798/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.382583\n",
      "det: 0.023970466\n",
      "Validation loss mlp/pin: 0.537236/1.062135\n",
      "###### N,i = 5,1 #####\n",
      "M: 145.17824\n",
      "det: 3.2713993e-05\n",
      "Validation loss mlp/pin: 1.467159/1.501749\n",
      "\n",
      "Epoch 248/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.645868/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.523329/1.017420\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496168/1.535218\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.119611\n",
      "det: 0.06745176\n",
      "Validation loss mlp/pin: 0.682940/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.1317387\n",
      "det: 0.023950811\n",
      "Validation loss mlp/pin: 0.536743/1.061691\n",
      "###### N,i = 5,1 #####\n",
      "M: 229.89139\n",
      "det: 3.3028133e-05\n",
      "Validation loss mlp/pin: 1.467116/1.501553\n",
      "\n",
      "Epoch 249/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.645040/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.522879/1.017006\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496036/1.534844\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1203732\n",
      "det: 0.067504175\n",
      "Validation loss mlp/pin: 0.682093/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.563457\n",
      "det: 0.023931835\n",
      "Validation loss mlp/pin: 0.536253/1.061241\n",
      "###### N,i = 5,1 #####\n",
      "M: 261.36432\n",
      "det: 3.333794e-05\n",
      "Validation loss mlp/pin: 1.467090/1.501644\n",
      "\n",
      "Epoch 250/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.644223/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.522396/1.016588\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.496035/1.534971\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1210976\n",
      "det: 0.06755472\n",
      "Validation loss mlp/pin: 0.681258/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.303244\n",
      "det: 0.02391449\n",
      "Validation loss mlp/pin: 0.535759/1.060809\n",
      "###### N,i = 5,1 #####\n",
      "M: 209.37032\n",
      "det: 3.3644672e-05\n",
      "Validation loss mlp/pin: 1.467057/1.501614\n",
      "\n",
      "Epoch 251/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.643416/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.521937/1.016176\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495970/1.534815\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1218615\n",
      "det: 0.06760704\n",
      "Validation loss mlp/pin: 0.680434/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.421761\n",
      "det: 0.023897003\n",
      "Validation loss mlp/pin: 0.535274/1.060376\n",
      "###### N,i = 5,1 #####\n",
      "M: 195.47348\n",
      "det: 3.3941968e-05\n",
      "Validation loss mlp/pin: 1.467032/1.501671\n",
      "\n",
      "Epoch 252/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.642621/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.521485/1.015778\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495949/1.534898\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.122581\n",
      "det: 0.06765726\n",
      "Validation loss mlp/pin: 0.679622/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.687209\n",
      "det: 0.023879731\n",
      "Validation loss mlp/pin: 0.534793/1.059950\n",
      "###### N,i = 5,1 #####\n",
      "M: 143.0744\n",
      "det: 3.425937e-05\n",
      "Validation loss mlp/pin: 1.466996/1.501561\n",
      "\n",
      "Epoch 253/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.641835/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.521025/1.015382\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495968/1.535142\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1232715\n",
      "det: 0.06770603\n",
      "Validation loss mlp/pin: 0.678820/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.278787\n",
      "det: 0.02386076\n",
      "Validation loss mlp/pin: 0.534325/1.059535\n",
      "###### N,i = 5,1 #####\n",
      "M: 260.06494\n",
      "det: 3.4551384e-05\n",
      "Validation loss mlp/pin: 1.466967/1.501614\n",
      "\n",
      "Epoch 254/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.641064/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.520596/1.014999\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495936/1.535120\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1239796\n",
      "det: 0.067755476\n",
      "Validation loss mlp/pin: 0.678030/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.047483\n",
      "det: 0.023843674\n",
      "Validation loss mlp/pin: 0.533854/1.059111\n",
      "###### N,i = 5,1 #####\n",
      "M: 81.47679\n",
      "det: 3.484715e-05\n",
      "Validation loss mlp/pin: 1.466950/1.501894\n",
      "\n",
      "Epoch 255/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.640296/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.520160/1.014629\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495916/1.535050\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1246552\n",
      "det: 0.0678033\n",
      "Validation loss mlp/pin: 0.677249/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.612404\n",
      "det: 0.023825904\n",
      "Validation loss mlp/pin: 0.533394/1.058703\n",
      "###### N,i = 5,1 #####\n",
      "M: 101.46033\n",
      "det: 3.515454e-05\n",
      "Validation loss mlp/pin: 1.466931/1.502136\n",
      "\n",
      "Epoch 256/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.639545/2.588993\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.519713/1.014226\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495859/1.535160\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.125308\n",
      "det: 0.06784987\n",
      "Validation loss mlp/pin: 0.676480/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.015205\n",
      "det: 0.023808304\n",
      "Validation loss mlp/pin: 0.532937/1.058299\n",
      "###### N,i = 5,1 #####\n",
      "M: 269.1988\n",
      "det: 3.5445602e-05\n",
      "Validation loss mlp/pin: 1.466897/1.501704\n",
      "\n",
      "Epoch 257/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.638800/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.519285/1.013850\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495796/1.534920\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.125989\n",
      "det: 0.067897685\n",
      "Validation loss mlp/pin: 0.675721/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.218118\n",
      "det: 0.023790196\n",
      "Validation loss mlp/pin: 0.532488/1.057902\n",
      "###### N,i = 5,1 #####\n",
      "M: 180.97354\n",
      "det: 3.574055e-05\n",
      "Validation loss mlp/pin: 1.466869/1.501757\n",
      "\n",
      "Epoch 258/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.638070/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.518859/1.013503\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495808/1.535086\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1266556\n",
      "det: 0.06794469\n",
      "Validation loss mlp/pin: 0.674972/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.680296\n",
      "det: 0.023772843\n",
      "Validation loss mlp/pin: 0.532043/1.057505\n",
      "###### N,i = 5,1 #####\n",
      "M: 213.00848\n",
      "det: 3.6020174e-05\n",
      "Validation loss mlp/pin: 1.466829/1.501594\n",
      "\n",
      "Epoch 259/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.637346/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.518440/1.013110\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495754/1.535007\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.127266\n",
      "det: 0.06798902\n",
      "Validation loss mlp/pin: 0.674233/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.455743\n",
      "det: 0.023755629\n",
      "Validation loss mlp/pin: 0.531603/1.057116\n",
      "###### N,i = 5,1 #####\n",
      "M: 201.97198\n",
      "det: 3.632894e-05\n",
      "Validation loss mlp/pin: 1.466805/1.501704\n",
      "\n",
      "Epoch 260/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.636630/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.518035/1.012758\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495753/1.535208\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.127897\n",
      "det: 0.06803425\n",
      "Validation loss mlp/pin: 0.673504/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.329205\n",
      "det: 0.02373839\n",
      "Validation loss mlp/pin: 0.531167/1.056731\n",
      "###### N,i = 5,1 #####\n",
      "M: 129.67496\n",
      "det: 3.661834e-05\n",
      "Validation loss mlp/pin: 1.466767/1.501577\n",
      "\n",
      "Epoch 261/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.635927/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.517619/1.012428\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495648/1.534828\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.128523\n",
      "det: 0.06807916\n",
      "Validation loss mlp/pin: 0.672785/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.924047\n",
      "det: 0.023720484\n",
      "Validation loss mlp/pin: 0.530740/1.056354\n",
      "###### N,i = 5,1 #####\n",
      "M: 167.95572\n",
      "det: 3.6924477e-05\n",
      "Validation loss mlp/pin: 1.466733/1.501554\n",
      "\n",
      "Epoch 262/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.635229/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.517214/1.012048\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495688/1.535140\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.129162\n",
      "det: 0.068124615\n",
      "Validation loss mlp/pin: 0.672075/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.2210217\n",
      "det: 0.023703907\n",
      "Validation loss mlp/pin: 0.530312/1.055975\n",
      "###### N,i = 5,1 #####\n",
      "M: 242.24388\n",
      "det: 3.7191618e-05\n",
      "Validation loss mlp/pin: 1.466714/1.501735\n",
      "\n",
      "Epoch 263/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.634548/2.588992\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.516812/1.011696\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495619/1.535008\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1298294\n",
      "det: 0.06817135\n",
      "Validation loss mlp/pin: 0.671375/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.091944\n",
      "det: 0.023687076\n",
      "Validation loss mlp/pin: 0.529892/1.055608\n",
      "###### N,i = 5,1 #####\n",
      "M: 233.46112\n",
      "det: 3.7477625e-05\n",
      "Validation loss mlp/pin: 1.466687/1.501665\n",
      "\n",
      "Epoch 264/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.633873/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.516410/1.011349\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495638/1.535191\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1304417\n",
      "det: 0.06821541\n",
      "Validation loss mlp/pin: 0.670684/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.6049623\n",
      "det: 0.023670947\n",
      "Validation loss mlp/pin: 0.529473/1.055241\n",
      "###### N,i = 5,1 #####\n",
      "M: 226.2552\n",
      "det: 3.776376e-05\n",
      "Validation loss mlp/pin: 1.466667/1.501729\n",
      "\n",
      "Epoch 265/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.633203/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.515995/1.011013\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495610/1.535230\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.13109\n",
      "det: 0.06826105\n",
      "Validation loss mlp/pin: 0.670003/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.35584\n",
      "det: 0.02365494\n",
      "Validation loss mlp/pin: 0.529060/1.054884\n",
      "###### N,i = 5,1 #####\n",
      "M: 253.5914\n",
      "det: 3.8053364e-05\n",
      "Validation loss mlp/pin: 1.466640/1.501735\n",
      "\n",
      "Epoch 266/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.632548/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.515627/1.010689\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495496/1.534889\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1317267\n",
      "det: 0.0683061\n",
      "Validation loss mlp/pin: 0.669330/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.6401954\n",
      "det: 0.023639783\n",
      "Validation loss mlp/pin: 0.528648/1.054526\n",
      "###### N,i = 5,1 #####\n",
      "M: 129.91592\n",
      "det: 3.8341106e-05\n",
      "Validation loss mlp/pin: 1.466610/1.501616\n",
      "\n",
      "Epoch 267/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.631900/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.515237/1.010342\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495488/1.534894\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1323266\n",
      "det: 0.06834932\n",
      "Validation loss mlp/pin: 0.668666/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.198463\n",
      "det: 0.0236238\n",
      "Validation loss mlp/pin: 0.528248/1.054179\n",
      "###### N,i = 5,1 #####\n",
      "M: 104.666794\n",
      "det: 3.8615042e-05\n",
      "Validation loss mlp/pin: 1.466576/1.501553\n",
      "\n",
      "Epoch 268/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.631256/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.514848/1.010031\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495466/1.535004\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1328897\n",
      "det: 0.0683907\n",
      "Validation loss mlp/pin: 0.668010/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.946176\n",
      "det: 0.023607219\n",
      "Validation loss mlp/pin: 0.527855/1.053829\n",
      "###### N,i = 5,1 #####\n",
      "M: 147.16469\n",
      "det: 3.888984e-05\n",
      "Validation loss mlp/pin: 1.466551/1.501563\n",
      "\n",
      "Epoch 269/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.630627/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.514454/1.009704\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495451/1.534980\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1334443\n",
      "det: 0.06843159\n",
      "Validation loss mlp/pin: 0.667364/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.484007\n",
      "det: 0.023592245\n",
      "Validation loss mlp/pin: 0.527457/1.053477\n",
      "###### N,i = 5,1 #####\n",
      "M: 97.7972\n",
      "det: 3.9167753e-05\n",
      "Validation loss mlp/pin: 1.466536/1.501736\n",
      "\n",
      "Epoch 270/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.630002/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.514077/1.009378\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495435/1.535043\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1339917\n",
      "det: 0.06847208\n",
      "Validation loss mlp/pin: 0.666725/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.167381\n",
      "det: 0.023576766\n",
      "Validation loss mlp/pin: 0.527066/1.053137\n",
      "###### N,i = 5,1 #####\n",
      "M: 167.94617\n",
      "det: 3.9440667e-05\n",
      "Validation loss mlp/pin: 1.466509/1.501657\n",
      "\n",
      "Epoch 271/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.629387/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.513695/1.009069\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495388/1.535000\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.134515\n",
      "det: 0.06851131\n",
      "Validation loss mlp/pin: 0.666094/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.102039\n",
      "det: 0.02356104\n",
      "Validation loss mlp/pin: 0.526681/1.052801\n",
      "###### N,i = 5,1 #####\n",
      "M: 101.16344\n",
      "det: 3.971704e-05\n",
      "Validation loss mlp/pin: 1.466486/1.501716\n",
      "\n",
      "Epoch 272/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.628780/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.513330/1.008756\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495340/1.534858\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1350565\n",
      "det: 0.06855128\n",
      "Validation loss mlp/pin: 0.665471/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.711722\n",
      "det: 0.023545176\n",
      "Validation loss mlp/pin: 0.526304/1.052476\n",
      "###### N,i = 5,1 #####\n",
      "M: 113.51174\n",
      "det: 3.9990005e-05\n",
      "Validation loss mlp/pin: 1.466459/1.501634\n",
      "\n",
      "Epoch 273/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.628177/2.588990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.512960/1.008455\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495333/1.535025\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.135604\n",
      "det: 0.06859142\n",
      "Validation loss mlp/pin: 0.664857/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.37383\n",
      "det: 0.02353051\n",
      "Validation loss mlp/pin: 0.525924/1.052148\n",
      "###### N,i = 5,1 #####\n",
      "M: 138.13034\n",
      "det: 4.0255905e-05\n",
      "Validation loss mlp/pin: 1.466432/1.501590\n",
      "\n",
      "Epoch 274/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.627585/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.512610/1.008149\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495283/1.534899\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1361475\n",
      "det: 0.06863138\n",
      "Validation loss mlp/pin: 0.664250/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.304045\n",
      "det: 0.02351571\n",
      "Validation loss mlp/pin: 0.525549/1.051822\n",
      "###### N,i = 5,1 #####\n",
      "M: 172.35135\n",
      "det: 4.0528237e-05\n",
      "Validation loss mlp/pin: 1.466407/1.501601\n",
      "\n",
      "Epoch 275/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.627003/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.512235/1.007858\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495359/1.535151\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1366467\n",
      "det: 0.06866913\n",
      "Validation loss mlp/pin: 0.663652/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.216264\n",
      "det: 0.023501202\n",
      "Validation loss mlp/pin: 0.525175/1.051502\n",
      "###### N,i = 5,1 #####\n",
      "M: 203.26079\n",
      "det: 4.0811592e-05\n",
      "Validation loss mlp/pin: 1.466372/1.501572\n",
      "\n",
      "Epoch 276/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.626422/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.511875/1.007553\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495251/1.535031\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.137144\n",
      "det: 0.068706684\n",
      "Validation loss mlp/pin: 0.663060/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.2742195\n",
      "det: 0.023486968\n",
      "Validation loss mlp/pin: 0.524806/1.051186\n",
      "###### N,i = 5,1 #####\n",
      "M: 197.7153\n",
      "det: 4.1079962e-05\n",
      "Validation loss mlp/pin: 1.466353/1.501605\n",
      "\n",
      "Epoch 277/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.625853/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.511523/1.007256\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495201/1.534904\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1376247\n",
      "det: 0.06874333\n",
      "Validation loss mlp/pin: 0.662477/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.352375\n",
      "det: 0.023472361\n",
      "Validation loss mlp/pin: 0.524443/1.050875\n",
      "###### N,i = 5,1 #####\n",
      "M: 126.57642\n",
      "det: 4.1340994e-05\n",
      "Validation loss mlp/pin: 1.466332/1.501615\n",
      "\n",
      "Epoch 278/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.625290/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.511186/1.006981\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495184/1.534906\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.138117\n",
      "det: 0.068780385\n",
      "Validation loss mlp/pin: 0.661901/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.975553\n",
      "det: 0.023457887\n",
      "Validation loss mlp/pin: 0.524083/1.050570\n",
      "###### N,i = 5,1 #####\n",
      "M: 145.5254\n",
      "det: 4.1604173e-05\n",
      "Validation loss mlp/pin: 1.466308/1.501603\n",
      "\n",
      "Epoch 279/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.624736/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.510827/1.006689\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495152/1.534914\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1386075\n",
      "det: 0.06881727\n",
      "Validation loss mlp/pin: 0.661332/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.253467\n",
      "det: 0.023443135\n",
      "Validation loss mlp/pin: 0.523730/1.050269\n",
      "###### N,i = 5,1 #####\n",
      "M: 211.70071\n",
      "det: 4.1872616e-05\n",
      "Validation loss mlp/pin: 1.466284/1.501585\n",
      "\n",
      "Epoch 280/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.624185/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.510481/1.006398\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495124/1.534872\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.139093\n",
      "det: 0.06885381\n",
      "Validation loss mlp/pin: 0.660770/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.536878\n",
      "det: 0.023429492\n",
      "Validation loss mlp/pin: 0.523377/1.049965\n",
      "###### N,i = 5,1 #####\n",
      "M: 157.509\n",
      "det: 4.213884e-05\n",
      "Validation loss mlp/pin: 1.466257/1.501552\n",
      "\n",
      "Epoch 281/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.623642/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.510136/1.006109\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495080/1.534841\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1395674\n",
      "det: 0.06888974\n",
      "Validation loss mlp/pin: 0.660216/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.774273\n",
      "det: 0.023415767\n",
      "Validation loss mlp/pin: 0.523029/1.049667\n",
      "###### N,i = 5,1 #####\n",
      "M: 168.14426\n",
      "det: 4.2377305e-05\n",
      "Validation loss mlp/pin: 1.466237/1.501592\n",
      "\n",
      "Epoch 282/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.623107/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.509818/1.005859\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495174/1.535236\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1400237\n",
      "det: 0.0689247\n",
      "Validation loss mlp/pin: 0.659668/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.472987\n",
      "det: 0.023401855\n",
      "Validation loss mlp/pin: 0.522686/1.049369\n",
      "###### N,i = 5,1 #####\n",
      "M: 241.25357\n",
      "det: 4.2640077e-05\n",
      "Validation loss mlp/pin: 1.466210/1.501555\n",
      "\n",
      "Epoch 283/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.622581/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.509493/1.005567\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495047/1.534889\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1404505\n",
      "det: 0.06895823\n",
      "Validation loss mlp/pin: 0.659128/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.615216\n",
      "det: 0.023388268\n",
      "Validation loss mlp/pin: 0.522348/1.049078\n",
      "###### N,i = 5,1 #####\n",
      "M: 124.030716\n",
      "det: 4.2893e-05\n",
      "Validation loss mlp/pin: 1.466193/1.501608\n",
      "\n",
      "Epoch 284/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.622057/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.509156/1.005301\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495029/1.534824\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1409035\n",
      "det: 0.06899279\n",
      "Validation loss mlp/pin: 0.658594/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.798943\n",
      "det: 0.023376135\n",
      "Validation loss mlp/pin: 0.522006/1.048791\n",
      "###### N,i = 5,1 #####\n",
      "M: 138.7732\n",
      "det: 4.314361e-05\n",
      "Validation loss mlp/pin: 1.466182/1.501789\n",
      "\n",
      "Epoch 285/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.621543/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.508845/1.005026\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495045/1.535110\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.14133\n",
      "det: 0.06902601\n",
      "Validation loss mlp/pin: 0.658066/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.192894\n",
      "det: 0.023363033\n",
      "Validation loss mlp/pin: 0.521673/1.048507\n",
      "###### N,i = 5,1 #####\n",
      "M: 101.22539\n",
      "det: 4.3410335e-05\n",
      "Validation loss mlp/pin: 1.466158/1.501616\n",
      "\n",
      "Epoch 286/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.621032/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.508512/1.004770\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494985/1.534966\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1417646\n",
      "det: 0.06905951\n",
      "Validation loss mlp/pin: 0.657545/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.615202\n",
      "det: 0.023349645\n",
      "Validation loss mlp/pin: 0.521347/1.048227\n",
      "###### N,i = 5,1 #####\n",
      "M: 93.06228\n",
      "det: 4.3651376e-05\n",
      "Validation loss mlp/pin: 1.466138/1.501652\n",
      "\n",
      "Epoch 287/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.620528/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.508197/1.004506\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.495014/1.534943\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1422005\n",
      "det: 0.06909301\n",
      "Validation loss mlp/pin: 0.657031/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.645663\n",
      "det: 0.023337198\n",
      "Validation loss mlp/pin: 0.521021/1.047951\n",
      "###### N,i = 5,1 #####\n",
      "M: 95.98814\n",
      "det: 4.3885153e-05\n",
      "Validation loss mlp/pin: 1.466105/1.501563\n",
      "\n",
      "Epoch 288/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.620033/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.507898/1.004254\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494933/1.534878\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1426144\n",
      "det: 0.0691254\n",
      "Validation loss mlp/pin: 0.656524/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.454546\n",
      "det: 0.023324113\n",
      "Validation loss mlp/pin: 0.520702/1.047679\n",
      "###### N,i = 5,1 #####\n",
      "M: 222.31386\n",
      "det: 4.4144173e-05\n",
      "Validation loss mlp/pin: 1.466093/1.501695\n",
      "\n",
      "Epoch 289/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.619543/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.507578/1.003993\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494932/1.535044\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1430197\n",
      "det: 0.06915731\n",
      "Validation loss mlp/pin: 0.656022/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.591572\n",
      "det: 0.023311451\n",
      "Validation loss mlp/pin: 0.520386/1.047411\n",
      "###### N,i = 5,1 #####\n",
      "M: 105.974686\n",
      "det: 4.437536e-05\n",
      "Validation loss mlp/pin: 1.466072/1.501606\n",
      "\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.619060/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.507285/1.003755\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494884/1.534870\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1434226\n",
      "det: 0.06918907\n",
      "Validation loss mlp/pin: 0.655527/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.775921\n",
      "det: 0.02329896\n",
      "Validation loss mlp/pin: 0.520074/1.047144\n",
      "###### N,i = 5,1 #####\n",
      "M: 91.44243\n",
      "det: 4.4632958e-05\n",
      "Validation loss mlp/pin: 1.466056/1.501704\n",
      "\n",
      "Epoch 291/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.618581/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.506978/1.003498\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494916/1.535164\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1438465\n",
      "det: 0.06922172\n",
      "Validation loss mlp/pin: 0.655039/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.289818\n",
      "det: 0.023286937\n",
      "Validation loss mlp/pin: 0.519763/1.046877\n",
      "###### N,i = 5,1 #####\n",
      "M: 102.683945\n",
      "det: 4.4867546e-05\n",
      "Validation loss mlp/pin: 1.466035/1.501647\n",
      "\n",
      "Epoch 292/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.618110/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.506701/1.003251\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494860/1.534976\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1442466\n",
      "det: 0.06925317\n",
      "Validation loss mlp/pin: 0.654556/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.448441\n",
      "det: 0.023274196\n",
      "Validation loss mlp/pin: 0.519460/1.046618\n",
      "###### N,i = 5,1 #####\n",
      "M: 130.05167\n",
      "det: 4.5104778e-05\n",
      "Validation loss mlp/pin: 1.466015/1.501651\n",
      "\n",
      "Epoch 293/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.617643/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.506398/1.003011\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494812/1.534895\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.144648\n",
      "det: 0.06928454\n",
      "Validation loss mlp/pin: 0.654080/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.3843355\n",
      "det: 0.023262009\n",
      "Validation loss mlp/pin: 0.519158/1.046359\n",
      "###### N,i = 5,1 #####\n",
      "M: 82.02196\n",
      "det: 4.534264e-05\n",
      "Validation loss mlp/pin: 1.465999/1.501737\n",
      "\n",
      "Epoch 294/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.617181/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.506100/1.002783\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494784/1.534830\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1450343\n",
      "det: 0.069315106\n",
      "Validation loss mlp/pin: 0.653609/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.59436\n",
      "det: 0.023249894\n",
      "Validation loss mlp/pin: 0.518859/1.046102\n",
      "###### N,i = 5,1 #####\n",
      "M: 169.47855\n",
      "det: 4.5565917e-05\n",
      "Validation loss mlp/pin: 1.465975/1.501621\n",
      "\n",
      "Epoch 295/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.616729/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.505830/1.002547\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494813/1.535094\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1454105\n",
      "det: 0.06934512\n",
      "Validation loss mlp/pin: 0.653143/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.121666\n",
      "det: 0.023238234\n",
      "Validation loss mlp/pin: 0.518561/1.045850\n",
      "###### N,i = 5,1 #####\n",
      "M: 154.14029\n",
      "det: 4.5805362e-05\n",
      "Validation loss mlp/pin: 1.465956/1.501630\n",
      "\n",
      "Epoch 296/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.616277/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.505545/1.002306\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494750/1.534891\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.145795\n",
      "det: 0.06937541\n",
      "Validation loss mlp/pin: 0.652684/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.480043\n",
      "det: 0.023226628\n",
      "Validation loss mlp/pin: 0.518266/1.045600\n",
      "###### N,i = 5,1 #####\n",
      "M: 141.73901\n",
      "det: 4.603838e-05\n",
      "Validation loss mlp/pin: 1.465937/1.501655\n",
      "\n",
      "Epoch 297/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.615833/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.505252/1.002079\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494728/1.534841\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1461663\n",
      "det: 0.069404975\n",
      "Validation loss mlp/pin: 0.652230/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.462117\n",
      "det: 0.0232149\n",
      "Validation loss mlp/pin: 0.517976/1.045354\n",
      "###### N,i = 5,1 #####\n",
      "M: 228.77573\n",
      "det: 4.625644e-05\n",
      "Validation loss mlp/pin: 1.465924/1.501759\n",
      "\n",
      "Epoch 298/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.615397/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.504970/1.001852\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494716/1.534961\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1465425\n",
      "det: 0.06943465\n",
      "Validation loss mlp/pin: 0.651782/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.706528\n",
      "det: 0.023202825\n",
      "Validation loss mlp/pin: 0.517692/1.045111\n",
      "###### N,i = 5,1 #####\n",
      "M: 134.04462\n",
      "det: 4.6487385e-05\n",
      "Validation loss mlp/pin: 1.465904/1.501684\n",
      "\n",
      "Epoch 299/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.614966/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.504695/1.001628\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494670/1.534833\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1469417\n",
      "det: 0.06946539\n",
      "Validation loss mlp/pin: 0.651340/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.696342\n",
      "det: 0.023191314\n",
      "Validation loss mlp/pin: 0.517409/1.044870\n",
      "###### N,i = 5,1 #####\n",
      "M: 135.33131\n",
      "det: 4.6709265e-05\n",
      "Validation loss mlp/pin: 1.465886/1.501686\n",
      "\n",
      "Epoch 300/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.614535/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.504428/1.001409\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494702/1.535000\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1473374\n",
      "det: 0.06949587\n",
      "Validation loss mlp/pin: 0.650903/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.394529\n",
      "det: 0.023180211\n",
      "Validation loss mlp/pin: 0.517126/1.044632\n",
      "###### N,i = 5,1 #####\n",
      "M: 248.63312\n",
      "det: 4.692379e-05\n",
      "Validation loss mlp/pin: 1.465872/1.501771\n",
      "\n",
      "Epoch 301/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.614116/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.504152/1.001189\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494629/1.534855\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1477127\n",
      "det: 0.06952535\n",
      "Validation loss mlp/pin: 0.650472/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.921529\n",
      "det: 0.023168948\n",
      "Validation loss mlp/pin: 0.516848/1.044397\n",
      "###### N,i = 5,1 #####\n",
      "M: 213.57864\n",
      "det: 4.7133497e-05\n",
      "Validation loss mlp/pin: 1.465851/1.501667\n",
      "\n",
      "Epoch 302/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.613701/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.503888/1.000978\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494631/1.534846\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.148075\n",
      "det: 0.0695541\n",
      "Validation loss mlp/pin: 0.650046/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.047611\n",
      "det: 0.023157924\n",
      "Validation loss mlp/pin: 0.516573/1.044164\n",
      "###### N,i = 5,1 #####\n",
      "M: 105.619316\n",
      "det: 4.736201e-05\n",
      "Validation loss mlp/pin: 1.465824/1.501556\n",
      "\n",
      "Epoch 303/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.613287/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.503637/1.000758\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494619/1.535050\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.148458\n",
      "det: 0.0695838\n",
      "Validation loss mlp/pin: 0.649625/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.906544\n",
      "det: 0.02314701\n",
      "Validation loss mlp/pin: 0.516302/1.043934\n",
      "###### N,i = 5,1 #####\n",
      "M: 98.36015\n",
      "det: 4.7571546e-05\n",
      "Validation loss mlp/pin: 1.465806/1.501609\n",
      "\n",
      "Epoch 304/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.612882/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.503378/1.000540\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494566/1.534837\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1488166\n",
      "det: 0.0696122\n",
      "Validation loss mlp/pin: 0.649209/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.073548\n",
      "det: 0.023135964\n",
      "Validation loss mlp/pin: 0.516035/1.043709\n",
      "###### N,i = 5,1 #####\n",
      "M: 128.48627\n",
      "det: 4.777231e-05\n",
      "Validation loss mlp/pin: 1.465786/1.501602\n",
      "\n",
      "Epoch 305/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.612482/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.503123/1.000335\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494534/1.534780\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.149179\n",
      "det: 0.06964075\n",
      "Validation loss mlp/pin: 0.648799/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.5436535\n",
      "det: 0.02312493\n",
      "Validation loss mlp/pin: 0.515771/1.043485\n",
      "###### N,i = 5,1 #####\n",
      "M: 138.9731\n",
      "det: 4.7977293e-05\n",
      "Validation loss mlp/pin: 1.465767/1.501604\n",
      "\n",
      "Epoch 306/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.612084/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.502854/1.000124\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494549/1.534912\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.149527\n",
      "det: 0.06966856\n",
      "Validation loss mlp/pin: 0.648393/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.079388\n",
      "det: 0.023113903\n",
      "Validation loss mlp/pin: 0.515511/1.043263\n",
      "###### N,i = 5,1 #####\n",
      "M: 137.77792\n",
      "det: 4.8195823e-05\n",
      "Validation loss mlp/pin: 1.465744/1.501560\n",
      "\n",
      "Epoch 307/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.611694/2.588990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.502618/0.999928\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494530/1.534995\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.149884\n",
      "det: 0.06969668\n",
      "Validation loss mlp/pin: 0.647992/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.050426\n",
      "det: 0.023103591\n",
      "Validation loss mlp/pin: 0.515251/1.043043\n",
      "###### N,i = 5,1 #####\n",
      "M: 137.19537\n",
      "det: 4.8398888e-05\n",
      "Validation loss mlp/pin: 1.465726/1.501587\n",
      "\n",
      "Epoch 308/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.611306/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.502359/0.999726\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494492/1.534829\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.150224\n",
      "det: 0.069724016\n",
      "Validation loss mlp/pin: 0.647596/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.589299\n",
      "det: 0.023092922\n",
      "Validation loss mlp/pin: 0.514997/1.042827\n",
      "###### N,i = 5,1 #####\n",
      "M: 223.29405\n",
      "det: 4.8613212e-05\n",
      "Validation loss mlp/pin: 1.465715/1.501700\n",
      "\n",
      "Epoch 309/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.610925/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.502118/0.999521\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494459/1.534792\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1505604\n",
      "det: 0.06975111\n",
      "Validation loss mlp/pin: 0.647205/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.852769\n",
      "det: 0.023082295\n",
      "Validation loss mlp/pin: 0.514746/1.042611\n",
      "###### N,i = 5,1 #####\n",
      "M: 135.46812\n",
      "det: 4.8800972e-05\n",
      "Validation loss mlp/pin: 1.465697/1.501619\n",
      "\n",
      "Epoch 310/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.610548/2.588990\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.501868/0.999326\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494465/1.534857\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1508865\n",
      "det: 0.06977773\n",
      "Validation loss mlp/pin: 0.646818/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.834608\n",
      "det: 0.023072\n",
      "Validation loss mlp/pin: 0.514498/1.042400\n",
      "###### N,i = 5,1 #####\n",
      "M: 182.48418\n",
      "det: 4.8999693e-05\n",
      "Validation loss mlp/pin: 1.465675/1.501557\n",
      "\n",
      "Epoch 311/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.610174/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.501628/0.999132\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494487/1.535078\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1512146\n",
      "det: 0.069804385\n",
      "Validation loss mlp/pin: 0.646436/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.25991\n",
      "det: 0.02306171\n",
      "Validation loss mlp/pin: 0.514252/1.042190\n",
      "###### N,i = 5,1 #####\n",
      "M: 157.39899\n",
      "det: 4.9208993e-05\n",
      "Validation loss mlp/pin: 1.465654/1.501552\n",
      "\n",
      "Epoch 312/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.609806/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.501397/0.998943\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494439/1.534982\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.151564\n",
      "det: 0.06983181\n",
      "Validation loss mlp/pin: 0.646059/2.617972\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.542867\n",
      "det: 0.02305115\n",
      "Validation loss mlp/pin: 0.514010/1.041984\n",
      "###### N,i = 5,1 #####\n",
      "M: 205.92128\n",
      "det: 4.940321e-05\n",
      "Validation loss mlp/pin: 1.465639/1.501573\n",
      "\n",
      "Epoch 313/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.609444/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.501163/0.998747\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494401/1.534875\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1518793\n",
      "det: 0.06985759\n",
      "Validation loss mlp/pin: 0.645687/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.257435\n",
      "det: 0.023040852\n",
      "Validation loss mlp/pin: 0.513770/1.041781\n",
      "###### N,i = 5,1 #####\n",
      "M: 91.634514\n",
      "det: 4.9609924e-05\n",
      "Validation loss mlp/pin: 1.465624/1.501592\n",
      "\n",
      "Epoch 314/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.609085/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.500931/0.998554\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494398/1.534941\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1522126\n",
      "det: 0.069884054\n",
      "Validation loss mlp/pin: 0.645318/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.246809\n",
      "det: 0.023030873\n",
      "Validation loss mlp/pin: 0.513530/1.041577\n",
      "###### N,i = 5,1 #####\n",
      "M: 91.128845\n",
      "det: 4.9815906e-05\n",
      "Validation loss mlp/pin: 1.465611/1.501665\n",
      "\n",
      "Epoch 315/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.608733/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.500705/0.998373\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494359/1.534895\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.152526\n",
      "det: 0.069909506\n",
      "Validation loss mlp/pin: 0.644954/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.588284\n",
      "det: 0.023021044\n",
      "Validation loss mlp/pin: 0.513293/1.041377\n",
      "###### N,i = 5,1 #####\n",
      "M: 132.25685\n",
      "det: 4.9999686e-05\n",
      "Validation loss mlp/pin: 1.465595/1.501622\n",
      "\n",
      "Epoch 316/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.608378/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.500473/0.998182\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494336/1.534823\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1528316\n",
      "det: 0.06993451\n",
      "Validation loss mlp/pin: 0.644595/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.339069\n",
      "det: 0.023011206\n",
      "Validation loss mlp/pin: 0.513059/1.041178\n",
      "###### N,i = 5,1 #####\n",
      "M: 114.81424\n",
      "det: 5.0193376e-05\n",
      "Validation loss mlp/pin: 1.465580/1.501634\n",
      "\n",
      "Epoch 317/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.608030/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.500250/0.998010\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494309/1.534800\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1531315\n",
      "det: 0.06995916\n",
      "Validation loss mlp/pin: 0.644240/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.026727\n",
      "det: 0.023001457\n",
      "Validation loss mlp/pin: 0.512828/1.040982\n",
      "###### N,i = 5,1 #####\n",
      "M: 181.37744\n",
      "det: 5.039247e-05\n",
      "Validation loss mlp/pin: 1.465567/1.501672\n",
      "\n",
      "Epoch 318/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.607692/2.588991\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.500030/0.997821\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494315/1.534892\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.153436\n",
      "det: 0.069983944\n",
      "Validation loss mlp/pin: 0.643889/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.24742\n",
      "det: 0.022992183\n",
      "Validation loss mlp/pin: 0.512597/1.040788\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.67445\n",
      "det: 5.058018e-05\n",
      "Validation loss mlp/pin: 1.465550/1.501613\n",
      "\n",
      "Epoch 319/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.607352/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.499820/0.997658\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494299/1.534874\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.153727\n",
      "det: 0.070008\n",
      "Validation loss mlp/pin: 0.643542/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.6016445\n",
      "det: 0.022982951\n",
      "Validation loss mlp/pin: 0.512369/1.040596\n",
      "###### N,i = 5,1 #####\n",
      "M: 131.38525\n",
      "det: 5.0771105e-05\n",
      "Validation loss mlp/pin: 1.465537/1.501667\n",
      "\n",
      "Epoch 320/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.607017/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.499598/0.997485\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494303/1.534990\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.154012\n",
      "det: 0.0700317\n",
      "Validation loss mlp/pin: 0.643199/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.782928\n",
      "det: 0.022973636\n",
      "Validation loss mlp/pin: 0.512144/1.040406\n",
      "###### N,i = 5,1 #####\n",
      "M: 210.79425\n",
      "det: 5.097044e-05\n",
      "Validation loss mlp/pin: 1.465521/1.501630\n",
      "\n",
      "Epoch 321/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.606687/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.499378/0.997286\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494266/1.534915\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.154294\n",
      "det: 0.07005514\n",
      "Validation loss mlp/pin: 0.642861/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.005782\n",
      "det: 0.022964152\n",
      "Validation loss mlp/pin: 0.511924/1.040219\n",
      "###### N,i = 5,1 #####\n",
      "M: 127.07756\n",
      "det: 5.1157393e-05\n",
      "Validation loss mlp/pin: 1.465506/1.501640\n",
      "\n",
      "Epoch 322/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.606359/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.499172/0.997125\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494242/1.534879\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1545625\n",
      "det: 0.07007787\n",
      "Validation loss mlp/pin: 0.642526/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.170471\n",
      "det: 0.022954714\n",
      "Validation loss mlp/pin: 0.511706/1.040036\n",
      "###### N,i = 5,1 #####\n",
      "M: 125.59886\n",
      "det: 5.132905e-05\n",
      "Validation loss mlp/pin: 1.465491/1.501613\n",
      "\n",
      "Epoch 323/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.606036/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.498957/0.996950\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494220/1.534849\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1548204\n",
      "det: 0.07010001\n",
      "Validation loss mlp/pin: 0.642195/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.256602\n",
      "det: 0.022945262\n",
      "Validation loss mlp/pin: 0.511491/1.039856\n",
      "###### N,i = 5,1 #####\n",
      "M: 146.94855\n",
      "det: 5.1517363e-05\n",
      "Validation loss mlp/pin: 1.465478/1.501656\n",
      "\n",
      "Epoch 324/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.605717/2.588988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.498770/0.996796\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494213/1.534895\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1550913\n",
      "det: 0.07012273\n",
      "Validation loss mlp/pin: 0.641868/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.025046\n",
      "det: 0.022935383\n",
      "Validation loss mlp/pin: 0.511280/1.039678\n",
      "###### N,i = 5,1 #####\n",
      "M: 246.93079\n",
      "det: 5.1694864e-05\n",
      "Validation loss mlp/pin: 1.465463/1.501629\n",
      "\n",
      "Epoch 325/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.605401/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.498540/0.996619\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494197/1.534885\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1553545\n",
      "det: 0.07014499\n",
      "Validation loss mlp/pin: 0.641544/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.450275\n",
      "det: 0.022926291\n",
      "Validation loss mlp/pin: 0.511067/1.039498\n",
      "###### N,i = 5,1 #####\n",
      "M: 215.14664\n",
      "det: 5.1883784e-05\n",
      "Validation loss mlp/pin: 1.465449/1.501643\n",
      "\n",
      "Epoch 326/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.605091/2.588989\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.498348/0.996447\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494155/1.534794\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1556177\n",
      "det: 0.0701672\n",
      "Validation loss mlp/pin: 0.641225/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.197882\n",
      "det: 0.022917397\n",
      "Validation loss mlp/pin: 0.510856/1.039321\n",
      "###### N,i = 5,1 #####\n",
      "M: 124.35541\n",
      "det: 5.205469e-05\n",
      "Validation loss mlp/pin: 1.465435/1.501648\n",
      "\n",
      "Epoch 327/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.604783/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.498131/0.996297\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494179/1.534964\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1558666\n",
      "det: 0.07018867\n",
      "Validation loss mlp/pin: 0.640909/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.958155\n",
      "det: 0.022908276\n",
      "Validation loss mlp/pin: 0.510649/1.039146\n",
      "###### N,i = 5,1 #####\n",
      "M: 185.52928\n",
      "det: 5.2244515e-05\n",
      "Validation loss mlp/pin: 1.465423/1.501685\n",
      "\n",
      "Epoch 328/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.604476/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.497933/0.996124\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494142/1.534879\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1561265\n",
      "det: 0.07021049\n",
      "Validation loss mlp/pin: 0.640597/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.948834\n",
      "det: 0.022899352\n",
      "Validation loss mlp/pin: 0.510444/1.038974\n",
      "###### N,i = 5,1 #####\n",
      "M: 230.59099\n",
      "det: 5.2420517e-05\n",
      "Validation loss mlp/pin: 1.465410/1.501681\n",
      "\n",
      "Epoch 329/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.604177/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.497735/0.995964\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494122/1.534862\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.156376\n",
      "det: 0.070231736\n",
      "Validation loss mlp/pin: 0.640289/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.881404\n",
      "det: 0.022890475\n",
      "Validation loss mlp/pin: 0.510241/1.038804\n",
      "###### N,i = 5,1 #####\n",
      "M: 178.27682\n",
      "det: 5.2590105e-05\n",
      "Validation loss mlp/pin: 1.465397/1.501673\n",
      "\n",
      "Epoch 330/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.603879/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.497540/0.995814\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494093/1.534804\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1566315\n",
      "det: 0.0702532\n",
      "Validation loss mlp/pin: 0.639984/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.206112\n",
      "det: 0.022881769\n",
      "Validation loss mlp/pin: 0.510039/1.038635\n",
      "###### N,i = 5,1 #####\n",
      "M: 89.435875\n",
      "det: 5.2756455e-05\n",
      "Validation loss mlp/pin: 1.465382/1.501655\n",
      "\n",
      "Epoch 331/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.603586/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.497346/0.995661\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494102/1.534900\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.156882\n",
      "det: 0.07027438\n",
      "Validation loss mlp/pin: 0.639683/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.995455\n",
      "det: 0.022873154\n",
      "Validation loss mlp/pin: 0.509839/1.038468\n",
      "###### N,i = 5,1 #####\n",
      "M: 169.01631\n",
      "det: 5.2941403e-05\n",
      "Validation loss mlp/pin: 1.465367/1.501610\n",
      "\n",
      "Epoch 332/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.603294/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.497155/0.995507\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494081/1.534861\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1571174\n",
      "det: 0.07029474\n",
      "Validation loss mlp/pin: 0.639385/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.44008\n",
      "det: 0.022864496\n",
      "Validation loss mlp/pin: 0.509643/1.038305\n",
      "###### N,i = 5,1 #####\n",
      "M: 98.079865\n",
      "det: 5.3105203e-05\n",
      "Validation loss mlp/pin: 1.465354/1.501658\n",
      "\n",
      "Epoch 333/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.603006/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.496958/0.995349\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494062/1.534878\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1573567\n",
      "det: 0.07031518\n",
      "Validation loss mlp/pin: 0.639090/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.366898\n",
      "det: 0.022856124\n",
      "Validation loss mlp/pin: 0.509448/1.038142\n",
      "###### N,i = 5,1 #####\n",
      "M: 123.463715\n",
      "det: 5.3283544e-05\n",
      "Validation loss mlp/pin: 1.465341/1.501662\n",
      "\n",
      "Epoch 334/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.602722/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.496773/0.995196\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494042/1.534854\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.15759\n",
      "det: 0.070335224\n",
      "Validation loss mlp/pin: 0.638799/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.625692\n",
      "det: 0.022847492\n",
      "Validation loss mlp/pin: 0.509257/1.037981\n",
      "###### N,i = 5,1 #####\n",
      "M: 96.25105\n",
      "det: 5.3456006e-05\n",
      "Validation loss mlp/pin: 1.465328/1.501653\n",
      "\n",
      "Epoch 335/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.602442/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.496583/0.995050\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494045/1.534900\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1578264\n",
      "det: 0.070355386\n",
      "Validation loss mlp/pin: 0.638511/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.606752\n",
      "det: 0.022839218\n",
      "Validation loss mlp/pin: 0.509067/1.037822\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.65821\n",
      "det: 5.3614436e-05\n",
      "Validation loss mlp/pin: 1.465316/1.501701\n",
      "\n",
      "Epoch 336/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.602165/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.496405/0.994903\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.494008/1.534838\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1580677\n",
      "det: 0.07037566\n",
      "Validation loss mlp/pin: 0.638227/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.54109\n",
      "det: 0.022830822\n",
      "Validation loss mlp/pin: 0.508880/1.037665\n",
      "###### N,i = 5,1 #####\n",
      "M: 82.09887\n",
      "det: 5.3777967e-05\n",
      "Validation loss mlp/pin: 1.465302/1.501662\n",
      "\n",
      "Epoch 337/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.601890/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.496226/0.994757\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493978/1.534770\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.158293\n",
      "det: 0.070395134\n",
      "Validation loss mlp/pin: 0.637946/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.922335\n",
      "det: 0.022822853\n",
      "Validation loss mlp/pin: 0.508694/1.037509\n",
      "###### N,i = 5,1 #####\n",
      "M: 203.2718\n",
      "det: 5.394392e-05\n",
      "Validation loss mlp/pin: 1.465287/1.501620\n",
      "\n",
      "Epoch 338/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.601621/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.496053/0.994611\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493986/1.534865\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1585174\n",
      "det: 0.07041445\n",
      "Validation loss mlp/pin: 0.637668/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.324834\n",
      "det: 0.022814693\n",
      "Validation loss mlp/pin: 0.508511/1.037355\n",
      "###### N,i = 5,1 #####\n",
      "M: 78.10713\n",
      "det: 5.4104003e-05\n",
      "Validation loss mlp/pin: 1.465273/1.501610\n",
      "\n",
      "Epoch 339/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.601352/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.495872/0.994468\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493971/1.534837\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1587462\n",
      "det: 0.070433944\n",
      "Validation loss mlp/pin: 0.637394/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.909232\n",
      "det: 0.022806784\n",
      "Validation loss mlp/pin: 0.508329/1.037203\n",
      "###### N,i = 5,1 #####\n",
      "M: 74.21004\n",
      "det: 5.427945e-05\n",
      "Validation loss mlp/pin: 1.465262/1.501650\n",
      "\n",
      "Epoch 340/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.601088/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.495693/0.994326\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493953/1.534839\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1589727\n",
      "det: 0.07045319\n",
      "Validation loss mlp/pin: 0.637123/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.907164\n",
      "det: 0.02279881\n",
      "Validation loss mlp/pin: 0.508149/1.037053\n",
      "###### N,i = 5,1 #####\n",
      "M: 96.299484\n",
      "det: 5.4452776e-05\n",
      "Validation loss mlp/pin: 1.465249/1.501642\n",
      "\n",
      "Epoch 341/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.600826/2.588988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.495527/0.994191\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493940/1.534849\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.159191\n",
      "det: 0.07047203\n",
      "Validation loss mlp/pin: 0.636854/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.927668\n",
      "det: 0.022790892\n",
      "Validation loss mlp/pin: 0.507971/1.036904\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.8324\n",
      "det: 5.4595384e-05\n",
      "Validation loss mlp/pin: 1.465236/1.501633\n",
      "\n",
      "Epoch 342/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.600568/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.495347/0.994049\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493922/1.534846\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1594014\n",
      "det: 0.070490435\n",
      "Validation loss mlp/pin: 0.636589/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.978107\n",
      "det: 0.02278304\n",
      "Validation loss mlp/pin: 0.507795/1.036756\n",
      "###### N,i = 5,1 #####\n",
      "M: 92.71515\n",
      "det: 5.4750013e-05\n",
      "Validation loss mlp/pin: 1.465222/1.501608\n",
      "\n",
      "Epoch 343/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.600311/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.495180/0.993913\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493910/1.534857\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1596155\n",
      "det: 0.07050891\n",
      "Validation loss mlp/pin: 0.636326/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.594937\n",
      "det: 0.022775283\n",
      "Validation loss mlp/pin: 0.507621/1.036611\n",
      "###### N,i = 5,1 #####\n",
      "M: 144.90086\n",
      "det: 5.4915065e-05\n",
      "Validation loss mlp/pin: 1.465210/1.501630\n",
      "\n",
      "Epoch 344/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.600058/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.495010/0.993774\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493884/1.534791\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1598253\n",
      "det: 0.0705271\n",
      "Validation loss mlp/pin: 0.636067/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.621211\n",
      "det: 0.022767631\n",
      "Validation loss mlp/pin: 0.507449/1.036466\n",
      "###### N,i = 5,1 #####\n",
      "M: 109.2342\n",
      "det: 5.5076336e-05\n",
      "Validation loss mlp/pin: 1.465196/1.501611\n",
      "\n",
      "Epoch 345/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.599808/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.494847/0.993655\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493888/1.534881\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1600313\n",
      "det: 0.07054502\n",
      "Validation loss mlp/pin: 0.635811/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 18.619041\n",
      "det: 0.022760086\n",
      "Validation loss mlp/pin: 0.507278/1.036324\n",
      "###### N,i = 5,1 #####\n",
      "M: 107.175964\n",
      "det: 5.5227574e-05\n",
      "Validation loss mlp/pin: 1.465184/1.501609\n",
      "\n",
      "Epoch 346/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.599562/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.494686/0.993510\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493876/1.534887\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1602373\n",
      "det: 0.07056289\n",
      "Validation loss mlp/pin: 0.635558/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.3738365\n",
      "det: 0.02275244\n",
      "Validation loss mlp/pin: 0.507110/1.036183\n",
      "###### N,i = 5,1 #####\n",
      "M: 115.07477\n",
      "det: 5.538329e-05\n",
      "Validation loss mlp/pin: 1.465172/1.501624\n",
      "\n",
      "Epoch 347/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.599318/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.494515/0.993376\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493857/1.534851\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.160441\n",
      "det: 0.070580624\n",
      "Validation loss mlp/pin: 0.635307/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.131135\n",
      "det: 0.022744805\n",
      "Validation loss mlp/pin: 0.506944/1.036045\n",
      "###### N,i = 5,1 #####\n",
      "M: 137.19063\n",
      "det: 5.5528035e-05\n",
      "Validation loss mlp/pin: 1.465160/1.501629\n",
      "\n",
      "Epoch 348/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.599077/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.494353/0.993253\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493861/1.534948\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1606436\n",
      "det: 0.07059821\n",
      "Validation loss mlp/pin: 0.635059/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.694319\n",
      "det: 0.022737581\n",
      "Validation loss mlp/pin: 0.506778/1.035906\n",
      "###### N,i = 5,1 #####\n",
      "M: 167.80278\n",
      "det: 5.568205e-05\n",
      "Validation loss mlp/pin: 1.465149/1.501636\n",
      "\n",
      "Epoch 349/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.598837/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.494194/0.993118\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493831/1.534867\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1608367\n",
      "det: 0.0706153\n",
      "Validation loss mlp/pin: 0.634815/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.282711\n",
      "det: 0.022730349\n",
      "Validation loss mlp/pin: 0.506614/1.035769\n",
      "###### N,i = 5,1 #####\n",
      "M: 214.83168\n",
      "det: 5.5823064e-05\n",
      "Validation loss mlp/pin: 1.465138/1.501637\n",
      "\n",
      "Epoch 350/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.598600/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.494034/0.992995\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493842/1.534971\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1610246\n",
      "det: 0.07063208\n",
      "Validation loss mlp/pin: 0.634573/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.626751\n",
      "det: 0.022723122\n",
      "Validation loss mlp/pin: 0.506453/1.035635\n",
      "###### N,i = 5,1 #####\n",
      "M: 99.892105\n",
      "det: 5.5965877e-05\n",
      "Validation loss mlp/pin: 1.465125/1.501605\n",
      "\n",
      "Epoch 351/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.598367/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.493884/0.992877\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493825/1.534932\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1612105\n",
      "det: 0.07064867\n",
      "Validation loss mlp/pin: 0.634333/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.595594\n",
      "det: 0.02271603\n",
      "Validation loss mlp/pin: 0.506293/1.035501\n",
      "###### N,i = 5,1 #####\n",
      "M: 123.17912\n",
      "det: 5.611127e-05\n",
      "Validation loss mlp/pin: 1.465113/1.501604\n",
      "\n",
      "Epoch 352/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.598136/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.493732/0.992747\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493813/1.534932\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.161397\n",
      "det: 0.07066525\n",
      "Validation loss mlp/pin: 0.634097/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.88006\n",
      "det: 0.022708837\n",
      "Validation loss mlp/pin: 0.506136/1.035370\n",
      "###### N,i = 5,1 #####\n",
      "M: 115.17733\n",
      "det: 5.62681e-05\n",
      "Validation loss mlp/pin: 1.465098/1.501575\n",
      "\n",
      "Epoch 353/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.597908/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.493579/0.992622\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493810/1.535007\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1615896\n",
      "det: 0.070682034\n",
      "Validation loss mlp/pin: 0.633863/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.977911\n",
      "det: 0.022701928\n",
      "Validation loss mlp/pin: 0.505979/1.035239\n",
      "###### N,i = 5,1 #####\n",
      "M: 204.18285\n",
      "det: 5.6407567e-05\n",
      "Validation loss mlp/pin: 1.465088/1.501603\n",
      "\n",
      "Epoch 354/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.597682/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.493427/0.992501\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493756/1.534817\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.161774\n",
      "det: 0.070698455\n",
      "Validation loss mlp/pin: 0.633631/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.148795\n",
      "det: 0.022694958\n",
      "Validation loss mlp/pin: 0.505825/1.035110\n",
      "###### N,i = 5,1 #####\n",
      "M: 97.25334\n",
      "det: 5.6557095e-05\n",
      "Validation loss mlp/pin: 1.465077/1.501623\n",
      "\n",
      "Epoch 355/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.597462/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.493267/0.992387\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493751/1.534837\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.161953\n",
      "det: 0.070714526\n",
      "Validation loss mlp/pin: 0.633403/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.457782\n",
      "det: 0.022687962\n",
      "Validation loss mlp/pin: 0.505673/1.034983\n",
      "###### N,i = 5,1 #####\n",
      "M: 140.66283\n",
      "det: 5.6699075e-05\n",
      "Validation loss mlp/pin: 1.465067/1.501626\n",
      "\n",
      "Epoch 356/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.597239/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.493123/0.992273\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493744/1.534872\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1621323\n",
      "det: 0.070730545\n",
      "Validation loss mlp/pin: 0.633177/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.311611\n",
      "det: 0.022681309\n",
      "Validation loss mlp/pin: 0.505521/1.034856\n",
      "###### N,i = 5,1 #####\n",
      "M: 225.33269\n",
      "det: 5.683969e-05\n",
      "Validation loss mlp/pin: 1.465056/1.501611\n",
      "\n",
      "Epoch 357/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.597021/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.492977/0.992149\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493738/1.534864\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.162313\n",
      "det: 0.07074651\n",
      "Validation loss mlp/pin: 0.632953/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.486071\n",
      "det: 0.022674575\n",
      "Validation loss mlp/pin: 0.505371/1.034731\n",
      "###### N,i = 5,1 #####\n",
      "M: 174.4546\n",
      "det: 5.6971956e-05\n",
      "Validation loss mlp/pin: 1.465043/1.501576\n",
      "\n",
      "Epoch 358/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.596806/2.588987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.492832/0.992035\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493707/1.534797\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1624837\n",
      "det: 0.07076199\n",
      "Validation loss mlp/pin: 0.632732/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.606896\n",
      "det: 0.022667935\n",
      "Validation loss mlp/pin: 0.505223/1.034607\n",
      "###### N,i = 5,1 #####\n",
      "M: 276.79984\n",
      "det: 5.7109297e-05\n",
      "Validation loss mlp/pin: 1.465035/1.501638\n",
      "\n",
      "Epoch 359/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.596593/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.492686/0.991920\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493716/1.534908\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.162652\n",
      "det: 0.07077725\n",
      "Validation loss mlp/pin: 0.632513/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.388954\n",
      "det: 0.022661453\n",
      "Validation loss mlp/pin: 0.505076/1.034485\n",
      "###### N,i = 5,1 #####\n",
      "M: 79.02734\n",
      "det: 5.7245303e-05\n",
      "Validation loss mlp/pin: 1.465025/1.501643\n",
      "\n",
      "Epoch 360/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.596382/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.492542/0.991805\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493684/1.534817\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.162817\n",
      "det: 0.0707923\n",
      "Validation loss mlp/pin: 0.632296/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.654566\n",
      "det: 0.022654805\n",
      "Validation loss mlp/pin: 0.504932/1.034364\n",
      "###### N,i = 5,1 #####\n",
      "M: 133.97714\n",
      "det: 5.7379777e-05\n",
      "Validation loss mlp/pin: 1.465013/1.501606\n",
      "\n",
      "Epoch 361/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.596174/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.492400/0.991702\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493671/1.534809\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1629753\n",
      "det: 0.070807\n",
      "Validation loss mlp/pin: 0.632082/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.9096975\n",
      "det: 0.022648202\n",
      "Validation loss mlp/pin: 0.504789/1.034245\n",
      "###### N,i = 5,1 #####\n",
      "M: 196.47128\n",
      "det: 5.750674e-05\n",
      "Validation loss mlp/pin: 1.465004/1.501633\n",
      "\n",
      "Epoch 362/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.595966/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.492271/0.991588\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493683/1.534940\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1631355\n",
      "det: 0.07082171\n",
      "Validation loss mlp/pin: 0.631871/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.480723\n",
      "det: 0.022641921\n",
      "Validation loss mlp/pin: 0.504647/1.034126\n",
      "###### N,i = 5,1 #####\n",
      "M: 106.09481\n",
      "det: 5.7654077e-05\n",
      "Validation loss mlp/pin: 1.464994/1.501626\n",
      "\n",
      "Epoch 363/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.595761/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.492130/0.991475\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493664/1.534875\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.163295\n",
      "det: 0.07083626\n",
      "Validation loss mlp/pin: 0.631661/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.476845\n",
      "det: 0.022635583\n",
      "Validation loss mlp/pin: 0.504507/1.034010\n",
      "###### N,i = 5,1 #####\n",
      "M: 138.00955\n",
      "det: 5.778073e-05\n",
      "Validation loss mlp/pin: 1.464985/1.501644\n",
      "\n",
      "Epoch 364/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.595561/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.491994/0.991376\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493642/1.534853\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.163454\n",
      "det: 0.07085078\n",
      "Validation loss mlp/pin: 0.631454/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.994731\n",
      "det: 0.022629276\n",
      "Validation loss mlp/pin: 0.504369/1.033895\n",
      "###### N,i = 5,1 #####\n",
      "M: 87.066124\n",
      "det: 5.791199e-05\n",
      "Validation loss mlp/pin: 1.464975/1.501626\n",
      "\n",
      "Epoch 365/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.595360/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.491856/0.991261\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493631/1.534851\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.163609\n",
      "det: 0.070865035\n",
      "Validation loss mlp/pin: 0.631250/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.315104\n",
      "det: 0.022623193\n",
      "Validation loss mlp/pin: 0.504231/1.033782\n",
      "###### N,i = 5,1 #####\n",
      "M: 116.00237\n",
      "det: 5.8049496e-05\n",
      "Validation loss mlp/pin: 1.464966/1.501652\n",
      "\n",
      "Epoch 366/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.595163/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.491725/0.991157\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493619/1.534847\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.163765\n",
      "det: 0.070879266\n",
      "Validation loss mlp/pin: 0.631047/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.272935\n",
      "det: 0.02261725\n",
      "Validation loss mlp/pin: 0.504094/1.033668\n",
      "###### N,i = 5,1 #####\n",
      "M: 70.35641\n",
      "det: 5.818058e-05\n",
      "Validation loss mlp/pin: 1.464956/1.501627\n",
      "\n",
      "Epoch 367/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.594967/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.491586/0.991052\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493626/1.534922\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1639175\n",
      "det: 0.07089325\n",
      "Validation loss mlp/pin: 0.630847/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.856228\n",
      "det: 0.02261119\n",
      "Validation loss mlp/pin: 0.503960/1.033556\n",
      "###### N,i = 5,1 #####\n",
      "M: 100.046936\n",
      "det: 5.8298443e-05\n",
      "Validation loss mlp/pin: 1.464945/1.501610\n",
      "\n",
      "Epoch 368/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.594775/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.491458/0.990948\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493589/1.534808\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1640677\n",
      "det: 0.07090712\n",
      "Validation loss mlp/pin: 0.630649/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.625641\n",
      "det: 0.022605253\n",
      "Validation loss mlp/pin: 0.503827/1.033445\n",
      "###### N,i = 5,1 #####\n",
      "M: 207.52379\n",
      "det: 5.8439335e-05\n",
      "Validation loss mlp/pin: 1.464936/1.501617\n",
      "\n",
      "Epoch 369/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.594583/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.491329/0.990846\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493576/1.534794\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1642113\n",
      "det: 0.07092055\n",
      "Validation loss mlp/pin: 0.630453/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.42018\n",
      "det: 0.022599284\n",
      "Validation loss mlp/pin: 0.503696/1.033336\n",
      "###### N,i = 5,1 #####\n",
      "M: 203.97708\n",
      "det: 5.8562753e-05\n",
      "Validation loss mlp/pin: 1.464926/1.501614\n",
      "\n",
      "Epoch 370/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.594393/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.491201/0.990742\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493567/1.534808\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1643515\n",
      "det: 0.07093378\n",
      "Validation loss mlp/pin: 0.630260/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.226531\n",
      "det: 0.02259328\n",
      "Validation loss mlp/pin: 0.503567/1.033227\n",
      "###### N,i = 5,1 #####\n",
      "M: 165.01857\n",
      "det: 5.869192e-05\n",
      "Validation loss mlp/pin: 1.464917/1.501615\n",
      "\n",
      "Epoch 371/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.594207/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.491080/0.990641\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493578/1.534871\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1644955\n",
      "det: 0.07094714\n",
      "Validation loss mlp/pin: 0.630068/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.588253\n",
      "det: 0.022587497\n",
      "Validation loss mlp/pin: 0.503438/1.033120\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.39287\n",
      "det: 5.8805857e-05\n",
      "Validation loss mlp/pin: 1.464909/1.501658\n",
      "\n",
      "Epoch 372/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.594023/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.490950/0.990543\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493567/1.534900\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1646485\n",
      "det: 0.07096091\n",
      "Validation loss mlp/pin: 0.629879/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.183048\n",
      "det: 0.022581622\n",
      "Validation loss mlp/pin: 0.503312/1.033015\n",
      "###### N,i = 5,1 #####\n",
      "M: 107.140625\n",
      "det: 5.8918045e-05\n",
      "Validation loss mlp/pin: 1.464900/1.501644\n",
      "\n",
      "Epoch 373/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.593841/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.490826/0.990443\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493526/1.534769\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.164788\n",
      "det: 0.07097391\n",
      "Validation loss mlp/pin: 0.629692/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.851358\n",
      "det: 0.022576028\n",
      "Validation loss mlp/pin: 0.503185/1.032909\n",
      "###### N,i = 5,1 #####\n",
      "M: 89.8096\n",
      "det: 5.9053913e-05\n",
      "Validation loss mlp/pin: 1.464891/1.501652\n",
      "\n",
      "Epoch 374/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.593659/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.490700/0.990354\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493532/1.534836\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.164928\n",
      "det: 0.07098692\n",
      "Validation loss mlp/pin: 0.629507/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.544798\n",
      "det: 0.02257038\n",
      "Validation loss mlp/pin: 0.503061/1.032806\n",
      "###### N,i = 5,1 #####\n",
      "M: 95.23629\n",
      "det: 5.9167716e-05\n",
      "Validation loss mlp/pin: 1.464881/1.501623\n",
      "\n",
      "Epoch 375/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.593481/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.490580/0.990264\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493547/1.534915\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1650763\n",
      "det: 0.07100025\n",
      "Validation loss mlp/pin: 0.629324/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.705433\n",
      "det: 0.022564847\n",
      "Validation loss mlp/pin: 0.502938/1.032703\n",
      "###### N,i = 5,1 #####\n",
      "M: 225.43715\n",
      "det: 5.9272148e-05\n",
      "Validation loss mlp/pin: 1.464873/1.501632\n",
      "\n",
      "Epoch 376/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.593307/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.490462/0.990163\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493499/1.534795\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.165224\n",
      "det: 0.07101349\n",
      "Validation loss mlp/pin: 0.629143/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.275943\n",
      "det: 0.022559276\n",
      "Validation loss mlp/pin: 0.502816/1.032602\n",
      "###### N,i = 5,1 #####\n",
      "M: 167.03174\n",
      "det: 5.9400907e-05\n",
      "Validation loss mlp/pin: 1.464864/1.501624\n",
      "\n",
      "Epoch 377/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.593129/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.490338/0.990063\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493484/1.534769\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1653633\n",
      "det: 0.071026266\n",
      "Validation loss mlp/pin: 0.628964/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.90633\n",
      "det: 0.022553798\n",
      "Validation loss mlp/pin: 0.502696/1.032501\n",
      "###### N,i = 5,1 #####\n",
      "M: 226.46123\n",
      "det: 5.9520688e-05\n",
      "Validation loss mlp/pin: 1.464856/1.501640\n",
      "\n",
      "Epoch 378/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.592957/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.490218/0.989970\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493502/1.534872\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1655035\n",
      "det: 0.071039036\n",
      "Validation loss mlp/pin: 0.628787/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.190157\n",
      "det: 0.022548433\n",
      "Validation loss mlp/pin: 0.502576/1.032402\n",
      "###### N,i = 5,1 #####\n",
      "M: 96.47893\n",
      "det: 5.964018e-05\n",
      "Validation loss mlp/pin: 1.464846/1.501626\n",
      "\n",
      "Epoch 379/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.592786/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.490104/0.989878\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493471/1.534788\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.165642\n",
      "det: 0.07105167\n",
      "Validation loss mlp/pin: 0.628612/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.085918\n",
      "det: 0.02254308\n",
      "Validation loss mlp/pin: 0.502458/1.032304\n",
      "###### N,i = 5,1 #####\n",
      "M: 122.55116\n",
      "det: 5.9748272e-05\n",
      "Validation loss mlp/pin: 1.464837/1.501616\n",
      "\n",
      "Epoch 380/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.592617/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.489993/0.989793\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493472/1.534842\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1657815\n",
      "det: 0.071064316\n",
      "Validation loss mlp/pin: 0.628439/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.280281\n",
      "det: 0.022537826\n",
      "Validation loss mlp/pin: 0.502341/1.032207\n",
      "###### N,i = 5,1 #####\n",
      "M: 105.3236\n",
      "det: 5.9862963e-05\n",
      "Validation loss mlp/pin: 1.464828/1.501612\n",
      "\n",
      "Epoch 381/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.592452/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.489872/0.989700\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493448/1.534780\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.16592\n",
      "det: 0.07107679\n",
      "Validation loss mlp/pin: 0.628268/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.879116\n",
      "det: 0.02253257\n",
      "Validation loss mlp/pin: 0.502225/1.032111\n",
      "###### N,i = 5,1 #####\n",
      "M: 64.03424\n",
      "det: 5.997748e-05\n",
      "Validation loss mlp/pin: 1.464821/1.501640\n",
      "\n",
      "Epoch 382/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.592286/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.489765/0.989620\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493444/1.534815\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.16606\n",
      "det: 0.07108933\n",
      "Validation loss mlp/pin: 0.628098/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.800921\n",
      "det: 0.022527393\n",
      "Validation loss mlp/pin: 0.502110/1.032015\n",
      "###### N,i = 5,1 #####\n",
      "M: 146.99648\n",
      "det: 6.0088012e-05\n",
      "Validation loss mlp/pin: 1.464813/1.501629\n",
      "\n",
      "Epoch 383/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.592123/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.489651/0.989527\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493445/1.534854\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.166191\n",
      "det: 0.07110138\n",
      "Validation loss mlp/pin: 0.627931/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.303292\n",
      "det: 0.02252226\n",
      "Validation loss mlp/pin: 0.501997/1.031921\n",
      "###### N,i = 5,1 #####\n",
      "M: 194.81596\n",
      "det: 6.0202536e-05\n",
      "Validation loss mlp/pin: 1.464804/1.501621\n",
      "\n",
      "Epoch 384/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.591961/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.489539/0.989438\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493439/1.534860\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.166327\n",
      "det: 0.07111367\n",
      "Validation loss mlp/pin: 0.627765/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.784727\n",
      "det: 0.02251714\n",
      "Validation loss mlp/pin: 0.501885/1.031829\n",
      "###### N,i = 5,1 #####\n",
      "M: 123.74738\n",
      "det: 6.031894e-05\n",
      "Validation loss mlp/pin: 1.464795/1.501608\n",
      "\n",
      "Epoch 385/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.591801/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.489430/0.989348\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493415/1.534804\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.166455\n",
      "det: 0.071125485\n",
      "Validation loss mlp/pin: 0.627602/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.564842\n",
      "det: 0.022512011\n",
      "Validation loss mlp/pin: 0.501774/1.031737\n",
      "###### N,i = 5,1 #####\n",
      "M: 117.048386\n",
      "det: 6.0418795e-05\n",
      "Validation loss mlp/pin: 1.464787/1.501613\n",
      "\n",
      "Epoch 386/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.591644/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.489320/0.989268\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493400/1.534777\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.166584\n",
      "det: 0.07113734\n",
      "Validation loss mlp/pin: 0.627439/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.168431\n",
      "det: 0.022507058\n",
      "Validation loss mlp/pin: 0.501664/1.031646\n",
      "###### N,i = 5,1 #####\n",
      "M: 80.20586\n",
      "det: 6.0530485e-05\n",
      "Validation loss mlp/pin: 1.464778/1.501613\n",
      "\n",
      "Epoch 387/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.591488/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.489209/0.989179\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493394/1.534790\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1667156\n",
      "det: 0.07114925\n",
      "Validation loss mlp/pin: 0.627279/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.575852\n",
      "det: 0.02250214\n",
      "Validation loss mlp/pin: 0.501555/1.031556\n",
      "###### N,i = 5,1 #####\n",
      "M: 108.921196\n",
      "det: 6.064092e-05\n",
      "Validation loss mlp/pin: 1.464770/1.501610\n",
      "\n",
      "Epoch 388/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.591333/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.489105/0.989106\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493381/1.534773\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1668444\n",
      "det: 0.071160994\n",
      "Validation loss mlp/pin: 0.627121/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.596051\n",
      "det: 0.022497315\n",
      "Validation loss mlp/pin: 0.501447/1.031466\n",
      "###### N,i = 5,1 #####\n",
      "M: 112.68875\n",
      "det: 6.0739076e-05\n",
      "Validation loss mlp/pin: 1.464763/1.501627\n",
      "\n",
      "Epoch 389/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.591181/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.488998/0.989018\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493372/1.534771\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.166969\n",
      "det: 0.071172506\n",
      "Validation loss mlp/pin: 0.626964/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.201323\n",
      "det: 0.022492427\n",
      "Validation loss mlp/pin: 0.501340/1.031377\n",
      "###### N,i = 5,1 #####\n",
      "M: 121.257706\n",
      "det: 6.0848655e-05\n",
      "Validation loss mlp/pin: 1.464756/1.501636\n",
      "\n",
      "Epoch 390/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.591030/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.488894/0.988936\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493371/1.534801\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1670914\n",
      "det: 0.07118384\n",
      "Validation loss mlp/pin: 0.626809/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.976971\n",
      "det: 0.022487711\n",
      "Validation loss mlp/pin: 0.501234/1.031290\n",
      "###### N,i = 5,1 #####\n",
      "M: 191.67259\n",
      "det: 6.0945513e-05\n",
      "Validation loss mlp/pin: 1.464748/1.501636\n",
      "\n",
      "Epoch 391/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.590881/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.488791/0.988853\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493363/1.534810\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1672115\n",
      "det: 0.07119505\n",
      "Validation loss mlp/pin: 0.626655/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.780132\n",
      "det: 0.022482984\n",
      "Validation loss mlp/pin: 0.501130/1.031204\n",
      "###### N,i = 5,1 #####\n",
      "M: 192.87234\n",
      "det: 6.106213e-05\n",
      "Validation loss mlp/pin: 1.464740/1.501623\n",
      "\n",
      "Epoch 392/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.590733/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.488689/0.988774\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493347/1.534778\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.167339\n",
      "det: 0.0712065\n",
      "Validation loss mlp/pin: 0.626504/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.970613\n",
      "det: 0.02247837\n",
      "Validation loss mlp/pin: 0.501026/1.031118\n",
      "###### N,i = 5,1 #####\n",
      "M: 125.74272\n",
      "det: 6.116359e-05\n",
      "Validation loss mlp/pin: 1.464733/1.501631\n",
      "\n",
      "Epoch 393/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.590586/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.488584/0.988695\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493333/1.534757\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1674576\n",
      "det: 0.07121758\n",
      "Validation loss mlp/pin: 0.626354/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.007103\n",
      "det: 0.022473749\n",
      "Validation loss mlp/pin: 0.500924/1.031034\n",
      "###### N,i = 5,1 #####\n",
      "M: 174.57947\n",
      "det: 6.1268176e-05\n",
      "Validation loss mlp/pin: 1.464726/1.501636\n",
      "\n",
      "Epoch 394/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.590442/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.488489/0.988626\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493346/1.534845\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1675797\n",
      "det: 0.071228735\n",
      "Validation loss mlp/pin: 0.626205/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.017275\n",
      "det: 0.022469236\n",
      "Validation loss mlp/pin: 0.500822/1.030950\n",
      "###### N,i = 5,1 #####\n",
      "M: 129.74544\n",
      "det: 6.136397e-05\n",
      "Validation loss mlp/pin: 1.464718/1.501626\n",
      "\n",
      "Epoch 395/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.590299/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.488384/0.988536\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493330/1.534822\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1677055\n",
      "det: 0.07123999\n",
      "Validation loss mlp/pin: 0.626059/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.426136\n",
      "det: 0.022464683\n",
      "Validation loss mlp/pin: 0.500721/1.030868\n",
      "###### N,i = 5,1 #####\n",
      "M: 136.2598\n",
      "det: 6.1464016e-05\n",
      "Validation loss mlp/pin: 1.464710/1.501621\n",
      "\n",
      "Epoch 396/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.590158/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.488294/0.988459\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493313/1.534780\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1678295\n",
      "det: 0.07125114\n",
      "Validation loss mlp/pin: 0.625914/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.27009\n",
      "det: 0.022460215\n",
      "Validation loss mlp/pin: 0.500622/1.030786\n",
      "###### N,i = 5,1 #####\n",
      "M: 151.6047\n",
      "det: 6.1570994e-05\n",
      "Validation loss mlp/pin: 1.464702/1.501612\n",
      "\n",
      "Epoch 397/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.590018/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.488188/0.988383\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493310/1.534799\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1679497\n",
      "det: 0.07126206\n",
      "Validation loss mlp/pin: 0.625770/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.771109\n",
      "det: 0.022455681\n",
      "Validation loss mlp/pin: 0.500524/1.030705\n",
      "###### N,i = 5,1 #####\n",
      "M: 92.41977\n",
      "det: 6.166722e-05\n",
      "Validation loss mlp/pin: 1.464696/1.501639\n",
      "\n",
      "Epoch 398/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.589879/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.488093/0.988308\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493290/1.534758\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1680727\n",
      "det: 0.071273044\n",
      "Validation loss mlp/pin: 0.625628/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.6072855\n",
      "det: 0.022451278\n",
      "Validation loss mlp/pin: 0.500427/1.030625\n",
      "###### N,i = 5,1 #####\n",
      "M: 91.66731\n",
      "det: 6.176713e-05\n",
      "Validation loss mlp/pin: 1.464689/1.501635\n",
      "\n",
      "Epoch 399/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.589742/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.487999/0.988241\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493292/1.534797\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1681933\n",
      "det: 0.0712839\n",
      "Validation loss mlp/pin: 0.625488/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.574949\n",
      "det: 0.0224468\n",
      "Validation loss mlp/pin: 0.500332/1.030546\n",
      "###### N,i = 5,1 #####\n",
      "M: 104.725266\n",
      "det: 6.1868006e-05\n",
      "Validation loss mlp/pin: 1.464682/1.501634\n",
      "\n",
      "Epoch 400/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.589608/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.487900/0.988157\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493279/1.534776\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.168311\n",
      "det: 0.07129451\n",
      "Validation loss mlp/pin: 0.625349/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.343551\n",
      "det: 0.02244247\n",
      "Validation loss mlp/pin: 0.500237/1.030467\n",
      "###### N,i = 5,1 #####\n",
      "M: 143.61469\n",
      "det: 6.196642e-05\n",
      "Validation loss mlp/pin: 1.464676/1.501646\n",
      "\n",
      "Epoch 401/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.589475/2.588988\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.487812/0.988091\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493270/1.534767\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.168428\n",
      "det: 0.07130512\n",
      "Validation loss mlp/pin: 0.625212/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.073414\n",
      "det: 0.022438206\n",
      "Validation loss mlp/pin: 0.500142/1.030389\n",
      "###### N,i = 5,1 #####\n",
      "M: 131.32275\n",
      "det: 6.2059546e-05\n",
      "Validation loss mlp/pin: 1.464668/1.501634\n",
      "\n",
      "Epoch 402/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.589342/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.487723/0.988019\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493275/1.534823\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.168541\n",
      "det: 0.07131543\n",
      "Validation loss mlp/pin: 0.625076/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.697501\n",
      "det: 0.02243389\n",
      "Validation loss mlp/pin: 0.500050/1.030311\n",
      "###### N,i = 5,1 #####\n",
      "M: 65.90489\n",
      "det: 6.21481e-05\n",
      "Validation loss mlp/pin: 1.464661/1.501629\n",
      "\n",
      "Epoch 403/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.589211/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.487627/0.987944\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493280/1.534874\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1686525\n",
      "det: 0.07132564\n",
      "Validation loss mlp/pin: 0.624941/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.137978\n",
      "det: 0.022429664\n",
      "Validation loss mlp/pin: 0.499958/1.030235\n",
      "###### N,i = 5,1 #####\n",
      "M: 172.30556\n",
      "det: 6.2243525e-05\n",
      "Validation loss mlp/pin: 1.464655/1.501642\n",
      "\n",
      "Epoch 404/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.589081/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.487537/0.987874\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493249/1.534783\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.168762\n",
      "det: 0.0713357\n",
      "Validation loss mlp/pin: 0.624808/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.496073\n",
      "det: 0.022425491\n",
      "Validation loss mlp/pin: 0.499867/1.030160\n",
      "###### N,i = 5,1 #####\n",
      "M: 169.5857\n",
      "det: 6.2337735e-05\n",
      "Validation loss mlp/pin: 1.464648/1.501631\n",
      "\n",
      "Epoch 405/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.588953/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.487446/0.987808\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493238/1.534770\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.168872\n",
      "det: 0.07134579\n",
      "Validation loss mlp/pin: 0.624676/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.631597\n",
      "det: 0.022421429\n",
      "Validation loss mlp/pin: 0.499776/1.030086\n",
      "###### N,i = 5,1 #####\n",
      "M: 155.63327\n",
      "det: 6.2439576e-05\n",
      "Validation loss mlp/pin: 1.464641/1.501628\n",
      "\n",
      "Epoch 406/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.588827/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.487356/0.987743\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493240/1.534806\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1689806\n",
      "det: 0.071355745\n",
      "Validation loss mlp/pin: 0.624546/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.652176\n",
      "det: 0.022417367\n",
      "Validation loss mlp/pin: 0.499687/1.030012\n",
      "###### N,i = 5,1 #####\n",
      "M: 107.27182\n",
      "det: 6.252073e-05\n",
      "Validation loss mlp/pin: 1.464634/1.501621\n",
      "\n",
      "Epoch 407/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.588702/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.487276/0.987670\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493237/1.534828\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1690865\n",
      "det: 0.07136557\n",
      "Validation loss mlp/pin: 0.624418/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.21121\n",
      "det: 0.022413319\n",
      "Validation loss mlp/pin: 0.499598/1.029939\n",
      "###### N,i = 5,1 #####\n",
      "M: 136.87778\n",
      "det: 6.260528e-05\n",
      "Validation loss mlp/pin: 1.464628/1.501644\n",
      "\n",
      "Epoch 408/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.588578/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.487187/0.987599\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493219/1.534786\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.169192\n",
      "det: 0.07137528\n",
      "Validation loss mlp/pin: 0.624290/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.897996\n",
      "det: 0.02240935\n",
      "Validation loss mlp/pin: 0.499511/1.029867\n",
      "###### N,i = 5,1 #####\n",
      "M: 125.03806\n",
      "det: 6.270086e-05\n",
      "Validation loss mlp/pin: 1.464622/1.501634\n",
      "\n",
      "Epoch 409/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.588457/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.487100/0.987541\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493214/1.534781\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1692953\n",
      "det: 0.07138488\n",
      "Validation loss mlp/pin: 0.624164/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.138502\n",
      "det: 0.022405442\n",
      "Validation loss mlp/pin: 0.499424/1.029795\n",
      "###### N,i = 5,1 #####\n",
      "M: 152.0526\n",
      "det: 6.2787134e-05\n",
      "Validation loss mlp/pin: 1.464615/1.501640\n",
      "\n",
      "Epoch 410/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.588335/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.487016/0.987472\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493212/1.534820\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1693964\n",
      "det: 0.071394295\n",
      "Validation loss mlp/pin: 0.624040/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.9836655\n",
      "det: 0.02240147\n",
      "Validation loss mlp/pin: 0.499338/1.029724\n",
      "###### N,i = 5,1 #####\n",
      "M: 73.42426\n",
      "det: 6.287719e-05\n",
      "Validation loss mlp/pin: 1.464609/1.501631\n",
      "\n",
      "Epoch 411/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.588214/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.486931/0.987406\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493214/1.534826\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1694946\n",
      "det: 0.071403585\n",
      "Validation loss mlp/pin: 0.623916/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.887407\n",
      "det: 0.022397593\n",
      "Validation loss mlp/pin: 0.499253/1.029655\n",
      "###### N,i = 5,1 #####\n",
      "M: 99.19681\n",
      "det: 6.296865e-05\n",
      "Validation loss mlp/pin: 1.464604/1.501660\n",
      "\n",
      "Epoch 412/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.588095/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.486847/0.987345\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493193/1.534804\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1695924\n",
      "det: 0.07141274\n",
      "Validation loss mlp/pin: 0.623794/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.1110935\n",
      "det: 0.022393767\n",
      "Validation loss mlp/pin: 0.499169/1.029585\n",
      "###### N,i = 5,1 #####\n",
      "M: 77.55397\n",
      "det: 6.305455e-05\n",
      "Validation loss mlp/pin: 1.464597/1.501649\n",
      "\n",
      "Epoch 413/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.587978/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.486771/0.987280\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493181/1.534768\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1696873\n",
      "det: 0.071421735\n",
      "Validation loss mlp/pin: 0.623674/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.043321\n",
      "det: 0.022389956\n",
      "Validation loss mlp/pin: 0.499087/1.029517\n",
      "###### N,i = 5,1 #####\n",
      "M: 94.52586\n",
      "det: 6.313755e-05\n",
      "Validation loss mlp/pin: 1.464590/1.501630\n",
      "\n",
      "Epoch 414/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.587862/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.486685/0.987211\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493176/1.534780\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1697817\n",
      "det: 0.071430676\n",
      "Validation loss mlp/pin: 0.623554/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.511595\n",
      "det: 0.022386208\n",
      "Validation loss mlp/pin: 0.499004/1.029449\n",
      "###### N,i = 5,1 #####\n",
      "M: 83.691956\n",
      "det: 6.3228625e-05\n",
      "Validation loss mlp/pin: 1.464584/1.501630\n",
      "\n",
      "Epoch 415/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.587747/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.486606/0.987152\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493172/1.534798\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.169874\n",
      "det: 0.07143948\n",
      "Validation loss mlp/pin: 0.623436/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.106979\n",
      "det: 0.022382474\n",
      "Validation loss mlp/pin: 0.498923/1.029382\n",
      "###### N,i = 5,1 #####\n",
      "M: 187.05981\n",
      "det: 6.3302905e-05\n",
      "Validation loss mlp/pin: 1.464578/1.501627\n",
      "\n",
      "Epoch 416/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.587634/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.486539/0.987091\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493161/1.534773\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1699657\n",
      "det: 0.07144818\n",
      "Validation loss mlp/pin: 0.623319/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.990383\n",
      "det: 0.022378823\n",
      "Validation loss mlp/pin: 0.498842/1.029316\n",
      "###### N,i = 5,1 #####\n",
      "M: 108.51102\n",
      "det: 6.338206e-05\n",
      "Validation loss mlp/pin: 1.464571/1.501617\n",
      "\n",
      "Epoch 417/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.587521/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.486452/0.987028\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493184/1.534910\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1700554\n",
      "det: 0.071456775\n",
      "Validation loss mlp/pin: 0.623203/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.432408\n",
      "det: 0.022375183\n",
      "Validation loss mlp/pin: 0.498762/1.029251\n",
      "###### N,i = 5,1 #####\n",
      "M: 89.044334\n",
      "det: 6.3469415e-05\n",
      "Validation loss mlp/pin: 1.464566/1.501630\n",
      "\n",
      "Epoch 418/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.587408/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.486371/0.986968\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493147/1.534772\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.170146\n",
      "det: 0.07146536\n",
      "Validation loss mlp/pin: 0.623089/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.599733\n",
      "det: 0.02237161\n",
      "Validation loss mlp/pin: 0.498684/1.029186\n",
      "###### N,i = 5,1 #####\n",
      "M: 152.99886\n",
      "det: 6.3548825e-05\n",
      "Validation loss mlp/pin: 1.464560/1.501628\n",
      "\n",
      "Epoch 419/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.587299/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.486298/0.986908\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493136/1.534757\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1702385\n",
      "det: 0.07147393\n",
      "Validation loss mlp/pin: 0.622976/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.716728\n",
      "det: 0.022368109\n",
      "Validation loss mlp/pin: 0.498605/1.029122\n",
      "###### N,i = 5,1 #####\n",
      "M: 167.33305\n",
      "det: 6.363209e-05\n",
      "Validation loss mlp/pin: 1.464554/1.501637\n",
      "\n",
      "Epoch 420/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.587189/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.486222/0.986851\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493131/1.534757\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1703296\n",
      "det: 0.07148243\n",
      "Validation loss mlp/pin: 0.622864/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.125449\n",
      "det: 0.022364637\n",
      "Validation loss mlp/pin: 0.498528/1.029058\n",
      "###### N,i = 5,1 #####\n",
      "M: 105.26279\n",
      "det: 6.37121e-05\n",
      "Validation loss mlp/pin: 1.464548/1.501643\n",
      "\n",
      "Epoch 421/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.587081/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.486148/0.986796\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493126/1.534782\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1704187\n",
      "det: 0.071490794\n",
      "Validation loss mlp/pin: 0.622753/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.131574\n",
      "det: 0.022361157\n",
      "Validation loss mlp/pin: 0.498452/1.028995\n",
      "###### N,i = 5,1 #####\n",
      "M: 104.11252\n",
      "det: 6.379693e-05\n",
      "Validation loss mlp/pin: 1.464543/1.501641\n",
      "\n",
      "Epoch 422/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.586975/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.486075/0.986733\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493128/1.534811\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1705065\n",
      "det: 0.07149908\n",
      "Validation loss mlp/pin: 0.622643/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.4584436\n",
      "det: 0.022357695\n",
      "Validation loss mlp/pin: 0.498376/1.028933\n",
      "###### N,i = 5,1 #####\n",
      "M: 93.33424\n",
      "det: 6.386809e-05\n",
      "Validation loss mlp/pin: 1.464537/1.501640\n",
      "\n",
      "Epoch 423/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.586869/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.486002/0.986677\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493113/1.534770\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1705933\n",
      "det: 0.07150723\n",
      "Validation loss mlp/pin: 0.622534/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.91272\n",
      "det: 0.02235432\n",
      "Validation loss mlp/pin: 0.498301/1.028871\n",
      "###### N,i = 5,1 #####\n",
      "M: 115.6132\n",
      "det: 6.395362e-05\n",
      "Validation loss mlp/pin: 1.464531/1.501638\n",
      "\n",
      "Epoch 424/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.586765/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485934/0.986622\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493107/1.534784\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1706824\n",
      "det: 0.07151551\n",
      "Validation loss mlp/pin: 0.622427/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.8382\n",
      "det: 0.022350928\n",
      "Validation loss mlp/pin: 0.498227/1.028810\n",
      "###### N,i = 5,1 #####\n",
      "M: 93.785164\n",
      "det: 6.4023196e-05\n",
      "Validation loss mlp/pin: 1.464526/1.501627\n",
      "\n",
      "Epoch 425/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.586662/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485857/0.986564\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493104/1.534787\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.170766\n",
      "det: 0.07152348\n",
      "Validation loss mlp/pin: 0.622321/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.9293036\n",
      "det: 0.022347571\n",
      "Validation loss mlp/pin: 0.498154/1.028750\n",
      "###### N,i = 5,1 #####\n",
      "M: 124.12761\n",
      "det: 6.409906e-05\n",
      "Validation loss mlp/pin: 1.464520/1.501626\n",
      "\n",
      "Epoch 426/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.586559/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485786/0.986506\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493097/1.534775\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1708508\n",
      "det: 0.07153145\n",
      "Validation loss mlp/pin: 0.622216/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.738602\n",
      "det: 0.022344243\n",
      "Validation loss mlp/pin: 0.498081/1.028690\n",
      "###### N,i = 5,1 #####\n",
      "M: 107.52937\n",
      "det: 6.417404e-05\n",
      "Validation loss mlp/pin: 1.464515/1.501633\n",
      "\n",
      "Epoch 427/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.586458/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485721/0.986453\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493087/1.534767\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1709337\n",
      "det: 0.07153933\n",
      "Validation loss mlp/pin: 0.622112/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.2743864\n",
      "det: 0.022340948\n",
      "Validation loss mlp/pin: 0.498009/1.028631\n",
      "###### N,i = 5,1 #####\n",
      "M: 84.41189\n",
      "det: 6.424903e-05\n",
      "Validation loss mlp/pin: 1.464509/1.501626\n",
      "\n",
      "Epoch 428/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.586359/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485647/0.986402\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493079/1.534760\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1710167\n",
      "det: 0.07154711\n",
      "Validation loss mlp/pin: 0.622009/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.353811\n",
      "det: 0.022337677\n",
      "Validation loss mlp/pin: 0.497939/1.028573\n",
      "###### N,i = 5,1 #####\n",
      "M: 139.32538\n",
      "det: 6.433196e-05\n",
      "Validation loss mlp/pin: 1.464504/1.501630\n",
      "\n",
      "Epoch 429/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.586260/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485582/0.986344\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493080/1.534788\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1710987\n",
      "det: 0.07155483\n",
      "Validation loss mlp/pin: 0.621907/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.7495\n",
      "det: 0.022334458\n",
      "Validation loss mlp/pin: 0.497868/1.028515\n",
      "###### N,i = 5,1 #####\n",
      "M: 243.18983\n",
      "det: 6.439961e-05\n",
      "Validation loss mlp/pin: 1.464498/1.501621\n",
      "\n",
      "Epoch 430/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.586162/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485514/0.986292\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493075/1.534793\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1711783\n",
      "det: 0.07156245\n",
      "Validation loss mlp/pin: 0.621807/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.469734\n",
      "det: 0.022331245\n",
      "Validation loss mlp/pin: 0.497799/1.028457\n",
      "###### N,i = 5,1 #####\n",
      "M: 128.53856\n",
      "det: 6.447286e-05\n",
      "Validation loss mlp/pin: 1.464493/1.501624\n",
      "\n",
      "Epoch 431/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.586065/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485445/0.986244\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493066/1.534781\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1712604\n",
      "det: 0.071570076\n",
      "Validation loss mlp/pin: 0.621707/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.88311\n",
      "det: 0.022328055\n",
      "Validation loss mlp/pin: 0.497730/1.028401\n",
      "###### N,i = 5,1 #####\n",
      "M: 157.597\n",
      "det: 6.453839e-05\n",
      "Validation loss mlp/pin: 1.464488/1.501627\n",
      "\n",
      "Epoch 432/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.585970/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485377/0.986187\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493054/1.534753\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1713443\n",
      "det: 0.071577795\n",
      "Validation loss mlp/pin: 0.621609/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.81301\n",
      "det: 0.022324929\n",
      "Validation loss mlp/pin: 0.497662/1.028345\n",
      "###### N,i = 5,1 #####\n",
      "M: 78.84285\n",
      "det: 6.461205e-05\n",
      "Validation loss mlp/pin: 1.464483/1.501618\n",
      "\n",
      "Epoch 433/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.585875/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485311/0.986138\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493049/1.534759\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.171426\n",
      "det: 0.07158542\n",
      "Validation loss mlp/pin: 0.621512/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.283762\n",
      "det: 0.022321844\n",
      "Validation loss mlp/pin: 0.497594/1.028289\n",
      "###### N,i = 5,1 #####\n",
      "M: 78.64616\n",
      "det: 6.4691914e-05\n",
      "Validation loss mlp/pin: 1.464477/1.501617\n",
      "\n",
      "Epoch 434/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.585781/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485248/0.986088\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493044/1.534759\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.171507\n",
      "det: 0.07159289\n",
      "Validation loss mlp/pin: 0.621415/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.275367\n",
      "det: 0.02231875\n",
      "Validation loss mlp/pin: 0.497528/1.028234\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.779175\n",
      "det: 6.475945e-05\n",
      "Validation loss mlp/pin: 1.464473/1.501625\n",
      "\n",
      "Epoch 435/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.585688/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485182/0.986034\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493037/1.534755\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.171586\n",
      "det: 0.07160027\n",
      "Validation loss mlp/pin: 0.621320/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.507367\n",
      "det: 0.02231572\n",
      "Validation loss mlp/pin: 0.497462/1.028180\n",
      "###### N,i = 5,1 #####\n",
      "M: 124.8526\n",
      "det: 6.481279e-05\n",
      "Validation loss mlp/pin: 1.464468/1.501630\n",
      "\n",
      "Epoch 436/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.585597/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485118/0.985987\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493046/1.534822\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1716623\n",
      "det: 0.07160751\n",
      "Validation loss mlp/pin: 0.621225/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.220433\n",
      "det: 0.022312744\n",
      "Validation loss mlp/pin: 0.497396/1.028126\n",
      "###### N,i = 5,1 #####\n",
      "M: 114.02539\n",
      "det: 6.489469e-05\n",
      "Validation loss mlp/pin: 1.464463/1.501631\n",
      "\n",
      "Epoch 437/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.585506/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.485057/0.985935\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493031/1.534781\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1717386\n",
      "det: 0.071614705\n",
      "Validation loss mlp/pin: 0.621132/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.275651\n",
      "det: 0.022309776\n",
      "Validation loss mlp/pin: 0.497332/1.028073\n",
      "###### N,i = 5,1 #####\n",
      "M: 94.302444\n",
      "det: 6.496916e-05\n",
      "Validation loss mlp/pin: 1.464458/1.501621\n",
      "\n",
      "Epoch 438/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.585416/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484994/0.985889\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493021/1.534762\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.171814\n",
      "det: 0.071621805\n",
      "Validation loss mlp/pin: 0.621040/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.9888754\n",
      "det: 0.022306839\n",
      "Validation loss mlp/pin: 0.497268/1.028020\n",
      "###### N,i = 5,1 #####\n",
      "M: 197.14275\n",
      "det: 6.5028114e-05\n",
      "Validation loss mlp/pin: 1.464453/1.501617\n",
      "\n",
      "Epoch 439/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.585328/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484933/0.985840\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493017/1.534758\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1718874\n",
      "det: 0.071628824\n",
      "Validation loss mlp/pin: 0.620948/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.685023\n",
      "det: 0.02230394\n",
      "Validation loss mlp/pin: 0.497204/1.027967\n",
      "###### N,i = 5,1 #####\n",
      "M: 142.76727\n",
      "det: 6.508494e-05\n",
      "Validation loss mlp/pin: 1.464448/1.501618\n",
      "\n",
      "Epoch 440/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.585239/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484871/0.985792\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493018/1.534791\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.171961\n",
      "det: 0.07163571\n",
      "Validation loss mlp/pin: 0.620858/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.758816\n",
      "det: 0.022301033\n",
      "Validation loss mlp/pin: 0.497142/1.027916\n",
      "###### N,i = 5,1 #####\n",
      "M: 172.7217\n",
      "det: 6.5162385e-05\n",
      "Validation loss mlp/pin: 1.464443/1.501616\n",
      "\n",
      "Epoch 441/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.585153/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484812/0.985745\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.493009/1.534772\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.172031\n",
      "det: 0.071642525\n",
      "Validation loss mlp/pin: 0.620768/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 20.535307\n",
      "det: 0.022298213\n",
      "Validation loss mlp/pin: 0.497080/1.027865\n",
      "###### N,i = 5,1 #####\n",
      "M: 78.83972\n",
      "det: 6.5222e-05\n",
      "Validation loss mlp/pin: 1.464439/1.501625\n",
      "\n",
      "Epoch 442/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.585066/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484756/0.985698\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492998/1.534754\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.172102\n",
      "det: 0.071649276\n",
      "Validation loss mlp/pin: 0.620680/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.747409\n",
      "det: 0.022295382\n",
      "Validation loss mlp/pin: 0.497018/1.027815\n",
      "###### N,i = 5,1 #####\n",
      "M: 96.44509\n",
      "det: 6.52848e-05\n",
      "Validation loss mlp/pin: 1.464434/1.501621\n",
      "\n",
      "Epoch 443/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.584981/2.588986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484695/0.985653\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492994/1.534763\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1721706\n",
      "det: 0.0716559\n",
      "Validation loss mlp/pin: 0.620592/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.939839\n",
      "det: 0.022292614\n",
      "Validation loss mlp/pin: 0.496957/1.027765\n",
      "###### N,i = 5,1 #####\n",
      "M: 228.25432\n",
      "det: 6.536062e-05\n",
      "Validation loss mlp/pin: 1.464429/1.501626\n",
      "\n",
      "Epoch 444/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.584897/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484636/0.985605\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492984/1.534736\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1722383\n",
      "det: 0.07166243\n",
      "Validation loss mlp/pin: 0.620505/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.72064\n",
      "det: 0.02228985\n",
      "Validation loss mlp/pin: 0.496897/1.027715\n",
      "###### N,i = 5,1 #####\n",
      "M: 181.89543\n",
      "det: 6.541326e-05\n",
      "Validation loss mlp/pin: 1.464425/1.501624\n",
      "\n",
      "Epoch 445/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.584813/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484578/0.985562\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492986/1.534770\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1723056\n",
      "det: 0.07166892\n",
      "Validation loss mlp/pin: 0.620419/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.404924\n",
      "det: 0.02228706\n",
      "Validation loss mlp/pin: 0.496838/1.027667\n",
      "###### N,i = 5,1 #####\n",
      "M: 194.45755\n",
      "det: 6.547315e-05\n",
      "Validation loss mlp/pin: 1.464420/1.501624\n",
      "\n",
      "Epoch 446/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.584731/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484523/0.985518\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492979/1.534756\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.172371\n",
      "det: 0.0716753\n",
      "Validation loss mlp/pin: 0.620335/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.67798\n",
      "det: 0.022284333\n",
      "Validation loss mlp/pin: 0.496779/1.027618\n",
      "###### N,i = 5,1 #####\n",
      "M: 75.35959\n",
      "det: 6.5539956e-05\n",
      "Validation loss mlp/pin: 1.464416/1.501620\n",
      "\n",
      "Epoch 447/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.584649/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484464/0.985473\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492978/1.534776\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.172436\n",
      "det: 0.07168165\n",
      "Validation loss mlp/pin: 0.620250/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.723525\n",
      "det: 0.022281623\n",
      "Validation loss mlp/pin: 0.496721/1.027570\n",
      "###### N,i = 5,1 #####\n",
      "M: 95.111496\n",
      "det: 6.560341e-05\n",
      "Validation loss mlp/pin: 1.464411/1.501615\n",
      "\n",
      "Epoch 448/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.584568/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484407/0.985425\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492973/1.534777\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1725006\n",
      "det: 0.0716879\n",
      "Validation loss mlp/pin: 0.620167/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.254444\n",
      "det: 0.022278922\n",
      "Validation loss mlp/pin: 0.496663/1.027523\n",
      "###### N,i = 5,1 #####\n",
      "M: 114.19452\n",
      "det: 6.5667744e-05\n",
      "Validation loss mlp/pin: 1.464407/1.501624\n",
      "\n",
      "Epoch 449/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.584488/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484352/0.985386\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492963/1.534754\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.172566\n",
      "det: 0.07169417\n",
      "Validation loss mlp/pin: 0.620085/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.272696\n",
      "det: 0.022276267\n",
      "Validation loss mlp/pin: 0.496606/1.027476\n",
      "###### N,i = 5,1 #####\n",
      "M: 67.65376\n",
      "det: 6.572212e-05\n",
      "Validation loss mlp/pin: 1.464402/1.501622\n",
      "\n",
      "Epoch 450/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.584409/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484297/0.985341\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492955/1.534744\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1726303\n",
      "det: 0.0717004\n",
      "Validation loss mlp/pin: 0.620004/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.1034775\n",
      "det: 0.02227366\n",
      "Validation loss mlp/pin: 0.496550/1.027429\n",
      "###### N,i = 5,1 #####\n",
      "M: 138.68774\n",
      "det: 6.579477e-05\n",
      "Validation loss mlp/pin: 1.464398/1.501619\n",
      "\n",
      "Epoch 451/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.584331/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484244/0.985298\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492954/1.534752\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1726947\n",
      "det: 0.07170656\n",
      "Validation loss mlp/pin: 0.619923/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.385716\n",
      "det: 0.022271056\n",
      "Validation loss mlp/pin: 0.496494/1.027383\n",
      "###### N,i = 5,1 #####\n",
      "M: 133.7561\n",
      "det: 6.585345e-05\n",
      "Validation loss mlp/pin: 1.464394/1.501620\n",
      "\n",
      "Epoch 452/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.584253/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484187/0.985255\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492949/1.534758\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.172758\n",
      "det: 0.07171263\n",
      "Validation loss mlp/pin: 0.619843/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.830313\n",
      "det: 0.022268508\n",
      "Validation loss mlp/pin: 0.496439/1.027338\n",
      "###### N,i = 5,1 #####\n",
      "M: 84.13774\n",
      "det: 6.591106e-05\n",
      "Validation loss mlp/pin: 1.464390/1.501626\n",
      "\n",
      "Epoch 453/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.584176/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484136/0.985215\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492941/1.534745\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.172819\n",
      "det: 0.07171862\n",
      "Validation loss mlp/pin: 0.619764/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 19.249973\n",
      "det: 0.022265969\n",
      "Validation loss mlp/pin: 0.496384/1.027293\n",
      "###### N,i = 5,1 #####\n",
      "M: 179.2925\n",
      "det: 6.597088e-05\n",
      "Validation loss mlp/pin: 1.464386/1.501628\n",
      "\n",
      "Epoch 454/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.584100/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484082/0.985176\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492948/1.534793\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17288\n",
      "det: 0.07172455\n",
      "Validation loss mlp/pin: 0.619686/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.162076\n",
      "det: 0.02226344\n",
      "Validation loss mlp/pin: 0.496330/1.027248\n",
      "###### N,i = 5,1 #####\n",
      "M: 179.89867\n",
      "det: 6.602646e-05\n",
      "Validation loss mlp/pin: 1.464382/1.501629\n",
      "\n",
      "Epoch 455/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.584026/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.484034/0.985133\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492941/1.534783\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1729403\n",
      "det: 0.071730375\n",
      "Validation loss mlp/pin: 0.619609/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.335918\n",
      "det: 0.022260932\n",
      "Validation loss mlp/pin: 0.496276/1.027204\n",
      "###### N,i = 5,1 #####\n",
      "M: 98.51989\n",
      "det: 6.607664e-05\n",
      "Validation loss mlp/pin: 1.464378/1.501634\n",
      "\n",
      "Epoch 456/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583950/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483980/0.985091\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492928/1.534747\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.173\n",
      "det: 0.07173615\n",
      "Validation loss mlp/pin: 0.619532/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.48066\n",
      "det: 0.02225849\n",
      "Validation loss mlp/pin: 0.496223/1.027161\n",
      "###### N,i = 5,1 #####\n",
      "M: 114.84441\n",
      "det: 6.613483e-05\n",
      "Validation loss mlp/pin: 1.464374/1.501633\n",
      "\n",
      "Epoch 457/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583877/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483930/0.985055\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492935/1.534794\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.173058\n",
      "det: 0.071741864\n",
      "Validation loss mlp/pin: 0.619456/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.532938\n",
      "det: 0.022256028\n",
      "Validation loss mlp/pin: 0.496171/1.027118\n",
      "###### N,i = 5,1 #####\n",
      "M: 144.46732\n",
      "det: 6.619447e-05\n",
      "Validation loss mlp/pin: 1.464370/1.501633\n",
      "\n",
      "Epoch 458/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583804/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483878/0.985013\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492918/1.534750\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1731167\n",
      "det: 0.071747564\n",
      "Validation loss mlp/pin: 0.619382/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.898437\n",
      "det: 0.022253618\n",
      "Validation loss mlp/pin: 0.496118/1.027075\n",
      "###### N,i = 5,1 #####\n",
      "M: 158.39973\n",
      "det: 6.625056e-05\n",
      "Validation loss mlp/pin: 1.464366/1.501633\n",
      "\n",
      "Epoch 459/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583732/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483825/0.984972\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492920/1.534773\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1731744\n",
      "det: 0.0717532\n",
      "Validation loss mlp/pin: 0.619307/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.894272\n",
      "det: 0.022251239\n",
      "Validation loss mlp/pin: 0.496067/1.027033\n",
      "###### N,i = 5,1 #####\n",
      "M: 96.57646\n",
      "det: 6.631003e-05\n",
      "Validation loss mlp/pin: 1.464362/1.501632\n",
      "\n",
      "Epoch 460/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583661/2.588987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483777/0.984934\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492910/1.534746\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.173231\n",
      "det: 0.07175874\n",
      "Validation loss mlp/pin: 0.619234/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.119459\n",
      "det: 0.022248872\n",
      "Validation loss mlp/pin: 0.496016/1.026991\n",
      "###### N,i = 5,1 #####\n",
      "M: 196.01532\n",
      "det: 6.636296e-05\n",
      "Validation loss mlp/pin: 1.464358/1.501632\n",
      "\n",
      "Epoch 461/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583590/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483726/0.984899\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492910/1.534772\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1732883\n",
      "det: 0.07176427\n",
      "Validation loss mlp/pin: 0.619161/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.846439\n",
      "det: 0.022246517\n",
      "Validation loss mlp/pin: 0.495966/1.026950\n",
      "###### N,i = 5,1 #####\n",
      "M: 128.94635\n",
      "det: 6.641101e-05\n",
      "Validation loss mlp/pin: 1.464354/1.501631\n",
      "\n",
      "Epoch 462/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583520/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483680/0.984861\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492906/1.534770\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1733437\n",
      "det: 0.071769714\n",
      "Validation loss mlp/pin: 0.619089/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.4596415\n",
      "det: 0.022244196\n",
      "Validation loss mlp/pin: 0.495916/1.026909\n",
      "###### N,i = 5,1 #####\n",
      "M: 176.52657\n",
      "det: 6.647691e-05\n",
      "Validation loss mlp/pin: 1.464351/1.501629\n",
      "\n",
      "Epoch 463/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583451/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483633/0.984820\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492899/1.534758\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.173398\n",
      "det: 0.071775086\n",
      "Validation loss mlp/pin: 0.619018/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.8584332\n",
      "det: 0.022241928\n",
      "Validation loss mlp/pin: 0.495866/1.026868\n",
      "###### N,i = 5,1 #####\n",
      "M: 98.52821\n",
      "det: 6.6524924e-05\n",
      "Validation loss mlp/pin: 1.464347/1.501633\n",
      "\n",
      "Epoch 464/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583383/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483585/0.984787\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492897/1.534768\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1734533\n",
      "det: 0.07178048\n",
      "Validation loss mlp/pin: 0.618948/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.830049\n",
      "det: 0.022239637\n",
      "Validation loss mlp/pin: 0.495817/1.026828\n",
      "###### N,i = 5,1 #####\n",
      "M: 101.21068\n",
      "det: 6.657783e-05\n",
      "Validation loss mlp/pin: 1.464343/1.501630\n",
      "\n",
      "Epoch 465/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583315/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483538/0.984747\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492887/1.534748\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1735077\n",
      "det: 0.07178578\n",
      "Validation loss mlp/pin: 0.618879/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.5274515\n",
      "det: 0.02223738\n",
      "Validation loss mlp/pin: 0.495769/1.026788\n",
      "###### N,i = 5,1 #####\n",
      "M: 106.00785\n",
      "det: 6.6625806e-05\n",
      "Validation loss mlp/pin: 1.464339/1.501626\n",
      "\n",
      "Epoch 466/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583248/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483491/0.984709\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492883/1.534748\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1735616\n",
      "det: 0.07179105\n",
      "Validation loss mlp/pin: 0.618810/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.810866\n",
      "det: 0.022235155\n",
      "Validation loss mlp/pin: 0.495721/1.026749\n",
      "###### N,i = 5,1 #####\n",
      "M: 158.45499\n",
      "det: 6.667681e-05\n",
      "Validation loss mlp/pin: 1.464336/1.501628\n",
      "\n",
      "Epoch 467/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583182/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483444/0.984672\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492889/1.534787\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.173615\n",
      "det: 0.07179628\n",
      "Validation loss mlp/pin: 0.618742/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.302441\n",
      "det: 0.022232959\n",
      "Validation loss mlp/pin: 0.495674/1.026710\n",
      "###### N,i = 5,1 #####\n",
      "M: 70.93084\n",
      "det: 6.674053e-05\n",
      "Validation loss mlp/pin: 1.464332/1.501622\n",
      "\n",
      "Epoch 468/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583117/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483401/0.984638\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492880/1.534772\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.173667\n",
      "det: 0.07180141\n",
      "Validation loss mlp/pin: 0.618674/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.329228\n",
      "det: 0.02223076\n",
      "Validation loss mlp/pin: 0.495626/1.026672\n",
      "###### N,i = 5,1 #####\n",
      "M: 140.72173\n",
      "det: 6.678793e-05\n",
      "Validation loss mlp/pin: 1.464328/1.501624\n",
      "\n",
      "Epoch 469/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.583052/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483354/0.984603\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492879/1.534776\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1737185\n",
      "det: 0.071806476\n",
      "Validation loss mlp/pin: 0.618608/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.94413\n",
      "det: 0.022228595\n",
      "Validation loss mlp/pin: 0.495580/1.026634\n",
      "###### N,i = 5,1 #####\n",
      "M: 60.860256\n",
      "det: 6.6832035e-05\n",
      "Validation loss mlp/pin: 1.464325/1.501629\n",
      "\n",
      "Epoch 470/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582987/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483308/0.984569\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492872/1.534757\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1737695\n",
      "det: 0.07181148\n",
      "Validation loss mlp/pin: 0.618542/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.39469\n",
      "det: 0.022226462\n",
      "Validation loss mlp/pin: 0.495534/1.026596\n",
      "###### N,i = 5,1 #####\n",
      "M: 85.96496\n",
      "det: 6.6888526e-05\n",
      "Validation loss mlp/pin: 1.464321/1.501630\n",
      "\n",
      "Epoch 471/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582924/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483265/0.984532\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492869/1.534771\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1738195\n",
      "det: 0.07181644\n",
      "Validation loss mlp/pin: 0.618476/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.300754\n",
      "det: 0.022224339\n",
      "Validation loss mlp/pin: 0.495488/1.026559\n",
      "###### N,i = 5,1 #####\n",
      "M: 132.60487\n",
      "det: 6.694252e-05\n",
      "Validation loss mlp/pin: 1.464318/1.501633\n",
      "\n",
      "Epoch 472/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582861/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483222/0.984498\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492868/1.534790\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1738696\n",
      "det: 0.071821354\n",
      "Validation loss mlp/pin: 0.618411/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.823746\n",
      "det: 0.022222236\n",
      "Validation loss mlp/pin: 0.495443/1.026522\n",
      "###### N,i = 5,1 #####\n",
      "M: 170.17491\n",
      "det: 6.69959e-05\n",
      "Validation loss mlp/pin: 1.464315/1.501634\n",
      "\n",
      "Epoch 473/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582799/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483179/0.984467\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492862/1.534771\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1739187\n",
      "det: 0.071826175\n",
      "Validation loss mlp/pin: 0.618347/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.20099\n",
      "det: 0.02222016\n",
      "Validation loss mlp/pin: 0.495399/1.026485\n",
      "###### N,i = 5,1 #####\n",
      "M: 111.85617\n",
      "det: 6.704311e-05\n",
      "Validation loss mlp/pin: 1.464311/1.501634\n",
      "\n",
      "Epoch 474/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582737/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483136/0.984431\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492854/1.534755\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1739674\n",
      "det: 0.071830966\n",
      "Validation loss mlp/pin: 0.618284/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.609247\n",
      "det: 0.022218114\n",
      "Validation loss mlp/pin: 0.495354/1.026449\n",
      "###### N,i = 5,1 #####\n",
      "M: 90.576645\n",
      "det: 6.7077555e-05\n",
      "Validation loss mlp/pin: 1.464308/1.501635\n",
      "\n",
      "Epoch 475/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582676/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483094/0.984396\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492857/1.534783\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.174015\n",
      "det: 0.07183571\n",
      "Validation loss mlp/pin: 0.618222/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.994781\n",
      "det: 0.02221606\n",
      "Validation loss mlp/pin: 0.495310/1.026413\n",
      "###### N,i = 5,1 #####\n",
      "M: 80.93148\n",
      "det: 6.713116e-05\n",
      "Validation loss mlp/pin: 1.464305/1.501640\n",
      "\n",
      "Epoch 476/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582616/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483052/0.984365\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492840/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.174062\n",
      "det: 0.07184038\n",
      "Validation loss mlp/pin: 0.618160/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.9290195\n",
      "det: 0.02221404\n",
      "Validation loss mlp/pin: 0.495267/1.026378\n",
      "###### N,i = 5,1 #####\n",
      "M: 82.04448\n",
      "det: 6.7179746e-05\n",
      "Validation loss mlp/pin: 1.464301/1.501637\n",
      "\n",
      "Epoch 477/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582556/2.588986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.483008/0.984330\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492848/1.534774\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1741085\n",
      "det: 0.07184503\n",
      "Validation loss mlp/pin: 0.618098/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.480672\n",
      "det: 0.022212034\n",
      "Validation loss mlp/pin: 0.495224/1.026343\n",
      "###### N,i = 5,1 #####\n",
      "M: 94.52069\n",
      "det: 6.722634e-05\n",
      "Validation loss mlp/pin: 1.464298/1.501635\n",
      "\n",
      "Epoch 478/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582497/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482967/0.984299\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492847/1.534790\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1741543\n",
      "det: 0.07184963\n",
      "Validation loss mlp/pin: 0.618037/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.56851\n",
      "det: 0.022210045\n",
      "Validation loss mlp/pin: 0.495182/1.026308\n",
      "###### N,i = 5,1 #####\n",
      "M: 162.85957\n",
      "det: 6.7277026e-05\n",
      "Validation loss mlp/pin: 1.464295/1.501636\n",
      "\n",
      "Epoch 479/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582439/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482926/0.984267\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492835/1.534759\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1741996\n",
      "det: 0.07185416\n",
      "Validation loss mlp/pin: 0.617977/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.594082\n",
      "det: 0.0222081\n",
      "Validation loss mlp/pin: 0.495140/1.026274\n",
      "###### N,i = 5,1 #####\n",
      "M: 85.64422\n",
      "det: 6.732911e-05\n",
      "Validation loss mlp/pin: 1.464291/1.501634\n",
      "\n",
      "Epoch 480/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582380/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482887/0.984237\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492829/1.534749\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1742444\n",
      "det: 0.07185865\n",
      "Validation loss mlp/pin: 0.617918/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.906143\n",
      "det: 0.022206176\n",
      "Validation loss mlp/pin: 0.495098/1.026240\n",
      "###### N,i = 5,1 #####\n",
      "M: 99.03712\n",
      "det: 6.7365574e-05\n",
      "Validation loss mlp/pin: 1.464289/1.501636\n",
      "\n",
      "Epoch 481/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582324/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482848/0.984204\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492829/1.534758\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1742887\n",
      "det: 0.07186307\n",
      "Validation loss mlp/pin: 0.617859/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.314284\n",
      "det: 0.022204248\n",
      "Validation loss mlp/pin: 0.495057/1.026206\n",
      "###### N,i = 5,1 #####\n",
      "M: 144.53441\n",
      "det: 6.741893e-05\n",
      "Validation loss mlp/pin: 1.464285/1.501633\n",
      "\n",
      "Epoch 482/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582267/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482807/0.984172\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492822/1.534750\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1743317\n",
      "det: 0.07186745\n",
      "Validation loss mlp/pin: 0.617800/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.618601\n",
      "det: 0.022202358\n",
      "Validation loss mlp/pin: 0.495016/1.026173\n",
      "###### N,i = 5,1 #####\n",
      "M: 131.1586\n",
      "det: 6.7463516e-05\n",
      "Validation loss mlp/pin: 1.464282/1.501633\n",
      "\n",
      "Epoch 483/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582210/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482771/0.984144\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492818/1.534746\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.174374\n",
      "det: 0.07187176\n",
      "Validation loss mlp/pin: 0.617743/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.582425\n",
      "det: 0.02220046\n",
      "Validation loss mlp/pin: 0.494976/1.026140\n",
      "###### N,i = 5,1 #####\n",
      "M: 68.36629\n",
      "det: 6.7503315e-05\n",
      "Validation loss mlp/pin: 1.464279/1.501632\n",
      "\n",
      "Epoch 484/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582155/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482731/0.984113\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492817/1.534754\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1744156\n",
      "det: 0.07187603\n",
      "Validation loss mlp/pin: 0.617685/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.0492225\n",
      "det: 0.022198588\n",
      "Validation loss mlp/pin: 0.494936/1.026107\n",
      "###### N,i = 5,1 #####\n",
      "M: 101.61906\n",
      "det: 6.754893e-05\n",
      "Validation loss mlp/pin: 1.464276/1.501629\n",
      "\n",
      "Epoch 485/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582100/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482693/0.984082\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492816/1.534770\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1744576\n",
      "det: 0.07188024\n",
      "Validation loss mlp/pin: 0.617629/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.637632\n",
      "det: 0.022196747\n",
      "Validation loss mlp/pin: 0.494897/1.026075\n",
      "###### N,i = 5,1 #####\n",
      "M: 64.2828\n",
      "det: 6.758938e-05\n",
      "Validation loss mlp/pin: 1.464272/1.501625\n",
      "\n",
      "Epoch 486/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.582045/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482653/0.984052\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492808/1.534747\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.174498\n",
      "det: 0.071884416\n",
      "Validation loss mlp/pin: 0.617573/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.122246\n",
      "det: 0.022194916\n",
      "Validation loss mlp/pin: 0.494858/1.026043\n",
      "###### N,i = 5,1 #####\n",
      "M: 215.3131\n",
      "det: 6.7624824e-05\n",
      "Validation loss mlp/pin: 1.464269/1.501623\n",
      "\n",
      "Epoch 487/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581991/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482618/0.984023\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492806/1.534752\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1745386\n",
      "det: 0.07188854\n",
      "Validation loss mlp/pin: 0.617517/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.729748\n",
      "det: 0.022193125\n",
      "Validation loss mlp/pin: 0.494819/1.026012\n",
      "###### N,i = 5,1 #####\n",
      "M: 26.602058\n",
      "det: 6.768166e-05\n",
      "Validation loss mlp/pin: 1.464266/1.501621\n",
      "\n",
      "Epoch 488/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581938/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482581/0.983992\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492800/1.534740\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.174578\n",
      "det: 0.07189259\n",
      "Validation loss mlp/pin: 0.617463/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.598717\n",
      "det: 0.022191303\n",
      "Validation loss mlp/pin: 0.494781/1.025981\n",
      "###### N,i = 5,1 #####\n",
      "M: 187.02473\n",
      "det: 6.772079e-05\n",
      "Validation loss mlp/pin: 1.464263/1.501622\n",
      "\n",
      "Epoch 489/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581886/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482545/0.983967\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492799/1.534757\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1746173\n",
      "det: 0.07189662\n",
      "Validation loss mlp/pin: 0.617408/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.296719\n",
      "det: 0.022189546\n",
      "Validation loss mlp/pin: 0.494743/1.025949\n",
      "###### N,i = 5,1 #####\n",
      "M: 99.303185\n",
      "det: 6.7768146e-05\n",
      "Validation loss mlp/pin: 1.464260/1.501621\n",
      "\n",
      "Epoch 490/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581833/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482506/0.983935\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492798/1.534761\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.174658\n",
      "det: 0.071900696\n",
      "Validation loss mlp/pin: 0.617355/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.344368\n",
      "det: 0.022187764\n",
      "Validation loss mlp/pin: 0.494705/1.025919\n",
      "###### N,i = 5,1 #####\n",
      "M: 69.10444\n",
      "det: 6.781368e-05\n",
      "Validation loss mlp/pin: 1.464257/1.501619\n",
      "\n",
      "Epoch 491/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581781/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482472/0.983909\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492797/1.534766\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.174697\n",
      "det: 0.0719047\n",
      "Validation loss mlp/pin: 0.617302/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.063462\n",
      "det: 0.022186065\n",
      "Validation loss mlp/pin: 0.494668/1.025888\n",
      "###### N,i = 5,1 #####\n",
      "M: 61.87611\n",
      "det: 6.78405e-05\n",
      "Validation loss mlp/pin: 1.464254/1.501621\n",
      "\n",
      "Epoch 492/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581731/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482436/0.983880\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492791/1.534756\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1747365\n",
      "det: 0.071908675\n",
      "Validation loss mlp/pin: 0.617249/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.393429\n",
      "det: 0.022184331\n",
      "Validation loss mlp/pin: 0.494631/1.025858\n",
      "###### N,i = 5,1 #####\n",
      "M: 120.72362\n",
      "det: 6.788149e-05\n",
      "Validation loss mlp/pin: 1.464252/1.501623\n",
      "\n",
      "Epoch 493/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581680/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482400/0.983853\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492786/1.534751\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.174775\n",
      "det: 0.07191261\n",
      "Validation loss mlp/pin: 0.617197/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.226312\n",
      "det: 0.022182649\n",
      "Validation loss mlp/pin: 0.494595/1.025828\n",
      "###### N,i = 5,1 #####\n",
      "M: 130.09433\n",
      "det: 6.7928144e-05\n",
      "Validation loss mlp/pin: 1.464249/1.501623\n",
      "\n",
      "Epoch 494/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581630/2.588986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482367/0.983826\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492784/1.534754\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1748133\n",
      "det: 0.07191649\n",
      "Validation loss mlp/pin: 0.617146/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.1590304\n",
      "det: 0.022180973\n",
      "Validation loss mlp/pin: 0.494559/1.025799\n",
      "###### N,i = 5,1 #####\n",
      "M: 83.22151\n",
      "det: 6.796807e-05\n",
      "Validation loss mlp/pin: 1.464246/1.501624\n",
      "\n",
      "Epoch 495/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581581/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482331/0.983798\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492780/1.534752\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.174851\n",
      "det: 0.07192032\n",
      "Validation loss mlp/pin: 0.617095/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.5310297\n",
      "det: 0.022179345\n",
      "Validation loss mlp/pin: 0.494523/1.025770\n",
      "###### N,i = 5,1 #####\n",
      "M: 138.72894\n",
      "det: 6.798659e-05\n",
      "Validation loss mlp/pin: 1.464243/1.501623\n",
      "\n",
      "Epoch 496/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581532/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482297/0.983771\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492776/1.534748\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1748886\n",
      "det: 0.07192411\n",
      "Validation loss mlp/pin: 0.617044/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.028838\n",
      "det: 0.02217766\n",
      "Validation loss mlp/pin: 0.494488/1.025741\n",
      "###### N,i = 5,1 #####\n",
      "M: 89.240326\n",
      "det: 6.803612e-05\n",
      "Validation loss mlp/pin: 1.464240/1.501626\n",
      "\n",
      "Epoch 497/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581483/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482264/0.983744\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492773/1.534746\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.174925\n",
      "det: 0.071927875\n",
      "Validation loss mlp/pin: 0.616994/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.725687\n",
      "det: 0.02217604\n",
      "Validation loss mlp/pin: 0.494454/1.025712\n",
      "###### N,i = 5,1 #####\n",
      "M: 59.11815\n",
      "det: 6.808548e-05\n",
      "Validation loss mlp/pin: 1.464238/1.501627\n",
      "\n",
      "Epoch 498/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581435/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482231/0.983718\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492773/1.534761\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.174961\n",
      "det: 0.071931586\n",
      "Validation loss mlp/pin: 0.616945/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.7757025\n",
      "det: 0.022174437\n",
      "Validation loss mlp/pin: 0.494419/1.025684\n",
      "###### N,i = 5,1 #####\n",
      "M: 89.14219\n",
      "det: 6.8117115e-05\n",
      "Validation loss mlp/pin: 1.464235/1.501629\n",
      "\n",
      "Epoch 499/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581387/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482197/0.983691\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492770/1.534764\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.174997\n",
      "det: 0.07193525\n",
      "Validation loss mlp/pin: 0.616896/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.007225\n",
      "det: 0.02217287\n",
      "Validation loss mlp/pin: 0.494385/1.025656\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.81672\n",
      "det: 6.815495e-05\n",
      "Validation loss mlp/pin: 1.464233/1.501630\n",
      "\n",
      "Epoch 500/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581340/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482165/0.983665\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492764/1.534749\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1750326\n",
      "det: 0.07193889\n",
      "Validation loss mlp/pin: 0.616848/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.547315\n",
      "det: 0.022171274\n",
      "Validation loss mlp/pin: 0.494351/1.025629\n",
      "###### N,i = 5,1 #####\n",
      "M: 175.14832\n",
      "det: 6.819028e-05\n",
      "Validation loss mlp/pin: 1.464230/1.501628\n",
      "\n",
      "Epoch 501/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581294/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482137/0.983641\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492766/1.534768\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175068\n",
      "det: 0.07194247\n",
      "Validation loss mlp/pin: 0.616800/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.871418\n",
      "det: 0.022169735\n",
      "Validation loss mlp/pin: 0.494318/1.025601\n",
      "###### N,i = 5,1 #####\n",
      "M: 131.1755\n",
      "det: 6.823121e-05\n",
      "Validation loss mlp/pin: 1.464228/1.501630\n",
      "\n",
      "Epoch 502/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581247/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482100/0.983614\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492761/1.534759\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1751027\n",
      "det: 0.071946\n",
      "Validation loss mlp/pin: 0.616752/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.619396\n",
      "det: 0.022168174\n",
      "Validation loss mlp/pin: 0.494284/1.025574\n",
      "###### N,i = 5,1 #####\n",
      "M: 156.04816\n",
      "det: 6.82797e-05\n",
      "Validation loss mlp/pin: 1.464225/1.501628\n",
      "\n",
      "Epoch 503/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581202/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482070/0.983589\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492758/1.534758\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1751366\n",
      "det: 0.07194953\n",
      "Validation loss mlp/pin: 0.616705/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.707063\n",
      "det: 0.022166654\n",
      "Validation loss mlp/pin: 0.494252/1.025547\n",
      "###### N,i = 5,1 #####\n",
      "M: 79.36589\n",
      "det: 6.830324e-05\n",
      "Validation loss mlp/pin: 1.464223/1.501630\n",
      "\n",
      "Epoch 504/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581157/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482039/0.983564\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492754/1.534752\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17517\n",
      "det: 0.07195299\n",
      "Validation loss mlp/pin: 0.616659/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.6347885\n",
      "det: 0.022165136\n",
      "Validation loss mlp/pin: 0.494219/1.025521\n",
      "###### N,i = 5,1 #####\n",
      "M: 84.08668\n",
      "det: 6.835236e-05\n",
      "Validation loss mlp/pin: 1.464220/1.501628\n",
      "\n",
      "Epoch 505/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581112/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.482006/0.983539\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492753/1.534760\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175204\n",
      "det: 0.0719564\n",
      "Validation loss mlp/pin: 0.616613/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.653643\n",
      "det: 0.02216363\n",
      "Validation loss mlp/pin: 0.494187/1.025494\n",
      "###### N,i = 5,1 #####\n",
      "M: 162.22372\n",
      "det: 6.8384994e-05\n",
      "Validation loss mlp/pin: 1.464218/1.501627\n",
      "\n",
      "Epoch 506/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581068/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481976/0.983518\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492744/1.534737\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175237\n",
      "det: 0.07195983\n",
      "Validation loss mlp/pin: 0.616568/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.025273\n",
      "det: 0.022162145\n",
      "Validation loss mlp/pin: 0.494155/1.025468\n",
      "###### N,i = 5,1 #####\n",
      "M: 63.802567\n",
      "det: 6.841346e-05\n",
      "Validation loss mlp/pin: 1.464215/1.501628\n",
      "\n",
      "Epoch 507/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.581025/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481947/0.983491\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492745/1.534752\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17527\n",
      "det: 0.07196325\n",
      "Validation loss mlp/pin: 0.616523/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.4379635\n",
      "det: 0.022160685\n",
      "Validation loss mlp/pin: 0.494123/1.025442\n",
      "###### N,i = 5,1 #####\n",
      "M: 91.724045\n",
      "det: 6.845323e-05\n",
      "Validation loss mlp/pin: 1.464213/1.501629\n",
      "\n",
      "Epoch 508/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580981/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481915/0.983467\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492741/1.534746\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1753035\n",
      "det: 0.071966626\n",
      "Validation loss mlp/pin: 0.616478/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 18.57564\n",
      "det: 0.02215921\n",
      "Validation loss mlp/pin: 0.494092/1.025417\n",
      "###### N,i = 5,1 #####\n",
      "M: 128.20718\n",
      "det: 6.848935e-05\n",
      "Validation loss mlp/pin: 1.464211/1.501630\n",
      "\n",
      "Epoch 509/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580938/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481886/0.983444\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492738/1.534750\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1753364\n",
      "det: 0.07196997\n",
      "Validation loss mlp/pin: 0.616434/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.788653\n",
      "det: 0.022157762\n",
      "Validation loss mlp/pin: 0.494061/1.025392\n",
      "###### N,i = 5,1 #####\n",
      "M: 124.37689\n",
      "det: 6.852145e-05\n",
      "Validation loss mlp/pin: 1.464208/1.501630\n",
      "\n",
      "Epoch 510/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580896/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481856/0.983420\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492735/1.534750\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175369\n",
      "det: 0.07197328\n",
      "Validation loss mlp/pin: 0.616390/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.5447493\n",
      "det: 0.022156352\n",
      "Validation loss mlp/pin: 0.494031/1.025367\n",
      "###### N,i = 5,1 #####\n",
      "M: 63.579174\n",
      "det: 6.855812e-05\n",
      "Validation loss mlp/pin: 1.464206/1.501630\n",
      "\n",
      "Epoch 511/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580854/2.588986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481829/0.983397\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492735/1.534756\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175401\n",
      "det: 0.07197653\n",
      "Validation loss mlp/pin: 0.616347/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.692485\n",
      "det: 0.02215496\n",
      "Validation loss mlp/pin: 0.494001/1.025342\n",
      "###### N,i = 5,1 #####\n",
      "M: 84.84189\n",
      "det: 6.858647e-05\n",
      "Validation loss mlp/pin: 1.464204/1.501627\n",
      "\n",
      "Epoch 512/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580812/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481798/0.983375\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492735/1.534768\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1754327\n",
      "det: 0.07197979\n",
      "Validation loss mlp/pin: 0.616305/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.466486\n",
      "det: 0.022153568\n",
      "Validation loss mlp/pin: 0.493971/1.025318\n",
      "###### N,i = 5,1 #####\n",
      "M: 49.817226\n",
      "det: 6.862291e-05\n",
      "Validation loss mlp/pin: 1.464202/1.501627\n",
      "\n",
      "Epoch 513/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580771/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481770/0.983353\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492728/1.534749\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1754637\n",
      "det: 0.071983\n",
      "Validation loss mlp/pin: 0.616262/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.016848\n",
      "det: 0.02215217\n",
      "Validation loss mlp/pin: 0.493941/1.025293\n",
      "###### N,i = 5,1 #####\n",
      "M: 119.506714\n",
      "det: 6.86482e-05\n",
      "Validation loss mlp/pin: 1.464199/1.501628\n",
      "\n",
      "Epoch 514/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580731/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481742/0.983331\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492727/1.534758\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175495\n",
      "det: 0.07198616\n",
      "Validation loss mlp/pin: 0.616220/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.226054\n",
      "det: 0.022150775\n",
      "Validation loss mlp/pin: 0.493912/1.025269\n",
      "###### N,i = 5,1 #####\n",
      "M: 183.24356\n",
      "det: 6.86889e-05\n",
      "Validation loss mlp/pin: 1.464197/1.501629\n",
      "\n",
      "Epoch 515/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580690/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481714/0.983308\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492726/1.534765\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1755257\n",
      "det: 0.0719893\n",
      "Validation loss mlp/pin: 0.616179/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.736902\n",
      "det: 0.022149405\n",
      "Validation loss mlp/pin: 0.493882/1.025246\n",
      "###### N,i = 5,1 #####\n",
      "M: 85.39201\n",
      "det: 6.871552e-05\n",
      "Validation loss mlp/pin: 1.464195/1.501630\n",
      "\n",
      "Epoch 516/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580650/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481685/0.983285\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492720/1.534747\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1755557\n",
      "det: 0.07199239\n",
      "Validation loss mlp/pin: 0.616138/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.407401\n",
      "det: 0.022148043\n",
      "Validation loss mlp/pin: 0.493854/1.025222\n",
      "###### N,i = 5,1 #####\n",
      "M: 95.70265\n",
      "det: 6.875595e-05\n",
      "Validation loss mlp/pin: 1.464193/1.501630\n",
      "\n",
      "Epoch 517/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580611/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481657/0.983263\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492716/1.534743\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1755857\n",
      "det: 0.071995445\n",
      "Validation loss mlp/pin: 0.616097/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.874107\n",
      "det: 0.022146713\n",
      "Validation loss mlp/pin: 0.493825/1.025199\n",
      "###### N,i = 5,1 #####\n",
      "M: 93.59225\n",
      "det: 6.878618e-05\n",
      "Validation loss mlp/pin: 1.464190/1.501629\n",
      "\n",
      "Epoch 518/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580572/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481630/0.983243\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492723/1.534785\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1756153\n",
      "det: 0.07199849\n",
      "Validation loss mlp/pin: 0.616057/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.179672\n",
      "det: 0.022145366\n",
      "Validation loss mlp/pin: 0.493797/1.025175\n",
      "###### N,i = 5,1 #####\n",
      "M: 97.979294\n",
      "det: 6.881369e-05\n",
      "Validation loss mlp/pin: 1.464188/1.501626\n",
      "\n",
      "Epoch 519/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580533/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481603/0.983220\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492717/1.534765\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175644\n",
      "det: 0.07200149\n",
      "Validation loss mlp/pin: 0.616017/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.696274\n",
      "det: 0.022144046\n",
      "Validation loss mlp/pin: 0.493769/1.025153\n",
      "###### N,i = 5,1 #####\n",
      "M: 96.33621\n",
      "det: 6.885062e-05\n",
      "Validation loss mlp/pin: 1.464186/1.501627\n",
      "\n",
      "Epoch 520/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580495/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481577/0.983199\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492711/1.534752\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1756725\n",
      "det: 0.07200444\n",
      "Validation loss mlp/pin: 0.615978/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.470127\n",
      "det: 0.022142759\n",
      "Validation loss mlp/pin: 0.493742/1.025130\n",
      "###### N,i = 5,1 #####\n",
      "M: 124.60758\n",
      "det: 6.88735e-05\n",
      "Validation loss mlp/pin: 1.464184/1.501628\n",
      "\n",
      "Epoch 521/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580457/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481550/0.983180\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492708/1.534748\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175701\n",
      "det: 0.07200739\n",
      "Validation loss mlp/pin: 0.615939/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.779173\n",
      "det: 0.022141483\n",
      "Validation loss mlp/pin: 0.493714/1.025108\n",
      "###### N,i = 5,1 #####\n",
      "M: 192.64807\n",
      "det: 6.891124e-05\n",
      "Validation loss mlp/pin: 1.464182/1.501628\n",
      "\n",
      "Epoch 522/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580419/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481526/0.983160\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492705/1.534745\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175729\n",
      "det: 0.07201028\n",
      "Validation loss mlp/pin: 0.615900/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.1719885\n",
      "det: 0.022140201\n",
      "Validation loss mlp/pin: 0.493688/1.025086\n",
      "###### N,i = 5,1 #####\n",
      "M: 112.35416\n",
      "det: 6.89313e-05\n",
      "Validation loss mlp/pin: 1.464180/1.501627\n",
      "\n",
      "Epoch 523/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580383/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481497/0.983138\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492704/1.534752\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1757565\n",
      "det: 0.07201313\n",
      "Validation loss mlp/pin: 0.615862/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.913208\n",
      "det: 0.022138957\n",
      "Validation loss mlp/pin: 0.493661/1.025064\n",
      "###### N,i = 5,1 #####\n",
      "M: 67.969055\n",
      "det: 6.8974194e-05\n",
      "Validation loss mlp/pin: 1.464178/1.501629\n",
      "\n",
      "Epoch 524/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580346/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481474/0.983118\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492701/1.534748\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175784\n",
      "det: 0.07201599\n",
      "Validation loss mlp/pin: 0.615825/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.595894\n",
      "det: 0.022137715\n",
      "Validation loss mlp/pin: 0.493634/1.025042\n",
      "###### N,i = 5,1 #####\n",
      "M: 111.25102\n",
      "det: 6.899905e-05\n",
      "Validation loss mlp/pin: 1.464176/1.501629\n",
      "\n",
      "Epoch 525/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580310/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481445/0.983098\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492699/1.534748\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175811\n",
      "det: 0.072018795\n",
      "Validation loss mlp/pin: 0.615788/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.081096\n",
      "det: 0.02213648\n",
      "Validation loss mlp/pin: 0.493608/1.025021\n",
      "###### N,i = 5,1 #####\n",
      "M: 112.466194\n",
      "det: 6.9023496e-05\n",
      "Validation loss mlp/pin: 1.464174/1.501627\n",
      "\n",
      "Epoch 526/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580274/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481421/0.983077\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492697/1.534754\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175838\n",
      "det: 0.07202156\n",
      "Validation loss mlp/pin: 0.615750/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.9576\n",
      "det: 0.022135267\n",
      "Validation loss mlp/pin: 0.493582/1.025000\n",
      "###### N,i = 5,1 #####\n",
      "M: 83.44025\n",
      "det: 6.905399e-05\n",
      "Validation loss mlp/pin: 1.464172/1.501627\n",
      "\n",
      "Epoch 527/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580238/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481396/0.983058\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492692/1.534739\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175864\n",
      "det: 0.07202429\n",
      "Validation loss mlp/pin: 0.615714/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.646166\n",
      "det: 0.022134054\n",
      "Validation loss mlp/pin: 0.493557/1.024979\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.51544\n",
      "det: 6.90824e-05\n",
      "Validation loss mlp/pin: 1.464170/1.501628\n",
      "\n",
      "Epoch 528/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580203/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481373/0.983039\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492694/1.534769\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175891\n",
      "det: 0.072027005\n",
      "Validation loss mlp/pin: 0.615677/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.526567\n",
      "det: 0.022132883\n",
      "Validation loss mlp/pin: 0.493531/1.024958\n",
      "###### N,i = 5,1 #####\n",
      "M: 91.907616\n",
      "det: 6.911066e-05\n",
      "Validation loss mlp/pin: 1.464168/1.501625\n",
      "\n",
      "Epoch 529/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580168/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481349/0.983020\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492689/1.534744\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1759167\n",
      "det: 0.07202972\n",
      "Validation loss mlp/pin: 0.615641/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.3123045\n",
      "det: 0.022131722\n",
      "Validation loss mlp/pin: 0.493506/1.024938\n",
      "###### N,i = 5,1 #####\n",
      "M: 85.40347\n",
      "det: 6.915168e-05\n",
      "Validation loss mlp/pin: 1.464166/1.501624\n",
      "\n",
      "Epoch 530/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580133/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481322/0.983001\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492685/1.534741\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1759424\n",
      "det: 0.07203237\n",
      "Validation loss mlp/pin: 0.615606/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.45194\n",
      "det: 0.022130555\n",
      "Validation loss mlp/pin: 0.493481/1.024917\n",
      "###### N,i = 5,1 #####\n",
      "M: 205.09851\n",
      "det: 6.9163114e-05\n",
      "Validation loss mlp/pin: 1.464164/1.501622\n",
      "\n",
      "Epoch 531/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580099/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481300/0.982981\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492681/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175967\n",
      "det: 0.072035\n",
      "Validation loss mlp/pin: 0.615571/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.036147\n",
      "det: 0.022129392\n",
      "Validation loss mlp/pin: 0.493457/1.024897\n",
      "###### N,i = 5,1 #####\n",
      "M: 37.74532\n",
      "det: 6.919388e-05\n",
      "Validation loss mlp/pin: 1.464162/1.501624\n",
      "\n",
      "Epoch 532/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580065/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481276/0.982963\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492686/1.534763\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.175992\n",
      "det: 0.072037615\n",
      "Validation loss mlp/pin: 0.615536/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.602572\n",
      "det: 0.02212827\n",
      "Validation loss mlp/pin: 0.493432/1.024877\n",
      "###### N,i = 5,1 #####\n",
      "M: 95.185425\n",
      "det: 6.9233836e-05\n",
      "Validation loss mlp/pin: 1.464160/1.501622\n",
      "\n",
      "Epoch 533/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.580031/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481252/0.982944\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492680/1.534749\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176017\n",
      "det: 0.07204018\n",
      "Validation loss mlp/pin: 0.615501/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.488449\n",
      "det: 0.022127135\n",
      "Validation loss mlp/pin: 0.493408/1.024857\n",
      "###### N,i = 5,1 #####\n",
      "M: 70.96489\n",
      "det: 6.925449e-05\n",
      "Validation loss mlp/pin: 1.464159/1.501623\n",
      "\n",
      "Epoch 534/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579998/2.588987\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481229/0.982926\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492677/1.534746\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176041\n",
      "det: 0.07204274\n",
      "Validation loss mlp/pin: 0.615467/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.026809\n",
      "det: 0.022126028\n",
      "Validation loss mlp/pin: 0.493384/1.024838\n",
      "###### N,i = 5,1 #####\n",
      "M: 88.185715\n",
      "det: 6.927487e-05\n",
      "Validation loss mlp/pin: 1.464157/1.501623\n",
      "\n",
      "Epoch 535/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579966/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481207/0.982908\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492674/1.534738\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1760654\n",
      "det: 0.07204526\n",
      "Validation loss mlp/pin: 0.615434/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.562417\n",
      "det: 0.02212494\n",
      "Validation loss mlp/pin: 0.493361/1.024819\n",
      "###### N,i = 5,1 #####\n",
      "M: 108.303696\n",
      "det: 6.9305075e-05\n",
      "Validation loss mlp/pin: 1.464155/1.501624\n",
      "\n",
      "Epoch 536/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579933/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481183/0.982890\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492673/1.534746\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1760893\n",
      "det: 0.072047755\n",
      "Validation loss mlp/pin: 0.615400/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.877257\n",
      "det: 0.02212382\n",
      "Validation loss mlp/pin: 0.493337/1.024799\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.9857\n",
      "det: 6.9325695e-05\n",
      "Validation loss mlp/pin: 1.464153/1.501624\n",
      "\n",
      "Epoch 537/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579901/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481161/0.982873\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492674/1.534759\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176112\n",
      "det: 0.0720502\n",
      "Validation loss mlp/pin: 0.615367/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.589932\n",
      "det: 0.02212274\n",
      "Validation loss mlp/pin: 0.493314/1.024781\n",
      "###### N,i = 5,1 #####\n",
      "M: 64.890015\n",
      "det: 6.9359565e-05\n",
      "Validation loss mlp/pin: 1.464151/1.501624\n",
      "\n",
      "Epoch 538/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579869/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481138/0.982856\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492667/1.534738\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176136\n",
      "det: 0.07205264\n",
      "Validation loss mlp/pin: 0.615334/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.801679\n",
      "det: 0.02212167\n",
      "Validation loss mlp/pin: 0.493291/1.024762\n",
      "###### N,i = 5,1 #####\n",
      "M: 59.223682\n",
      "det: 6.9386006e-05\n",
      "Validation loss mlp/pin: 1.464150/1.501625\n",
      "\n",
      "Epoch 539/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579837/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481119/0.982840\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492667/1.534743\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1761584\n",
      "det: 0.07205505\n",
      "Validation loss mlp/pin: 0.615302/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.143848\n",
      "det: 0.02212061\n",
      "Validation loss mlp/pin: 0.493269/1.024743\n",
      "###### N,i = 5,1 #####\n",
      "M: 171.31299\n",
      "det: 6.941165e-05\n",
      "Validation loss mlp/pin: 1.464148/1.501624\n",
      "\n",
      "Epoch 540/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579806/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481095/0.982820\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492665/1.534747\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176181\n",
      "det: 0.07205745\n",
      "Validation loss mlp/pin: 0.615270/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.614918\n",
      "det: 0.02211958\n",
      "Validation loss mlp/pin: 0.493246/1.024725\n",
      "###### N,i = 5,1 #####\n",
      "M: 152.96855\n",
      "det: 6.9443515e-05\n",
      "Validation loss mlp/pin: 1.464146/1.501624\n",
      "\n",
      "Epoch 541/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579775/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481073/0.982804\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492665/1.534751\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1762033\n",
      "det: 0.07205981\n",
      "Validation loss mlp/pin: 0.615238/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.4676747\n",
      "det: 0.022118544\n",
      "Validation loss mlp/pin: 0.493224/1.024707\n",
      "###### N,i = 5,1 #####\n",
      "M: 135.50806\n",
      "det: 6.946996e-05\n",
      "Validation loss mlp/pin: 1.464144/1.501625\n",
      "\n",
      "Epoch 542/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579745/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481052/0.982787\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492661/1.534742\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1762257\n",
      "det: 0.07206214\n",
      "Validation loss mlp/pin: 0.615207/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.470093\n",
      "det: 0.022117516\n",
      "Validation loss mlp/pin: 0.493202/1.024688\n",
      "###### N,i = 5,1 #####\n",
      "M: 83.94682\n",
      "det: 6.9489666e-05\n",
      "Validation loss mlp/pin: 1.464142/1.501625\n",
      "\n",
      "Epoch 543/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579714/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481031/0.982769\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492661/1.534751\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1762476\n",
      "det: 0.07206446\n",
      "Validation loss mlp/pin: 0.615176/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.556852\n",
      "det: 0.022116506\n",
      "Validation loss mlp/pin: 0.493180/1.024671\n",
      "###### N,i = 5,1 #####\n",
      "M: 173.31282\n",
      "det: 6.951456e-05\n",
      "Validation loss mlp/pin: 1.464141/1.501626\n",
      "\n",
      "Epoch 544/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579685/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.481011/0.982754\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492656/1.534740\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1762695\n",
      "det: 0.07206676\n",
      "Validation loss mlp/pin: 0.615145/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.39238\n",
      "det: 0.022115521\n",
      "Validation loss mlp/pin: 0.493158/1.024653\n",
      "###### N,i = 5,1 #####\n",
      "M: 185.42526\n",
      "det: 6.954354e-05\n",
      "Validation loss mlp/pin: 1.464139/1.501626\n",
      "\n",
      "Epoch 545/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579655/2.588986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480989/0.982736\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492658/1.534756\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1762905\n",
      "det: 0.072069034\n",
      "Validation loss mlp/pin: 0.615114/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.866734\n",
      "det: 0.022114502\n",
      "Validation loss mlp/pin: 0.493137/1.024635\n",
      "###### N,i = 5,1 #####\n",
      "M: 217.7032\n",
      "det: 6.95575e-05\n",
      "Validation loss mlp/pin: 1.464138/1.501628\n",
      "\n",
      "Epoch 546/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579625/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480969/0.982720\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492654/1.534748\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1763115\n",
      "det: 0.07207128\n",
      "Validation loss mlp/pin: 0.615084/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.315715\n",
      "det: 0.02211349\n",
      "Validation loss mlp/pin: 0.493116/1.024618\n",
      "###### N,i = 5,1 #####\n",
      "M: 131.25316\n",
      "det: 6.959404e-05\n",
      "Validation loss mlp/pin: 1.464136/1.501627\n",
      "\n",
      "Epoch 547/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579596/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480949/0.982704\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492651/1.534742\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1763325\n",
      "det: 0.07207349\n",
      "Validation loss mlp/pin: 0.615054/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.727043\n",
      "det: 0.02211252\n",
      "Validation loss mlp/pin: 0.493095/1.024601\n",
      "###### N,i = 5,1 #####\n",
      "M: 76.15166\n",
      "det: 6.9606016e-05\n",
      "Validation loss mlp/pin: 1.464135/1.501627\n",
      "\n",
      "Epoch 548/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579567/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480929/0.982689\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492656/1.534775\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176353\n",
      "det: 0.07207568\n",
      "Validation loss mlp/pin: 0.615025/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.352965\n",
      "det: 0.022111569\n",
      "Validation loss mlp/pin: 0.493074/1.024584\n",
      "###### N,i = 5,1 #####\n",
      "M: 124.26974\n",
      "det: 6.963211e-05\n",
      "Validation loss mlp/pin: 1.464133/1.501626\n",
      "\n",
      "Epoch 549/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579539/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480909/0.982672\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492646/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176373\n",
      "det: 0.07207785\n",
      "Validation loss mlp/pin: 0.614995/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.195155\n",
      "det: 0.022110581\n",
      "Validation loss mlp/pin: 0.493053/1.024567\n",
      "###### N,i = 5,1 #####\n",
      "M: 118.566895\n",
      "det: 6.966615e-05\n",
      "Validation loss mlp/pin: 1.464131/1.501626\n",
      "\n",
      "Epoch 550/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579511/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480890/0.982658\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492645/1.534739\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1763935\n",
      "det: 0.07207999\n",
      "Validation loss mlp/pin: 0.614966/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.770063\n",
      "det: 0.022109644\n",
      "Validation loss mlp/pin: 0.493033/1.024550\n",
      "###### N,i = 5,1 #####\n",
      "M: 206.90321\n",
      "det: 6.968464e-05\n",
      "Validation loss mlp/pin: 1.464129/1.501627\n",
      "\n",
      "Epoch 551/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579483/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480872/0.982642\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492642/1.534736\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1764145\n",
      "det: 0.07208215\n",
      "Validation loss mlp/pin: 0.614938/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.1452284\n",
      "det: 0.022108704\n",
      "Validation loss mlp/pin: 0.493013/1.024534\n",
      "###### N,i = 5,1 #####\n",
      "M: 74.12605\n",
      "det: 6.970041e-05\n",
      "Validation loss mlp/pin: 1.464128/1.501627\n",
      "\n",
      "Epoch 552/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579455/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480851/0.982626\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492643/1.534751\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1764345\n",
      "det: 0.07208427\n",
      "Validation loss mlp/pin: 0.614909/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.144556\n",
      "det: 0.022107778\n",
      "Validation loss mlp/pin: 0.492993/1.024517\n",
      "###### N,i = 5,1 #####\n",
      "M: 125.65541\n",
      "det: 6.9731825e-05\n",
      "Validation loss mlp/pin: 1.464127/1.501628\n",
      "\n",
      "Epoch 553/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579428/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480832/0.982612\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492643/1.534753\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1764545\n",
      "det: 0.07208638\n",
      "Validation loss mlp/pin: 0.614881/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.224662\n",
      "det: 0.022106875\n",
      "Validation loss mlp/pin: 0.492973/1.024501\n",
      "###### N,i = 5,1 #####\n",
      "M: 95.56915\n",
      "det: 6.974533e-05\n",
      "Validation loss mlp/pin: 1.464125/1.501627\n",
      "\n",
      "Epoch 554/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579401/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480813/0.982597\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492637/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1764746\n",
      "det: 0.07208846\n",
      "Validation loss mlp/pin: 0.614853/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.357827\n",
      "det: 0.022105958\n",
      "Validation loss mlp/pin: 0.492954/1.024486\n",
      "###### N,i = 5,1 #####\n",
      "M: 162.9344\n",
      "det: 6.97723e-05\n",
      "Validation loss mlp/pin: 1.464124/1.501628\n",
      "\n",
      "Epoch 555/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579374/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480794/0.982583\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492635/1.534736\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1764946\n",
      "det: 0.072090514\n",
      "Validation loss mlp/pin: 0.614826/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.035303\n",
      "det: 0.02210506\n",
      "Validation loss mlp/pin: 0.492934/1.024470\n",
      "###### N,i = 5,1 #####\n",
      "M: 98.19659\n",
      "det: 6.9792e-05\n",
      "Validation loss mlp/pin: 1.464122/1.501628\n",
      "\n",
      "Epoch 556/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579348/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480775/0.982567\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492635/1.534745\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1765137\n",
      "det: 0.072092585\n",
      "Validation loss mlp/pin: 0.614799/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.196406\n",
      "det: 0.022104172\n",
      "Validation loss mlp/pin: 0.492915/1.024454\n",
      "###### N,i = 5,1 #####\n",
      "M: 75.181946\n",
      "det: 6.981608e-05\n",
      "Validation loss mlp/pin: 1.464120/1.501627\n",
      "\n",
      "Epoch 557/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579322/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480757/0.982553\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492633/1.534740\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1765327\n",
      "det: 0.0720946\n",
      "Validation loss mlp/pin: 0.614772/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.877729\n",
      "det: 0.022103276\n",
      "Validation loss mlp/pin: 0.492896/1.024439\n",
      "###### N,i = 5,1 #####\n",
      "M: 174.81494\n",
      "det: 6.9833244e-05\n",
      "Validation loss mlp/pin: 1.464119/1.501627\n",
      "\n",
      "Epoch 558/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579296/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480740/0.982538\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492632/1.534743\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176552\n",
      "det: 0.0720966\n",
      "Validation loss mlp/pin: 0.614745/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.408537\n",
      "det: 0.022102378\n",
      "Validation loss mlp/pin: 0.492877/1.024423\n",
      "###### N,i = 5,1 #####\n",
      "M: 90.81768\n",
      "det: 6.9859736e-05\n",
      "Validation loss mlp/pin: 1.464118/1.501627\n",
      "\n",
      "Epoch 559/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579270/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480721/0.982525\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492630/1.534745\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1765704\n",
      "det: 0.07209859\n",
      "Validation loss mlp/pin: 0.614719/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.551043\n",
      "det: 0.022101512\n",
      "Validation loss mlp/pin: 0.492859/1.024408\n",
      "###### N,i = 5,1 #####\n",
      "M: 204.48059\n",
      "det: 6.987649e-05\n",
      "Validation loss mlp/pin: 1.464116/1.501627\n",
      "\n",
      "Epoch 560/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579245/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480703/0.982510\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492629/1.534741\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176589\n",
      "det: 0.07210055\n",
      "Validation loss mlp/pin: 0.614693/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.765576\n",
      "det: 0.022100648\n",
      "Validation loss mlp/pin: 0.492840/1.024393\n",
      "###### N,i = 5,1 #####\n",
      "M: 60.16069\n",
      "det: 6.9897345e-05\n",
      "Validation loss mlp/pin: 1.464115/1.501627\n",
      "\n",
      "Epoch 561/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579220/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480685/0.982496\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492627/1.534741\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176607\n",
      "det: 0.07210248\n",
      "Validation loss mlp/pin: 0.614667/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.987494\n",
      "det: 0.022099817\n",
      "Validation loss mlp/pin: 0.492822/1.024378\n",
      "###### N,i = 5,1 #####\n",
      "M: 79.28422\n",
      "det: 6.992558e-05\n",
      "Validation loss mlp/pin: 1.464113/1.501627\n",
      "\n",
      "Epoch 562/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579195/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480668/0.982482\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492625/1.534743\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176626\n",
      "det: 0.07210441\n",
      "Validation loss mlp/pin: 0.614641/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.606077\n",
      "det: 0.022098983\n",
      "Validation loss mlp/pin: 0.492804/1.024364\n",
      "###### N,i = 5,1 #####\n",
      "M: 188.06122\n",
      "det: 6.9943635e-05\n",
      "Validation loss mlp/pin: 1.464112/1.501627\n",
      "\n",
      "Epoch 563/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579170/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480651/0.982469\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492623/1.534739\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1766434\n",
      "det: 0.07210628\n",
      "Validation loss mlp/pin: 0.614615/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.46558\n",
      "det: 0.022098124\n",
      "Validation loss mlp/pin: 0.492786/1.024349\n",
      "###### N,i = 5,1 #####\n",
      "M: 73.04765\n",
      "det: 6.995758e-05\n",
      "Validation loss mlp/pin: 1.464110/1.501627\n",
      "\n",
      "Epoch 564/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579145/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480634/0.982456\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492622/1.534741\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1766615\n",
      "det: 0.072108164\n",
      "Validation loss mlp/pin: 0.614590/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.277775\n",
      "det: 0.022097297\n",
      "Validation loss mlp/pin: 0.492769/1.024335\n",
      "###### N,i = 5,1 #####\n",
      "M: 126.10058\n",
      "det: 6.9985574e-05\n",
      "Validation loss mlp/pin: 1.464109/1.501628\n",
      "\n",
      "Epoch 565/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579121/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480618/0.982443\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492618/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1766787\n",
      "det: 0.07211003\n",
      "Validation loss mlp/pin: 0.614566/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.922877\n",
      "det: 0.02209648\n",
      "Validation loss mlp/pin: 0.492751/1.024320\n",
      "###### N,i = 5,1 #####\n",
      "M: 82.07521\n",
      "det: 7.000421e-05\n",
      "Validation loss mlp/pin: 1.464108/1.501628\n",
      "\n",
      "Epoch 566/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579097/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480600/0.982429\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492617/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176697\n",
      "det: 0.07211187\n",
      "Validation loss mlp/pin: 0.614541/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.250282\n",
      "det: 0.022095675\n",
      "Validation loss mlp/pin: 0.492734/1.024306\n",
      "###### N,i = 5,1 #####\n",
      "M: 76.716385\n",
      "det: 7.0026595e-05\n",
      "Validation loss mlp/pin: 1.464106/1.501628\n",
      "\n",
      "Epoch 567/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579074/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480585/0.982418\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492617/1.534746\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176713\n",
      "det: 0.07211366\n",
      "Validation loss mlp/pin: 0.614516/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.2227864\n",
      "det: 0.022094876\n",
      "Validation loss mlp/pin: 0.492717/1.024292\n",
      "###### N,i = 5,1 #####\n",
      "M: 104.63874\n",
      "det: 7.004231e-05\n",
      "Validation loss mlp/pin: 1.464105/1.501628\n",
      "\n",
      "Epoch 568/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579050/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480567/0.982404\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492613/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1767306\n",
      "det: 0.07211548\n",
      "Validation loss mlp/pin: 0.614492/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.039104\n",
      "det: 0.022094093\n",
      "Validation loss mlp/pin: 0.492700/1.024278\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.19885\n",
      "det: 7.005135e-05\n",
      "Validation loss mlp/pin: 1.464104/1.501628\n",
      "\n",
      "Epoch 569/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579027/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480551/0.982391\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492612/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1767473\n",
      "det: 0.07211725\n",
      "Validation loss mlp/pin: 0.614469/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.706394\n",
      "det: 0.022093298\n",
      "Validation loss mlp/pin: 0.492683/1.024265\n",
      "###### N,i = 5,1 #####\n",
      "M: 102.88705\n",
      "det: 7.00891e-05\n",
      "Validation loss mlp/pin: 1.464103/1.501628\n",
      "\n",
      "Epoch 570/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.579004/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480536/0.982378\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492612/1.534737\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1767645\n",
      "det: 0.07211901\n",
      "Validation loss mlp/pin: 0.614445/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.632664\n",
      "det: 0.022092514\n",
      "Validation loss mlp/pin: 0.492667/1.024251\n",
      "###### N,i = 5,1 #####\n",
      "M: 135.72417\n",
      "det: 7.0096154e-05\n",
      "Validation loss mlp/pin: 1.464102/1.501628\n",
      "\n",
      "Epoch 571/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578981/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480519/0.982366\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492612/1.534745\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1767807\n",
      "det: 0.07212074\n",
      "Validation loss mlp/pin: 0.614422/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.195283\n",
      "det: 0.022091769\n",
      "Validation loss mlp/pin: 0.492650/1.024238\n",
      "###### N,i = 5,1 #####\n",
      "M: 106.954285\n",
      "det: 7.0116585e-05\n",
      "Validation loss mlp/pin: 1.464100/1.501628\n",
      "\n",
      "Epoch 572/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578959/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480504/0.982353\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492610/1.534743\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176797\n",
      "det: 0.07212248\n",
      "Validation loss mlp/pin: 0.614398/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.864031\n",
      "det: 0.022090996\n",
      "Validation loss mlp/pin: 0.492634/1.024224\n",
      "###### N,i = 5,1 #####\n",
      "M: 105.13623\n",
      "det: 7.014043e-05\n",
      "Validation loss mlp/pin: 1.464099/1.501628\n",
      "\n",
      "Epoch 573/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578936/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480488/0.982341\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492612/1.534753\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176813\n",
      "det: 0.0721242\n",
      "Validation loss mlp/pin: 0.614376/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.147375\n",
      "det: 0.022090245\n",
      "Validation loss mlp/pin: 0.492618/1.024211\n",
      "###### N,i = 5,1 #####\n",
      "M: 91.1071\n",
      "det: 7.0162125e-05\n",
      "Validation loss mlp/pin: 1.464097/1.501628\n",
      "\n",
      "Epoch 574/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578914/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480472/0.982329\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492605/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176829\n",
      "det: 0.0721259\n",
      "Validation loss mlp/pin: 0.614353/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.331598\n",
      "det: 0.022089513\n",
      "Validation loss mlp/pin: 0.492602/1.024198\n",
      "###### N,i = 5,1 #####\n",
      "M: 81.82933\n",
      "det: 7.017399e-05\n",
      "Validation loss mlp/pin: 1.464096/1.501628\n",
      "\n",
      "Epoch 575/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578892/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480457/0.982317\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492606/1.534742\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176845\n",
      "det: 0.072127596\n",
      "Validation loss mlp/pin: 0.614330/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.997907\n",
      "det: 0.02208876\n",
      "Validation loss mlp/pin: 0.492586/1.024185\n",
      "###### N,i = 5,1 #####\n",
      "M: 167.01462\n",
      "det: 7.01902e-05\n",
      "Validation loss mlp/pin: 1.464095/1.501628\n",
      "\n",
      "Epoch 576/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578871/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480443/0.982305\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492606/1.534749\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1768603\n",
      "det: 0.07212926\n",
      "Validation loss mlp/pin: 0.614308/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.152258\n",
      "det: 0.022088021\n",
      "Validation loss mlp/pin: 0.492570/1.024172\n",
      "###### N,i = 5,1 #####\n",
      "M: 91.04513\n",
      "det: 7.021068e-05\n",
      "Validation loss mlp/pin: 1.464094/1.501627\n",
      "\n",
      "Epoch 577/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578849/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480427/0.982294\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492602/1.534739\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176876\n",
      "det: 0.07213089\n",
      "Validation loss mlp/pin: 0.614286/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.524832\n",
      "det: 0.022087326\n",
      "Validation loss mlp/pin: 0.492555/1.024160\n",
      "###### N,i = 5,1 #####\n",
      "M: 90.46863\n",
      "det: 7.022855e-05\n",
      "Validation loss mlp/pin: 1.464092/1.501627\n",
      "\n",
      "Epoch 578/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578828/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480412/0.982281\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492601/1.534741\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176891\n",
      "det: 0.07213249\n",
      "Validation loss mlp/pin: 0.614264/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.461201\n",
      "det: 0.022086564\n",
      "Validation loss mlp/pin: 0.492540/1.024147\n",
      "###### N,i = 5,1 #####\n",
      "M: 179.53856\n",
      "det: 7.0248774e-05\n",
      "Validation loss mlp/pin: 1.464092/1.501627\n",
      "\n",
      "Epoch 579/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578807/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480398/0.982269\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492598/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1769066\n",
      "det: 0.0721341\n",
      "Validation loss mlp/pin: 0.614243/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.57571\n",
      "det: 0.022085872\n",
      "Validation loss mlp/pin: 0.492524/1.024135\n",
      "###### N,i = 5,1 #####\n",
      "M: 84.35788\n",
      "det: 7.0260874e-05\n",
      "Validation loss mlp/pin: 1.464090/1.501627\n",
      "\n",
      "Epoch 580/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578786/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480383/0.982258\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492597/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176921\n",
      "det: 0.072135665\n",
      "Validation loss mlp/pin: 0.614221/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.891667\n",
      "det: 0.022085166\n",
      "Validation loss mlp/pin: 0.492509/1.024123\n",
      "###### N,i = 5,1 #####\n",
      "M: 179.55313\n",
      "det: 7.028213e-05\n",
      "Validation loss mlp/pin: 1.464089/1.501627\n",
      "\n",
      "Epoch 581/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578766/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480369/0.982248\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492597/1.534741\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1769357\n",
      "det: 0.07213725\n",
      "Validation loss mlp/pin: 0.614200/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.990541\n",
      "det: 0.022084467\n",
      "Validation loss mlp/pin: 0.492494/1.024110\n",
      "###### N,i = 5,1 #####\n",
      "M: 136.0764\n",
      "det: 7.029006e-05\n",
      "Validation loss mlp/pin: 1.464088/1.501628\n",
      "\n",
      "Epoch 582/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578746/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480354/0.982236\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492595/1.534737\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17695\n",
      "det: 0.07213881\n",
      "Validation loss mlp/pin: 0.614179/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.701564\n",
      "det: 0.02208377\n",
      "Validation loss mlp/pin: 0.492480/1.024099\n",
      "###### N,i = 5,1 #####\n",
      "M: 134.32187\n",
      "det: 7.0317954e-05\n",
      "Validation loss mlp/pin: 1.464087/1.501628\n",
      "\n",
      "Epoch 583/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578725/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480340/0.982225\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492595/1.534741\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1769643\n",
      "det: 0.072140336\n",
      "Validation loss mlp/pin: 0.614159/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.571974\n",
      "det: 0.022083106\n",
      "Validation loss mlp/pin: 0.492465/1.024086\n",
      "###### N,i = 5,1 #####\n",
      "M: 159.16876\n",
      "det: 7.031751e-05\n",
      "Validation loss mlp/pin: 1.464086/1.501628\n",
      "\n",
      "Epoch 584/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578705/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480327/0.982214\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492592/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.176978\n",
      "det: 0.072141856\n",
      "Validation loss mlp/pin: 0.614138/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.797857\n",
      "det: 0.022082446\n",
      "Validation loss mlp/pin: 0.492451/1.024075\n",
      "###### N,i = 5,1 #####\n",
      "M: 136.60132\n",
      "det: 7.033699e-05\n",
      "Validation loss mlp/pin: 1.464085/1.501628\n",
      "\n",
      "Epoch 585/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578686/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480313/0.982203\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492593/1.534743\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1769924\n",
      "det: 0.07214336\n",
      "Validation loss mlp/pin: 0.614118/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.8131037\n",
      "det: 0.022081766\n",
      "Validation loss mlp/pin: 0.492437/1.024063\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.11269\n",
      "det: 7.036207e-05\n",
      "Validation loss mlp/pin: 1.464084/1.501629\n",
      "\n",
      "Epoch 586/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578666/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480299/0.982192\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492589/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177006\n",
      "det: 0.07214486\n",
      "Validation loss mlp/pin: 0.614097/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.469118\n",
      "det: 0.022081107\n",
      "Validation loss mlp/pin: 0.492422/1.024052\n",
      "###### N,i = 5,1 #####\n",
      "M: 79.54512\n",
      "det: 7.037956e-05\n",
      "Validation loss mlp/pin: 1.464082/1.501629\n",
      "\n",
      "Epoch 587/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578646/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480286/0.982182\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492589/1.534740\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1770196\n",
      "det: 0.07214633\n",
      "Validation loss mlp/pin: 0.614077/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.675665\n",
      "det: 0.022080453\n",
      "Validation loss mlp/pin: 0.492408/1.024040\n",
      "###### N,i = 5,1 #####\n",
      "M: 108.93437\n",
      "det: 7.0397466e-05\n",
      "Validation loss mlp/pin: 1.464081/1.501628\n",
      "\n",
      "Epoch 588/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578627/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480273/0.982172\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492591/1.534752\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177033\n",
      "det: 0.072147764\n",
      "Validation loss mlp/pin: 0.614058/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.170685\n",
      "det: 0.02207983\n",
      "Validation loss mlp/pin: 0.492395/1.024029\n",
      "###### N,i = 5,1 #####\n",
      "M: 126.75135\n",
      "det: 7.040246e-05\n",
      "Validation loss mlp/pin: 1.464080/1.501629\n",
      "\n",
      "Epoch 589/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578609/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480259/0.982161\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492585/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1770463\n",
      "det: 0.07214923\n",
      "Validation loss mlp/pin: 0.614038/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.542217\n",
      "det: 0.022079192\n",
      "Validation loss mlp/pin: 0.492381/1.024018\n",
      "###### N,i = 5,1 #####\n",
      "M: 162.68626\n",
      "det: 7.042621e-05\n",
      "Validation loss mlp/pin: 1.464079/1.501629\n",
      "\n",
      "Epoch 590/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578590/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480246/0.982151\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492585/1.534736\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1770597\n",
      "det: 0.07215064\n",
      "Validation loss mlp/pin: 0.614019/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.432547\n",
      "det: 0.022078548\n",
      "Validation loss mlp/pin: 0.492367/1.024007\n",
      "###### N,i = 5,1 #####\n",
      "M: 121.98166\n",
      "det: 7.0444425e-05\n",
      "Validation loss mlp/pin: 1.464078/1.501629\n",
      "\n",
      "Epoch 591/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578571/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480233/0.982140\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492584/1.534736\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177073\n",
      "det: 0.072152056\n",
      "Validation loss mlp/pin: 0.614000/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.263567\n",
      "det: 0.02207794\n",
      "Validation loss mlp/pin: 0.492354/1.023996\n",
      "###### N,i = 5,1 #####\n",
      "M: 173.05875\n",
      "det: 7.045285e-05\n",
      "Validation loss mlp/pin: 1.464077/1.501628\n",
      "\n",
      "Epoch 592/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578553/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480220/0.982131\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492582/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177086\n",
      "det: 0.07215348\n",
      "Validation loss mlp/pin: 0.613981/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.3452187\n",
      "det: 0.022077309\n",
      "Validation loss mlp/pin: 0.492341/1.023985\n",
      "###### N,i = 5,1 #####\n",
      "M: 200.4863\n",
      "det: 7.0467984e-05\n",
      "Validation loss mlp/pin: 1.464076/1.501629\n",
      "\n",
      "Epoch 593/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578535/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480207/0.982120\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492580/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1770988\n",
      "det: 0.07215486\n",
      "Validation loss mlp/pin: 0.613963/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.7857647\n",
      "det: 0.022076687\n",
      "Validation loss mlp/pin: 0.492327/1.023974\n",
      "###### N,i = 5,1 #####\n",
      "M: 134.33359\n",
      "det: 7.046616e-05\n",
      "Validation loss mlp/pin: 1.464075/1.501629\n",
      "\n",
      "Epoch 594/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578517/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480195/0.982110\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492580/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1771116\n",
      "det: 0.07215624\n",
      "Validation loss mlp/pin: 0.613944/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.761824\n",
      "det: 0.022076089\n",
      "Validation loss mlp/pin: 0.492314/1.023963\n",
      "###### N,i = 5,1 #####\n",
      "M: 61.26538\n",
      "det: 7.049518e-05\n",
      "Validation loss mlp/pin: 1.464074/1.501628\n",
      "\n",
      "Epoch 595/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578499/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480183/0.982100\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492579/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177124\n",
      "det: 0.0721576\n",
      "Validation loss mlp/pin: 0.613926/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.851745\n",
      "det: 0.022075484\n",
      "Validation loss mlp/pin: 0.492302/1.023953\n",
      "###### N,i = 5,1 #####\n",
      "M: 104.905235\n",
      "det: 7.050992e-05\n",
      "Validation loss mlp/pin: 1.464073/1.501629\n",
      "\n",
      "Epoch 596/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578481/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480171/0.982090\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492578/1.534737\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177137\n",
      "det: 0.07215893\n",
      "Validation loss mlp/pin: 0.613908/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.481857\n",
      "det: 0.0220749\n",
      "Validation loss mlp/pin: 0.492289/1.023942\n",
      "###### N,i = 5,1 #####\n",
      "M: 233.88005\n",
      "det: 7.052563e-05\n",
      "Validation loss mlp/pin: 1.464072/1.501628\n",
      "\n",
      "Epoch 597/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578464/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480158/0.982080\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492577/1.534741\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1771493\n",
      "det: 0.07216026\n",
      "Validation loss mlp/pin: 0.613890/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.474204\n",
      "det: 0.022074303\n",
      "Validation loss mlp/pin: 0.492276/1.023932\n",
      "###### N,i = 5,1 #####\n",
      "M: 100.961365\n",
      "det: 7.053851e-05\n",
      "Validation loss mlp/pin: 1.464071/1.501628\n",
      "\n",
      "Epoch 598/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578447/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480146/0.982071\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492576/1.534740\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177161\n",
      "det: 0.07216157\n",
      "Validation loss mlp/pin: 0.613872/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.283684\n",
      "det: 0.022073701\n",
      "Validation loss mlp/pin: 0.492264/1.023922\n",
      "###### N,i = 5,1 #####\n",
      "M: 49.929153\n",
      "det: 7.0558875e-05\n",
      "Validation loss mlp/pin: 1.464070/1.501629\n",
      "\n",
      "Epoch 599/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578430/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480134/0.982062\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492577/1.534746\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1771736\n",
      "det: 0.072162874\n",
      "Validation loss mlp/pin: 0.613855/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.829232\n",
      "det: 0.02207313\n",
      "Validation loss mlp/pin: 0.492251/1.023912\n",
      "###### N,i = 5,1 #####\n",
      "M: 221.14656\n",
      "det: 7.0564354e-05\n",
      "Validation loss mlp/pin: 1.464069/1.501629\n",
      "\n",
      "Epoch 600/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578413/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480122/0.982052\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492573/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177185\n",
      "det: 0.07216416\n",
      "Validation loss mlp/pin: 0.613837/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.869789\n",
      "det: 0.022072561\n",
      "Validation loss mlp/pin: 0.492239/1.023902\n",
      "###### N,i = 5,1 #####\n",
      "M: 161.51225\n",
      "det: 7.059265e-05\n",
      "Validation loss mlp/pin: 1.464068/1.501629\n",
      "\n",
      "Epoch 601/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578396/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480110/0.982044\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492572/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1771975\n",
      "det: 0.072165444\n",
      "Validation loss mlp/pin: 0.613820/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.095405\n",
      "det: 0.022071986\n",
      "Validation loss mlp/pin: 0.492227/1.023892\n",
      "###### N,i = 5,1 #####\n",
      "M: 119.956696\n",
      "det: 7.06061e-05\n",
      "Validation loss mlp/pin: 1.464067/1.501628\n",
      "\n",
      "Epoch 602/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578379/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480099/0.982034\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492571/1.534738\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177209\n",
      "det: 0.072166696\n",
      "Validation loss mlp/pin: 0.613803/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.716311\n",
      "det: 0.022071429\n",
      "Validation loss mlp/pin: 0.492215/1.023882\n",
      "###### N,i = 5,1 #####\n",
      "M: 104.3246\n",
      "det: 7.060984e-05\n",
      "Validation loss mlp/pin: 1.464067/1.501628\n",
      "\n",
      "Epoch 603/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578363/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480087/0.982024\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492571/1.534741\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1772203\n",
      "det: 0.07216795\n",
      "Validation loss mlp/pin: 0.613786/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.911846\n",
      "det: 0.022070874\n",
      "Validation loss mlp/pin: 0.492203/1.023872\n",
      "###### N,i = 5,1 #####\n",
      "M: 90.59338\n",
      "det: 7.0632545e-05\n",
      "Validation loss mlp/pin: 1.464066/1.501629\n",
      "\n",
      "Epoch 604/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578347/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480076/0.982017\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492570/1.534739\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177232\n",
      "det: 0.07216916\n",
      "Validation loss mlp/pin: 0.613769/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.793526\n",
      "det: 0.022070315\n",
      "Validation loss mlp/pin: 0.492191/1.023862\n",
      "###### N,i = 5,1 #####\n",
      "M: 180.5618\n",
      "det: 7.0623246e-05\n",
      "Validation loss mlp/pin: 1.464065/1.501628\n",
      "\n",
      "Epoch 605/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578330/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480065/0.982007\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492567/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177243\n",
      "det: 0.072170384\n",
      "Validation loss mlp/pin: 0.613753/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.858969\n",
      "det: 0.02206978\n",
      "Validation loss mlp/pin: 0.492179/1.023853\n",
      "###### N,i = 5,1 #####\n",
      "M: 89.64618\n",
      "det: 7.0634116e-05\n",
      "Validation loss mlp/pin: 1.464064/1.501629\n",
      "\n",
      "Epoch 606/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578315/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480054/0.981998\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492566/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1772547\n",
      "det: 0.07217157\n",
      "Validation loss mlp/pin: 0.613736/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.610382\n",
      "det: 0.022069244\n",
      "Validation loss mlp/pin: 0.492168/1.023843\n",
      "###### N,i = 5,1 #####\n",
      "M: 70.40111\n",
      "det: 7.066684e-05\n",
      "Validation loss mlp/pin: 1.464063/1.501629\n",
      "\n",
      "Epoch 607/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578299/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480042/0.981989\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492565/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177265\n",
      "det: 0.07217276\n",
      "Validation loss mlp/pin: 0.613720/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.202286\n",
      "det: 0.0220687\n",
      "Validation loss mlp/pin: 0.492157/1.023834\n",
      "###### N,i = 5,1 #####\n",
      "M: 99.013275\n",
      "det: 7.0679205e-05\n",
      "Validation loss mlp/pin: 1.464062/1.501629\n",
      "\n",
      "Epoch 608/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578283/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480032/0.981981\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492564/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1772766\n",
      "det: 0.07217394\n",
      "Validation loss mlp/pin: 0.613704/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.469137\n",
      "det: 0.02206817\n",
      "Validation loss mlp/pin: 0.492145/1.023825\n",
      "###### N,i = 5,1 #####\n",
      "M: 195.0549\n",
      "det: 7.069588e-05\n",
      "Validation loss mlp/pin: 1.464061/1.501628\n",
      "\n",
      "Epoch 609/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578268/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480021/0.981973\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492565/1.534739\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1772876\n",
      "det: 0.07217512\n",
      "Validation loss mlp/pin: 0.613688/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.882652\n",
      "det: 0.022067644\n",
      "Validation loss mlp/pin: 0.492134/1.023816\n",
      "###### N,i = 5,1 #####\n",
      "M: 193.21706\n",
      "det: 7.070698e-05\n",
      "Validation loss mlp/pin: 1.464060/1.501628\n",
      "\n",
      "Epoch 610/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578252/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480010/0.981964\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492562/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177299\n",
      "det: 0.07217627\n",
      "Validation loss mlp/pin: 0.613672/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.92193\n",
      "det: 0.022067139\n",
      "Validation loss mlp/pin: 0.492123/1.023807\n",
      "###### N,i = 5,1 #####\n",
      "M: 156.74147\n",
      "det: 7.07179e-05\n",
      "Validation loss mlp/pin: 1.464060/1.501628\n",
      "\n",
      "Epoch 611/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578237/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.480001/0.981957\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492561/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17731\n",
      "det: 0.07217745\n",
      "Validation loss mlp/pin: 0.613657/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.623651\n",
      "det: 0.022066627\n",
      "Validation loss mlp/pin: 0.492112/1.023798\n",
      "###### N,i = 5,1 #####\n",
      "M: 88.24889\n",
      "det: 7.072287e-05\n",
      "Validation loss mlp/pin: 1.464059/1.501628\n",
      "\n",
      "Epoch 612/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578222/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479989/0.981947\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492560/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17732\n",
      "det: 0.07217858\n",
      "Validation loss mlp/pin: 0.613641/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.157556\n",
      "det: 0.02206612\n",
      "Validation loss mlp/pin: 0.492101/1.023789\n",
      "###### N,i = 5,1 #####\n",
      "M: 154.94754\n",
      "det: 7.074473e-05\n",
      "Validation loss mlp/pin: 1.464058/1.501628\n",
      "\n",
      "Epoch 613/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578207/2.588986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479979/0.981939\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492560/1.534738\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177332\n",
      "det: 0.07217973\n",
      "Validation loss mlp/pin: 0.613626/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.382565\n",
      "det: 0.022065625\n",
      "Validation loss mlp/pin: 0.492090/1.023780\n",
      "###### N,i = 5,1 #####\n",
      "M: 70.33308\n",
      "det: 7.075099e-05\n",
      "Validation loss mlp/pin: 1.464057/1.501628\n",
      "\n",
      "Epoch 614/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578193/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479969/0.981931\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492561/1.534746\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1773424\n",
      "det: 0.07218087\n",
      "Validation loss mlp/pin: 0.613611/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.76402\n",
      "det: 0.022065131\n",
      "Validation loss mlp/pin: 0.492080/1.023771\n",
      "###### N,i = 5,1 #####\n",
      "M: 75.371925\n",
      "det: 7.075883e-05\n",
      "Validation loss mlp/pin: 1.464056/1.501628\n",
      "\n",
      "Epoch 615/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578178/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479959/0.981923\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492559/1.534742\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1773524\n",
      "det: 0.072181985\n",
      "Validation loss mlp/pin: 0.613596/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.4615097\n",
      "det: 0.022064617\n",
      "Validation loss mlp/pin: 0.492069/1.023763\n",
      "###### N,i = 5,1 #####\n",
      "M: 102.8741\n",
      "det: 7.078129e-05\n",
      "Validation loss mlp/pin: 1.464055/1.501628\n",
      "\n",
      "Epoch 616/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578164/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479949/0.981915\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492557/1.534737\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1773634\n",
      "det: 0.07218309\n",
      "Validation loss mlp/pin: 0.613581/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.150959\n",
      "det: 0.02206416\n",
      "Validation loss mlp/pin: 0.492059/1.023754\n",
      "###### N,i = 5,1 #####\n",
      "M: 99.6183\n",
      "det: 7.078936e-05\n",
      "Validation loss mlp/pin: 1.464054/1.501628\n",
      "\n",
      "Epoch 617/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578149/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479939/0.981907\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492555/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177373\n",
      "det: 0.07218419\n",
      "Validation loss mlp/pin: 0.613567/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.651234\n",
      "det: 0.02206367\n",
      "Validation loss mlp/pin: 0.492049/1.023746\n",
      "###### N,i = 5,1 #####\n",
      "M: 67.00907\n",
      "det: 7.080525e-05\n",
      "Validation loss mlp/pin: 1.464054/1.501628\n",
      "\n",
      "Epoch 618/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578135/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479929/0.981899\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492556/1.534739\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1773834\n",
      "det: 0.072185256\n",
      "Validation loss mlp/pin: 0.613552/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.897\n",
      "det: 0.022063186\n",
      "Validation loss mlp/pin: 0.492038/1.023738\n",
      "###### N,i = 5,1 #####\n",
      "M: 189.82684\n",
      "det: 7.081398e-05\n",
      "Validation loss mlp/pin: 1.464053/1.501628\n",
      "\n",
      "Epoch 619/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578121/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479919/0.981892\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492554/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1773934\n",
      "det: 0.07218632\n",
      "Validation loss mlp/pin: 0.613538/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.586052\n",
      "det: 0.022062715\n",
      "Validation loss mlp/pin: 0.492028/1.023729\n",
      "###### N,i = 5,1 #####\n",
      "M: 90.213036\n",
      "det: 7.083421e-05\n",
      "Validation loss mlp/pin: 1.464052/1.501628\n",
      "\n",
      "Epoch 620/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578107/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479909/0.981884\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492552/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1774035\n",
      "det: 0.07218738\n",
      "Validation loss mlp/pin: 0.613523/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.645683\n",
      "det: 0.02206224\n",
      "Validation loss mlp/pin: 0.492018/1.023721\n",
      "###### N,i = 5,1 #####\n",
      "M: 106.24511\n",
      "det: 7.083983e-05\n",
      "Validation loss mlp/pin: 1.464051/1.501628\n",
      "\n",
      "Epoch 621/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578094/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479900/0.981876\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492553/1.534737\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1774135\n",
      "det: 0.07218847\n",
      "Validation loss mlp/pin: 0.613509/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.571138\n",
      "det: 0.022061763\n",
      "Validation loss mlp/pin: 0.492008/1.023713\n",
      "###### N,i = 5,1 #####\n",
      "M: 92.374695\n",
      "det: 7.0853246e-05\n",
      "Validation loss mlp/pin: 1.464051/1.501628\n",
      "\n",
      "Epoch 622/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578080/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479891/0.981869\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492551/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177424\n",
      "det: 0.07218952\n",
      "Validation loss mlp/pin: 0.613495/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.919804\n",
      "det: 0.022061324\n",
      "Validation loss mlp/pin: 0.491998/1.023705\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.34034\n",
      "det: 7.086241e-05\n",
      "Validation loss mlp/pin: 1.464050/1.501628\n",
      "\n",
      "Epoch 623/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578066/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479882/0.981862\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492552/1.534739\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177433\n",
      "det: 0.07219052\n",
      "Validation loss mlp/pin: 0.613481/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.094467\n",
      "det: 0.022060854\n",
      "Validation loss mlp/pin: 0.491989/1.023697\n",
      "###### N,i = 5,1 #####\n",
      "M: 64.191956\n",
      "det: 7.086529e-05\n",
      "Validation loss mlp/pin: 1.464049/1.501628\n",
      "\n",
      "Epoch 624/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578053/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479872/0.981854\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492550/1.534737\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177443\n",
      "det: 0.07219156\n",
      "Validation loss mlp/pin: 0.613467/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.656928\n",
      "det: 0.0220604\n",
      "Validation loss mlp/pin: 0.491979/1.023689\n",
      "###### N,i = 5,1 #####\n",
      "M: 151.7554\n",
      "det: 7.088801e-05\n",
      "Validation loss mlp/pin: 1.464048/1.501629\n",
      "\n",
      "Epoch 625/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578040/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479863/0.981847\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492548/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1774526\n",
      "det: 0.07219257\n",
      "Validation loss mlp/pin: 0.613454/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.750603\n",
      "det: 0.022059986\n",
      "Validation loss mlp/pin: 0.491969/1.023681\n",
      "###### N,i = 5,1 #####\n",
      "M: 89.16851\n",
      "det: 7.088937e-05\n",
      "Validation loss mlp/pin: 1.464048/1.501629\n",
      "\n",
      "Epoch 626/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578027/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479854/0.981840\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492548/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177462\n",
      "det: 0.07219357\n",
      "Validation loss mlp/pin: 0.613441/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.95915\n",
      "det: 0.02205953\n",
      "Validation loss mlp/pin: 0.491960/1.023674\n",
      "###### N,i = 5,1 #####\n",
      "M: 139.4885\n",
      "det: 7.089536e-05\n",
      "Validation loss mlp/pin: 1.464047/1.501628\n",
      "\n",
      "Epoch 627/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578014/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479845/0.981833\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492547/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1774716\n",
      "det: 0.072194554\n",
      "Validation loss mlp/pin: 0.613427/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.37018\n",
      "det: 0.022059092\n",
      "Validation loss mlp/pin: 0.491951/1.023666\n",
      "###### N,i = 5,1 #####\n",
      "M: 149.85126\n",
      "det: 7.0907394e-05\n",
      "Validation loss mlp/pin: 1.464046/1.501628\n",
      "\n",
      "Epoch 628/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.578001/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479836/0.981826\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492546/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1774807\n",
      "det: 0.07219555\n",
      "Validation loss mlp/pin: 0.613414/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.70676\n",
      "det: 0.022058673\n",
      "Validation loss mlp/pin: 0.491942/1.023659\n",
      "###### N,i = 5,1 #####\n",
      "M: 135.52145\n",
      "det: 7.092815e-05\n",
      "Validation loss mlp/pin: 1.464045/1.501628\n",
      "\n",
      "Epoch 629/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577989/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479827/0.981819\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492545/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1774893\n",
      "det: 0.0721965\n",
      "Validation loss mlp/pin: 0.613401/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.732381\n",
      "det: 0.022058256\n",
      "Validation loss mlp/pin: 0.491932/1.023651\n",
      "###### N,i = 5,1 #####\n",
      "M: 120.74535\n",
      "det: 7.0931506e-05\n",
      "Validation loss mlp/pin: 1.464045/1.501628\n",
      "\n",
      "Epoch 630/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577976/2.588986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479819/0.981813\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492544/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1774983\n",
      "det: 0.072197445\n",
      "Validation loss mlp/pin: 0.613388/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.3303585\n",
      "det: 0.022057826\n",
      "Validation loss mlp/pin: 0.491923/1.023644\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.40606\n",
      "det: 7.094871e-05\n",
      "Validation loss mlp/pin: 1.464044/1.501629\n",
      "\n",
      "Epoch 631/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577964/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479810/0.981805\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492543/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1775074\n",
      "det: 0.07219842\n",
      "Validation loss mlp/pin: 0.613376/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.304731\n",
      "det: 0.022057403\n",
      "Validation loss mlp/pin: 0.491914/1.023636\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.40193\n",
      "det: 7.095762e-05\n",
      "Validation loss mlp/pin: 1.464043/1.501629\n",
      "\n",
      "Epoch 632/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577951/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479801/0.981798\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492544/1.534736\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177517\n",
      "det: 0.07219933\n",
      "Validation loss mlp/pin: 0.613363/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.915833\n",
      "det: 0.022056995\n",
      "Validation loss mlp/pin: 0.491906/1.023629\n",
      "###### N,i = 5,1 #####\n",
      "M: 104.231384\n",
      "det: 7.096592e-05\n",
      "Validation loss mlp/pin: 1.464043/1.501628\n",
      "\n",
      "Epoch 633/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577939/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479793/0.981792\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492543/1.534738\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177525\n",
      "det: 0.07220027\n",
      "Validation loss mlp/pin: 0.613351/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.602015\n",
      "det: 0.022056587\n",
      "Validation loss mlp/pin: 0.491897/1.023622\n",
      "###### N,i = 5,1 #####\n",
      "M: 80.27596\n",
      "det: 7.0963935e-05\n",
      "Validation loss mlp/pin: 1.464042/1.501628\n",
      "\n",
      "Epoch 634/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577927/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479785/0.981786\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492541/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1775336\n",
      "det: 0.07220118\n",
      "Validation loss mlp/pin: 0.613338/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.360038\n",
      "det: 0.022056175\n",
      "Validation loss mlp/pin: 0.491888/1.023615\n",
      "###### N,i = 5,1 #####\n",
      "M: 68.3163\n",
      "det: 7.098762e-05\n",
      "Validation loss mlp/pin: 1.464041/1.501628\n",
      "\n",
      "Epoch 635/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577915/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479776/0.981778\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492540/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177542\n",
      "det: 0.072202094\n",
      "Validation loss mlp/pin: 0.613326/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.3233\n",
      "det: 0.022055754\n",
      "Validation loss mlp/pin: 0.491879/1.023608\n",
      "###### N,i = 5,1 #####\n",
      "M: 184.71838\n",
      "det: 7.099156e-05\n",
      "Validation loss mlp/pin: 1.464041/1.501628\n",
      "\n",
      "Epoch 636/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577904/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479768/0.981772\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492540/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1775503\n",
      "det: 0.07220301\n",
      "Validation loss mlp/pin: 0.613314/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.610951\n",
      "det: 0.022055367\n",
      "Validation loss mlp/pin: 0.491871/1.023601\n",
      "###### N,i = 5,1 #####\n",
      "M: 168.6235\n",
      "det: 7.100457e-05\n",
      "Validation loss mlp/pin: 1.464040/1.501628\n",
      "\n",
      "Epoch 637/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577892/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479760/0.981766\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492540/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177559\n",
      "det: 0.0722039\n",
      "Validation loss mlp/pin: 0.613302/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.970772\n",
      "det: 0.022054957\n",
      "Validation loss mlp/pin: 0.491862/1.023594\n",
      "###### N,i = 5,1 #####\n",
      "M: 81.139206\n",
      "det: 7.101149e-05\n",
      "Validation loss mlp/pin: 1.464039/1.501628\n",
      "\n",
      "Epoch 638/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577881/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479752/0.981760\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492539/1.534739\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177567\n",
      "det: 0.072204776\n",
      "Validation loss mlp/pin: 0.613290/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.733585\n",
      "det: 0.022054547\n",
      "Validation loss mlp/pin: 0.491854/1.023587\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.4021\n",
      "det: 7.102342e-05\n",
      "Validation loss mlp/pin: 1.464039/1.501628\n",
      "\n",
      "Epoch 639/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577869/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479744/0.981753\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492537/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177575\n",
      "det: 0.07220566\n",
      "Validation loss mlp/pin: 0.613279/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.67803\n",
      "det: 0.02205417\n",
      "Validation loss mlp/pin: 0.491846/1.023581\n",
      "###### N,i = 5,1 #####\n",
      "M: 85.35691\n",
      "det: 7.102405e-05\n",
      "Validation loss mlp/pin: 1.464038/1.501628\n",
      "\n",
      "Epoch 640/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577858/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479736/0.981748\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492536/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177583\n",
      "det: 0.0722065\n",
      "Validation loss mlp/pin: 0.613267/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.571892\n",
      "det: 0.022053786\n",
      "Validation loss mlp/pin: 0.491838/1.023574\n",
      "###### N,i = 5,1 #####\n",
      "M: 131.50217\n",
      "det: 7.104573e-05\n",
      "Validation loss mlp/pin: 1.464037/1.501628\n",
      "\n",
      "Epoch 641/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577847/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479728/0.981741\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492535/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1775913\n",
      "det: 0.07220738\n",
      "Validation loss mlp/pin: 0.613256/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.855999\n",
      "det: 0.0220534\n",
      "Validation loss mlp/pin: 0.491829/1.023568\n",
      "###### N,i = 5,1 #####\n",
      "M: 97.6345\n",
      "det: 7.104982e-05\n",
      "Validation loss mlp/pin: 1.464037/1.501628\n",
      "\n",
      "Epoch 642/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577836/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479720/0.981735\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492535/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177599\n",
      "det: 0.072208196\n",
      "Validation loss mlp/pin: 0.613245/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.940069\n",
      "det: 0.022053026\n",
      "Validation loss mlp/pin: 0.491821/1.023561\n",
      "###### N,i = 5,1 #####\n",
      "M: 99.41211\n",
      "det: 7.106192e-05\n",
      "Validation loss mlp/pin: 1.464036/1.501628\n",
      "\n",
      "Epoch 643/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577825/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479713/0.981729\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492536/1.534742\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177607\n",
      "det: 0.07220902\n",
      "Validation loss mlp/pin: 0.613233/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.64139\n",
      "det: 0.022052633\n",
      "Validation loss mlp/pin: 0.491813/1.023554\n",
      "###### N,i = 5,1 #####\n",
      "M: 61.99486\n",
      "det: 7.107928e-05\n",
      "Validation loss mlp/pin: 1.464036/1.501628\n",
      "\n",
      "Epoch 644/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577814/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479705/0.981723\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492534/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1776147\n",
      "det: 0.072209865\n",
      "Validation loss mlp/pin: 0.613222/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.256279\n",
      "det: 0.022052277\n",
      "Validation loss mlp/pin: 0.491806/1.023548\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.85826\n",
      "det: 7.1085866e-05\n",
      "Validation loss mlp/pin: 1.464035/1.501628\n",
      "\n",
      "Epoch 645/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577803/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479699/0.981718\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492533/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177622\n",
      "det: 0.072210655\n",
      "Validation loss mlp/pin: 0.613211/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.4966345\n",
      "det: 0.02205191\n",
      "Validation loss mlp/pin: 0.491798/1.023542\n",
      "###### N,i = 5,1 #####\n",
      "M: 131.28355\n",
      "det: 7.108983e-05\n",
      "Validation loss mlp/pin: 1.464034/1.501628\n",
      "\n",
      "Epoch 646/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577793/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479691/0.981711\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492532/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1776295\n",
      "det: 0.07221146\n",
      "Validation loss mlp/pin: 0.613200/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.251026\n",
      "det: 0.022051534\n",
      "Validation loss mlp/pin: 0.491790/1.023535\n",
      "###### N,i = 5,1 #####\n",
      "M: 217.85777\n",
      "det: 7.10932e-05\n",
      "Validation loss mlp/pin: 1.464034/1.501628\n",
      "\n",
      "Epoch 647/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577783/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479683/0.981705\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492531/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1776366\n",
      "det: 0.07221225\n",
      "Validation loss mlp/pin: 0.613190/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.486342\n",
      "det: 0.02205117\n",
      "Validation loss mlp/pin: 0.491782/1.023529\n",
      "###### N,i = 5,1 #####\n",
      "M: 180.24956\n",
      "det: 7.110216e-05\n",
      "Validation loss mlp/pin: 1.464033/1.501628\n",
      "\n",
      "Epoch 648/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577772/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479676/0.981700\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492532/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1776443\n",
      "det: 0.07221305\n",
      "Validation loss mlp/pin: 0.613179/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.290386\n",
      "det: 0.022050826\n",
      "Validation loss mlp/pin: 0.491775/1.023523\n",
      "###### N,i = 5,1 #####\n",
      "M: 109.847984\n",
      "det: 7.1119226e-05\n",
      "Validation loss mlp/pin: 1.464033/1.501628\n",
      "\n",
      "Epoch 649/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577762/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479668/0.981694\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492530/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1776514\n",
      "det: 0.07221387\n",
      "Validation loss mlp/pin: 0.613168/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.674315\n",
      "det: 0.022050468\n",
      "Validation loss mlp/pin: 0.491767/1.023517\n",
      "###### N,i = 5,1 #####\n",
      "M: 98.54082\n",
      "det: 7.112866e-05\n",
      "Validation loss mlp/pin: 1.464032/1.501628\n",
      "\n",
      "Epoch 650/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577752/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479661/0.981688\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492529/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177659\n",
      "det: 0.07221462\n",
      "Validation loss mlp/pin: 0.613158/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.05024\n",
      "det: 0.022050122\n",
      "Validation loss mlp/pin: 0.491760/1.023511\n",
      "###### N,i = 5,1 #####\n",
      "M: 97.66854\n",
      "det: 7.112743e-05\n",
      "Validation loss mlp/pin: 1.464031/1.501628\n",
      "\n",
      "Epoch 651/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577741/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479654/0.981683\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492529/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177666\n",
      "det: 0.072215386\n",
      "Validation loss mlp/pin: 0.613147/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.369333\n",
      "det: 0.022049775\n",
      "Validation loss mlp/pin: 0.491752/1.023505\n",
      "###### N,i = 5,1 #####\n",
      "M: 158.37694\n",
      "det: 7.113311e-05\n",
      "Validation loss mlp/pin: 1.464031/1.501628\n",
      "\n",
      "Epoch 652/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577732/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479647/0.981677\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492528/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1776733\n",
      "det: 0.072216146\n",
      "Validation loss mlp/pin: 0.613137/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.100442\n",
      "det: 0.02204945\n",
      "Validation loss mlp/pin: 0.491745/1.023499\n",
      "###### N,i = 5,1 #####\n",
      "M: 132.9771\n",
      "det: 7.114674e-05\n",
      "Validation loss mlp/pin: 1.464030/1.501628\n",
      "\n",
      "Epoch 653/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577722/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479640/0.981671\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492529/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17768\n",
      "det: 0.0722169\n",
      "Validation loss mlp/pin: 0.613127/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.864887\n",
      "det: 0.022049112\n",
      "Validation loss mlp/pin: 0.491738/1.023493\n",
      "###### N,i = 5,1 #####\n",
      "M: 133.49074\n",
      "det: 7.1162525e-05\n",
      "Validation loss mlp/pin: 1.464030/1.501628\n",
      "\n",
      "Epoch 654/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577712/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479633/0.981667\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492527/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177687\n",
      "det: 0.07221764\n",
      "Validation loss mlp/pin: 0.613117/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.97609\n",
      "det: 0.022048766\n",
      "Validation loss mlp/pin: 0.491731/1.023487\n",
      "###### N,i = 5,1 #####\n",
      "M: 151.92175\n",
      "det: 7.116315e-05\n",
      "Validation loss mlp/pin: 1.464029/1.501628\n",
      "\n",
      "Epoch 655/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577702/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479627/0.981661\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492526/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177694\n",
      "det: 0.07221839\n",
      "Validation loss mlp/pin: 0.613107/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.551712\n",
      "det: 0.022048404\n",
      "Validation loss mlp/pin: 0.491724/1.023482\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.32921\n",
      "det: 7.1173046e-05\n",
      "Validation loss mlp/pin: 1.464028/1.501628\n",
      "\n",
      "Epoch 656/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577693/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479619/0.981656\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492526/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1777005\n",
      "det: 0.07221911\n",
      "Validation loss mlp/pin: 0.613097/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.806722\n",
      "det: 0.022048088\n",
      "Validation loss mlp/pin: 0.491717/1.023476\n",
      "###### N,i = 5,1 #####\n",
      "M: 55.844513\n",
      "det: 7.1193776e-05\n",
      "Validation loss mlp/pin: 1.464028/1.501628\n",
      "\n",
      "Epoch 657/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577683/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479613/0.981650\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492526/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177707\n",
      "det: 0.07221985\n",
      "Validation loss mlp/pin: 0.613087/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.123713\n",
      "det: 0.022047754\n",
      "Validation loss mlp/pin: 0.491710/1.023471\n",
      "###### N,i = 5,1 #####\n",
      "M: 83.418434\n",
      "det: 7.118717e-05\n",
      "Validation loss mlp/pin: 1.464028/1.501628\n",
      "\n",
      "Epoch 658/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577674/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479607/0.981646\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492525/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1777143\n",
      "det: 0.07222055\n",
      "Validation loss mlp/pin: 0.613077/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.716597\n",
      "det: 0.022047427\n",
      "Validation loss mlp/pin: 0.491703/1.023465\n",
      "###### N,i = 5,1 #####\n",
      "M: 137.50136\n",
      "det: 7.121366e-05\n",
      "Validation loss mlp/pin: 1.464027/1.501628\n",
      "\n",
      "Epoch 659/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577664/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479599/0.981640\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492524/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1777205\n",
      "det: 0.072221234\n",
      "Validation loss mlp/pin: 0.613068/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.771868\n",
      "det: 0.0220471\n",
      "Validation loss mlp/pin: 0.491696/1.023459\n",
      "###### N,i = 5,1 #####\n",
      "M: 94.05722\n",
      "det: 7.119673e-05\n",
      "Validation loss mlp/pin: 1.464026/1.501628\n",
      "\n",
      "Epoch 660/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577655/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479593/0.981635\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492524/1.534737\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1777267\n",
      "det: 0.07222194\n",
      "Validation loss mlp/pin: 0.613058/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.988594\n",
      "det: 0.022046795\n",
      "Validation loss mlp/pin: 0.491690/1.023454\n",
      "###### N,i = 5,1 #####\n",
      "M: 165.95627\n",
      "det: 7.1213115e-05\n",
      "Validation loss mlp/pin: 1.464026/1.501628\n",
      "\n",
      "Epoch 661/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577646/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479587/0.981630\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492522/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177733\n",
      "det: 0.072222635\n",
      "Validation loss mlp/pin: 0.613049/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.247557\n",
      "det: 0.022046462\n",
      "Validation loss mlp/pin: 0.491683/1.023448\n",
      "###### N,i = 5,1 #####\n",
      "M: 134.05743\n",
      "det: 7.121372e-05\n",
      "Validation loss mlp/pin: 1.464026/1.501628\n",
      "\n",
      "Epoch 662/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577637/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479581/0.981625\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492523/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1777396\n",
      "det: 0.07222331\n",
      "Validation loss mlp/pin: 0.613040/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.760458\n",
      "det: 0.02204615\n",
      "Validation loss mlp/pin: 0.491677/1.023443\n",
      "###### N,i = 5,1 #####\n",
      "M: 217.42378\n",
      "det: 7.123184e-05\n",
      "Validation loss mlp/pin: 1.464025/1.501628\n",
      "\n",
      "Epoch 663/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577628/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479574/0.981620\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492521/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177746\n",
      "det: 0.072224006\n",
      "Validation loss mlp/pin: 0.613031/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.886014\n",
      "det: 0.022045836\n",
      "Validation loss mlp/pin: 0.491670/1.023438\n",
      "###### N,i = 5,1 #####\n",
      "M: 154.66751\n",
      "det: 7.123979e-05\n",
      "Validation loss mlp/pin: 1.464024/1.501628\n",
      "\n",
      "Epoch 664/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577619/2.588986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479568/0.981616\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492522/1.534737\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177752\n",
      "det: 0.072224714\n",
      "Validation loss mlp/pin: 0.613022/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.900187\n",
      "det: 0.022045527\n",
      "Validation loss mlp/pin: 0.491664/1.023433\n",
      "###### N,i = 5,1 #####\n",
      "M: 108.707275\n",
      "det: 7.1248e-05\n",
      "Validation loss mlp/pin: 1.464024/1.501628\n",
      "\n",
      "Epoch 665/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577611/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479562/0.981610\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492520/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177758\n",
      "det: 0.07222539\n",
      "Validation loss mlp/pin: 0.613013/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.914413\n",
      "det: 0.022045245\n",
      "Validation loss mlp/pin: 0.491657/1.023427\n",
      "###### N,i = 5,1 #####\n",
      "M: 118.13361\n",
      "det: 7.1247974e-05\n",
      "Validation loss mlp/pin: 1.464023/1.501628\n",
      "\n",
      "Epoch 666/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577602/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479556/0.981605\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492519/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1777644\n",
      "det: 0.07222605\n",
      "Validation loss mlp/pin: 0.613004/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.581641\n",
      "det: 0.022044951\n",
      "Validation loss mlp/pin: 0.491651/1.023422\n",
      "###### N,i = 5,1 #####\n",
      "M: 99.764595\n",
      "det: 7.125538e-05\n",
      "Validation loss mlp/pin: 1.464023/1.501628\n",
      "\n",
      "Epoch 667/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577593/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479550/0.981601\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492520/1.534736\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17777\n",
      "det: 0.07222672\n",
      "Validation loss mlp/pin: 0.612995/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.176093\n",
      "det: 0.022044668\n",
      "Validation loss mlp/pin: 0.491645/1.023417\n",
      "###### N,i = 5,1 #####\n",
      "M: 171.95505\n",
      "det: 7.12629e-05\n",
      "Validation loss mlp/pin: 1.464023/1.501628\n",
      "\n",
      "Epoch 668/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577585/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479544/0.981596\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492519/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1777763\n",
      "det: 0.072227344\n",
      "Validation loss mlp/pin: 0.612987/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.856857\n",
      "det: 0.02204436\n",
      "Validation loss mlp/pin: 0.491639/1.023412\n",
      "###### N,i = 5,1 #####\n",
      "M: 59.99762\n",
      "det: 7.12744e-05\n",
      "Validation loss mlp/pin: 1.464022/1.501628\n",
      "\n",
      "Epoch 669/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577577/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479538/0.981591\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492519/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177782\n",
      "det: 0.07222798\n",
      "Validation loss mlp/pin: 0.612978/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.090626\n",
      "det: 0.022044092\n",
      "Validation loss mlp/pin: 0.491632/1.023407\n",
      "###### N,i = 5,1 #####\n",
      "M: 87.458275\n",
      "det: 7.128492e-05\n",
      "Validation loss mlp/pin: 1.464022/1.501628\n",
      "\n",
      "Epoch 670/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577568/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479532/0.981587\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492518/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1777883\n",
      "det: 0.07222863\n",
      "Validation loss mlp/pin: 0.612969/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.499922\n",
      "det: 0.022043811\n",
      "Validation loss mlp/pin: 0.491626/1.023403\n",
      "###### N,i = 5,1 #####\n",
      "M: 104.224014\n",
      "det: 7.127787e-05\n",
      "Validation loss mlp/pin: 1.464021/1.501628\n",
      "\n",
      "Epoch 671/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577560/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479526/0.981583\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492518/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1777945\n",
      "det: 0.072229244\n",
      "Validation loss mlp/pin: 0.612961/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.411705\n",
      "det: 0.022043496\n",
      "Validation loss mlp/pin: 0.491620/1.023398\n",
      "###### N,i = 5,1 #####\n",
      "M: 60.387375\n",
      "det: 7.1289694e-05\n",
      "Validation loss mlp/pin: 1.464020/1.501628\n",
      "\n",
      "Epoch 672/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577552/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479521/0.981578\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492516/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1778\n",
      "det: 0.072229885\n",
      "Validation loss mlp/pin: 0.612952/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.528677\n",
      "det: 0.02204322\n",
      "Validation loss mlp/pin: 0.491614/1.023393\n",
      "###### N,i = 5,1 #####\n",
      "M: 194.2193\n",
      "det: 7.1310744e-05\n",
      "Validation loss mlp/pin: 1.464020/1.501628\n",
      "\n",
      "Epoch 673/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577544/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479515/0.981573\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492516/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177806\n",
      "det: 0.07223049\n",
      "Validation loss mlp/pin: 0.612944/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.2840757\n",
      "det: 0.022042934\n",
      "Validation loss mlp/pin: 0.491609/1.023388\n",
      "###### N,i = 5,1 #####\n",
      "M: 88.611984\n",
      "det: 7.1312534e-05\n",
      "Validation loss mlp/pin: 1.464020/1.501628\n",
      "\n",
      "Epoch 674/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577536/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479509/0.981569\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492517/1.534738\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177811\n",
      "det: 0.07223112\n",
      "Validation loss mlp/pin: 0.612936/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.600967\n",
      "det: 0.02204266\n",
      "Validation loss mlp/pin: 0.491603/1.023383\n",
      "###### N,i = 5,1 #####\n",
      "M: 108.59091\n",
      "det: 7.131985e-05\n",
      "Validation loss mlp/pin: 1.464019/1.501628\n",
      "\n",
      "Epoch 675/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577528/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479504/0.981564\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492516/1.534735\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177817\n",
      "det: 0.07223172\n",
      "Validation loss mlp/pin: 0.612928/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.676252\n",
      "det: 0.02204238\n",
      "Validation loss mlp/pin: 0.491597/1.023378\n",
      "###### N,i = 5,1 #####\n",
      "M: 95.68917\n",
      "det: 7.131368e-05\n",
      "Validation loss mlp/pin: 1.464019/1.501628\n",
      "\n",
      "Epoch 676/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577520/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479498/0.981560\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492514/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177822\n",
      "det: 0.07223233\n",
      "Validation loss mlp/pin: 0.612920/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.609021\n",
      "det: 0.022042114\n",
      "Validation loss mlp/pin: 0.491591/1.023374\n",
      "###### N,i = 5,1 #####\n",
      "M: 127.75827\n",
      "det: 7.133451e-05\n",
      "Validation loss mlp/pin: 1.464018/1.501628\n",
      "\n",
      "Epoch 677/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577512/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479493/0.981556\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492514/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177828\n",
      "det: 0.07223295\n",
      "Validation loss mlp/pin: 0.612912/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.544252\n",
      "det: 0.022041855\n",
      "Validation loss mlp/pin: 0.491586/1.023369\n",
      "###### N,i = 5,1 #####\n",
      "M: 245.65256\n",
      "det: 7.134383e-05\n",
      "Validation loss mlp/pin: 1.464018/1.501628\n",
      "\n",
      "Epoch 678/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577505/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479488/0.981552\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492514/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1778336\n",
      "det: 0.07223353\n",
      "Validation loss mlp/pin: 0.612904/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.753251\n",
      "det: 0.022041585\n",
      "Validation loss mlp/pin: 0.491580/1.023365\n",
      "###### N,i = 5,1 #####\n",
      "M: 128.42754\n",
      "det: 7.133819e-05\n",
      "Validation loss mlp/pin: 1.464018/1.501628\n",
      "\n",
      "Epoch 679/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577497/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479482/0.981547\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492515/1.534739\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1778393\n",
      "det: 0.0722341\n",
      "Validation loss mlp/pin: 0.612896/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.443184\n",
      "det: 0.022041341\n",
      "Validation loss mlp/pin: 0.491575/1.023360\n",
      "###### N,i = 5,1 #####\n",
      "M: 97.80228\n",
      "det: 7.135347e-05\n",
      "Validation loss mlp/pin: 1.464017/1.501628\n",
      "\n",
      "Epoch 680/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577490/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479477/0.981543\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492514/1.534736\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177844\n",
      "det: 0.072234675\n",
      "Validation loss mlp/pin: 0.612888/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.133172\n",
      "det: 0.022041062\n",
      "Validation loss mlp/pin: 0.491569/1.023356\n",
      "###### N,i = 5,1 #####\n",
      "M: 147.67456\n",
      "det: 7.135654e-05\n",
      "Validation loss mlp/pin: 1.464017/1.501628\n",
      "\n",
      "Epoch 681/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577482/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479471/0.981539\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492512/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17785\n",
      "det: 0.07223524\n",
      "Validation loss mlp/pin: 0.612880/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.45484\n",
      "det: 0.022040807\n",
      "Validation loss mlp/pin: 0.491564/1.023351\n",
      "###### N,i = 5,1 #####\n",
      "M: 180.06937\n",
      "det: 7.1353395e-05\n",
      "Validation loss mlp/pin: 1.464016/1.501628\n",
      "\n",
      "Epoch 682/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577475/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479466/0.981535\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492511/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177855\n",
      "det: 0.07223581\n",
      "Validation loss mlp/pin: 0.612873/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.908712\n",
      "det: 0.022040555\n",
      "Validation loss mlp/pin: 0.491558/1.023347\n",
      "###### N,i = 5,1 #####\n",
      "M: 170.35782\n",
      "det: 7.136463e-05\n",
      "Validation loss mlp/pin: 1.464016/1.501628\n",
      "\n",
      "Epoch 683/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577467/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479461/0.981531\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492511/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17786\n",
      "det: 0.072236374\n",
      "Validation loss mlp/pin: 0.612865/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 19.901518\n",
      "det: 0.02204028\n",
      "Validation loss mlp/pin: 0.491553/1.023342\n",
      "###### N,i = 5,1 #####\n",
      "M: 181.97595\n",
      "det: 7.1363494e-05\n",
      "Validation loss mlp/pin: 1.464015/1.501628\n",
      "\n",
      "Epoch 684/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577460/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479456/0.981527\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492510/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177865\n",
      "det: 0.07223692\n",
      "Validation loss mlp/pin: 0.612858/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.686511\n",
      "det: 0.02204004\n",
      "Validation loss mlp/pin: 0.491548/1.023338\n",
      "###### N,i = 5,1 #####\n",
      "M: 153.64409\n",
      "det: 7.138348e-05\n",
      "Validation loss mlp/pin: 1.464015/1.501628\n",
      "\n",
      "Epoch 685/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577453/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479451/0.981522\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492510/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1778703\n",
      "det: 0.07223747\n",
      "Validation loss mlp/pin: 0.612850/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.82782\n",
      "det: 0.022039803\n",
      "Validation loss mlp/pin: 0.491543/1.023334\n",
      "###### N,i = 5,1 #####\n",
      "M: 133.66473\n",
      "det: 7.139298e-05\n",
      "Validation loss mlp/pin: 1.464014/1.501628\n",
      "\n",
      "Epoch 686/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577446/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479446/0.981519\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492509/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1778755\n",
      "det: 0.07223803\n",
      "Validation loss mlp/pin: 0.612843/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.248002\n",
      "det: 0.02203957\n",
      "Validation loss mlp/pin: 0.491537/1.023329\n",
      "###### N,i = 5,1 #####\n",
      "M: 83.78219\n",
      "det: 7.138856e-05\n",
      "Validation loss mlp/pin: 1.464014/1.501628\n",
      "\n",
      "Epoch 687/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577438/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479441/0.981515\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492509/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1778803\n",
      "det: 0.072238564\n",
      "Validation loss mlp/pin: 0.612836/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.476786\n",
      "det: 0.022039317\n",
      "Validation loss mlp/pin: 0.491532/1.023325\n",
      "###### N,i = 5,1 #####\n",
      "M: 128.66336\n",
      "det: 7.1386654e-05\n",
      "Validation loss mlp/pin: 1.464014/1.501628\n",
      "\n",
      "Epoch 688/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577432/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479436/0.981511\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492508/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177885\n",
      "det: 0.072239086\n",
      "Validation loss mlp/pin: 0.612829/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.8524685\n",
      "det: 0.022039087\n",
      "Validation loss mlp/pin: 0.491527/1.023321\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.98836\n",
      "det: 7.1402574e-05\n",
      "Validation loss mlp/pin: 1.464013/1.501628\n",
      "\n",
      "Epoch 689/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577425/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479432/0.981507\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492508/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17789\n",
      "det: 0.07223961\n",
      "Validation loss mlp/pin: 0.612822/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.3053713\n",
      "det: 0.022038857\n",
      "Validation loss mlp/pin: 0.491522/1.023317\n",
      "###### N,i = 5,1 #####\n",
      "M: 233.56117\n",
      "det: 7.141023e-05\n",
      "Validation loss mlp/pin: 1.464013/1.501628\n",
      "\n",
      "Epoch 690/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577418/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479427/0.981503\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492508/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1778946\n",
      "det: 0.07224011\n",
      "Validation loss mlp/pin: 0.612815/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.5209374\n",
      "det: 0.022038642\n",
      "Validation loss mlp/pin: 0.491517/1.023313\n",
      "###### N,i = 5,1 #####\n",
      "M: 161.88881\n",
      "det: 7.141503e-05\n",
      "Validation loss mlp/pin: 1.464013/1.501628\n",
      "\n",
      "Epoch 691/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577411/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479422/0.981499\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492507/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1778994\n",
      "det: 0.07224064\n",
      "Validation loss mlp/pin: 0.612808/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.059872\n",
      "det: 0.022038415\n",
      "Validation loss mlp/pin: 0.491512/1.023309\n",
      "###### N,i = 5,1 #####\n",
      "M: 134.11385\n",
      "det: 7.142038e-05\n",
      "Validation loss mlp/pin: 1.464012/1.501628\n",
      "\n",
      "Epoch 692/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577405/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479417/0.981496\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492506/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177904\n",
      "det: 0.07224115\n",
      "Validation loss mlp/pin: 0.612801/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.219822\n",
      "det: 0.022038177\n",
      "Validation loss mlp/pin: 0.491508/1.023305\n",
      "###### N,i = 5,1 #####\n",
      "M: 168.71773\n",
      "det: 7.142523e-05\n",
      "Validation loss mlp/pin: 1.464012/1.501628\n",
      "\n",
      "Epoch 693/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577398/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479413/0.981492\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492507/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177909\n",
      "det: 0.07224166\n",
      "Validation loss mlp/pin: 0.612794/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.66753\n",
      "det: 0.022037959\n",
      "Validation loss mlp/pin: 0.491503/1.023301\n",
      "###### N,i = 5,1 #####\n",
      "M: 149.07886\n",
      "det: 7.143084e-05\n",
      "Validation loss mlp/pin: 1.464012/1.501628\n",
      "\n",
      "Epoch 694/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577391/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479408/0.981488\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492506/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779137\n",
      "det: 0.07224214\n",
      "Validation loss mlp/pin: 0.612788/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.034683\n",
      "det: 0.02203774\n",
      "Validation loss mlp/pin: 0.491498/1.023297\n",
      "###### N,i = 5,1 #####\n",
      "M: 129.05626\n",
      "det: 7.1435235e-05\n",
      "Validation loss mlp/pin: 1.464011/1.501628\n",
      "\n",
      "Epoch 695/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577385/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479404/0.981485\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492506/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779184\n",
      "det: 0.07224263\n",
      "Validation loss mlp/pin: 0.612781/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.444504\n",
      "det: 0.022037517\n",
      "Validation loss mlp/pin: 0.491493/1.023293\n",
      "###### N,i = 5,1 #####\n",
      "M: 127.16535\n",
      "det: 7.144722e-05\n",
      "Validation loss mlp/pin: 1.464011/1.501628\n",
      "\n",
      "Epoch 696/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577378/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479399/0.981481\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492505/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779227\n",
      "det: 0.07224314\n",
      "Validation loss mlp/pin: 0.612774/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.5862684\n",
      "det: 0.022037303\n",
      "Validation loss mlp/pin: 0.491489/1.023289\n",
      "###### N,i = 5,1 #####\n",
      "M: 85.40607\n",
      "det: 7.144495e-05\n",
      "Validation loss mlp/pin: 1.464010/1.501628\n",
      "\n",
      "Epoch 697/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577372/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479394/0.981478\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492505/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177927\n",
      "det: 0.07224361\n",
      "Validation loss mlp/pin: 0.612768/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.447749\n",
      "det: 0.022037094\n",
      "Validation loss mlp/pin: 0.491484/1.023286\n",
      "###### N,i = 5,1 #####\n",
      "M: 139.75517\n",
      "det: 7.145636e-05\n",
      "Validation loss mlp/pin: 1.464010/1.501628\n",
      "\n",
      "Epoch 698/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577366/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479390/0.981475\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492504/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177932\n",
      "det: 0.072244115\n",
      "Validation loss mlp/pin: 0.612761/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.351944\n",
      "det: 0.022036873\n",
      "Validation loss mlp/pin: 0.491480/1.023282\n",
      "###### N,i = 5,1 #####\n",
      "M: 176.20552\n",
      "det: 7.145172e-05\n",
      "Validation loss mlp/pin: 1.464010/1.501628\n",
      "\n",
      "Epoch 699/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577360/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479386/0.981471\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492504/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177936\n",
      "det: 0.07224459\n",
      "Validation loss mlp/pin: 0.612755/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.565455\n",
      "det: 0.022036681\n",
      "Validation loss mlp/pin: 0.491475/1.023278\n",
      "###### N,i = 5,1 #####\n",
      "M: 131.56104\n",
      "det: 7.14563e-05\n",
      "Validation loss mlp/pin: 1.464009/1.501628\n",
      "\n",
      "Epoch 700/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577354/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479381/0.981467\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492503/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779404\n",
      "det: 0.07224507\n",
      "Validation loss mlp/pin: 0.612749/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.542067\n",
      "det: 0.022036454\n",
      "Validation loss mlp/pin: 0.491471/1.023274\n",
      "###### N,i = 5,1 #####\n",
      "M: 104.22654\n",
      "det: 7.147594e-05\n",
      "Validation loss mlp/pin: 1.464009/1.501628\n",
      "\n",
      "Epoch 701/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577347/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479377/0.981464\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492503/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779447\n",
      "det: 0.0722455\n",
      "Validation loss mlp/pin: 0.612742/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.947268\n",
      "det: 0.022036241\n",
      "Validation loss mlp/pin: 0.491466/1.023271\n",
      "###### N,i = 5,1 #####\n",
      "M: 66.562256\n",
      "det: 7.1470684e-05\n",
      "Validation loss mlp/pin: 1.464009/1.501628\n",
      "\n",
      "Epoch 702/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577342/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479373/0.981460\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492503/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779485\n",
      "det: 0.07224595\n",
      "Validation loss mlp/pin: 0.612736/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.63868\n",
      "det: 0.022036036\n",
      "Validation loss mlp/pin: 0.491462/1.023267\n",
      "###### N,i = 5,1 #####\n",
      "M: 173.87256\n",
      "det: 7.1466915e-05\n",
      "Validation loss mlp/pin: 1.464008/1.501628\n",
      "\n",
      "Epoch 703/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577335/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479369/0.981457\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492503/1.534733\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779532\n",
      "det: 0.0722464\n",
      "Validation loss mlp/pin: 0.612730/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.425502\n",
      "det: 0.022035828\n",
      "Validation loss mlp/pin: 0.491458/1.023263\n",
      "###### N,i = 5,1 #####\n",
      "M: 114.79375\n",
      "det: 7.1475e-05\n",
      "Validation loss mlp/pin: 1.464008/1.501628\n",
      "\n",
      "Epoch 704/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577329/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479364/0.981454\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492501/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779575\n",
      "det: 0.07224684\n",
      "Validation loss mlp/pin: 0.612724/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.34254\n",
      "det: 0.022035627\n",
      "Validation loss mlp/pin: 0.491453/1.023260\n",
      "###### N,i = 5,1 #####\n",
      "M: 81.46452\n",
      "det: 7.148939e-05\n",
      "Validation loss mlp/pin: 1.464007/1.501628\n",
      "\n",
      "Epoch 705/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577324/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479360/0.981451\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492501/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779613\n",
      "det: 0.072247304\n",
      "Validation loss mlp/pin: 0.612718/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.370972\n",
      "det: 0.022035437\n",
      "Validation loss mlp/pin: 0.491449/1.023257\n",
      "###### N,i = 5,1 #####\n",
      "M: 152.12352\n",
      "det: 7.148653e-05\n",
      "Validation loss mlp/pin: 1.464007/1.501628\n",
      "\n",
      "Epoch 706/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577318/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479356/0.981448\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492502/1.534734\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779656\n",
      "det: 0.072247736\n",
      "Validation loss mlp/pin: 0.612712/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.001015\n",
      "det: 0.022035243\n",
      "Validation loss mlp/pin: 0.491445/1.023253\n",
      "###### N,i = 5,1 #####\n",
      "M: 67.79972\n",
      "det: 7.149941e-05\n",
      "Validation loss mlp/pin: 1.464007/1.501628\n",
      "\n",
      "Epoch 707/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577312/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479353/0.981444\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492501/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177969\n",
      "det: 0.07224816\n",
      "Validation loss mlp/pin: 0.612706/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.443052\n",
      "det: 0.022035029\n",
      "Validation loss mlp/pin: 0.491441/1.023250\n",
      "###### N,i = 5,1 #####\n",
      "M: 98.70991\n",
      "det: 7.149893e-05\n",
      "Validation loss mlp/pin: 1.464007/1.501628\n",
      "\n",
      "Epoch 708/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577306/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479348/0.981441\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492501/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779737\n",
      "det: 0.07224861\n",
      "Validation loss mlp/pin: 0.612700/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.529982\n",
      "det: 0.022034837\n",
      "Validation loss mlp/pin: 0.491437/1.023246\n",
      "###### N,i = 5,1 #####\n",
      "M: 88.68533\n",
      "det: 7.151254e-05\n",
      "Validation loss mlp/pin: 1.464006/1.501628\n",
      "\n",
      "Epoch 709/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577301/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479345/0.981438\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492500/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779776\n",
      "det: 0.07224903\n",
      "Validation loss mlp/pin: 0.612694/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.414228\n",
      "det: 0.02203466\n",
      "Validation loss mlp/pin: 0.491433/1.023243\n",
      "###### N,i = 5,1 #####\n",
      "M: 64.80989\n",
      "det: 7.150879e-05\n",
      "Validation loss mlp/pin: 1.464006/1.501628\n",
      "\n",
      "Epoch 710/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577295/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479341/0.981435\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492499/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779814\n",
      "det: 0.072249435\n",
      "Validation loss mlp/pin: 0.612689/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.530389\n",
      "det: 0.02203447\n",
      "Validation loss mlp/pin: 0.491429/1.023240\n",
      "###### N,i = 5,1 #####\n",
      "M: 96.82078\n",
      "det: 7.1521514e-05\n",
      "Validation loss mlp/pin: 1.464006/1.501628\n",
      "\n",
      "Epoch 711/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577290/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479337/0.981432\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492500/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779847\n",
      "det: 0.072249874\n",
      "Validation loss mlp/pin: 0.612683/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.539696\n",
      "det: 0.022034278\n",
      "Validation loss mlp/pin: 0.491425/1.023236\n",
      "###### N,i = 5,1 #####\n",
      "M: 85.34057\n",
      "det: 7.1514136e-05\n",
      "Validation loss mlp/pin: 1.464006/1.501628\n",
      "\n",
      "Epoch 712/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577284/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479333/0.981429\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492499/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177989\n",
      "det: 0.07225029\n",
      "Validation loss mlp/pin: 0.612677/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.539734\n",
      "det: 0.022034079\n",
      "Validation loss mlp/pin: 0.491421/1.023233\n",
      "###### N,i = 5,1 #####\n",
      "M: 58.117363\n",
      "det: 7.15184e-05\n",
      "Validation loss mlp/pin: 1.464005/1.501628\n",
      "\n",
      "Epoch 713/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577279/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479329/0.981426\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492498/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.177993\n",
      "det: 0.072250694\n",
      "Validation loss mlp/pin: 0.612672/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.760693\n",
      "det: 0.022033906\n",
      "Validation loss mlp/pin: 0.491417/1.023230\n",
      "###### N,i = 5,1 #####\n",
      "M: 58.76996\n",
      "det: 7.1526316e-05\n",
      "Validation loss mlp/pin: 1.464005/1.501628\n",
      "\n",
      "Epoch 714/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577273/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479325/0.981423\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492499/1.534732\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1779966\n",
      "det: 0.07225112\n",
      "Validation loss mlp/pin: 0.612666/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.116762\n",
      "det: 0.022033732\n",
      "Validation loss mlp/pin: 0.491413/1.023227\n",
      "###### N,i = 5,1 #####\n",
      "M: 64.903404\n",
      "det: 7.153148e-05\n",
      "Validation loss mlp/pin: 1.464005/1.501628\n",
      "\n",
      "Epoch 715/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577268/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479322/0.981420\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492498/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780005\n",
      "det: 0.07225153\n",
      "Validation loss mlp/pin: 0.612661/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.596401\n",
      "det: 0.022033535\n",
      "Validation loss mlp/pin: 0.491409/1.023224\n",
      "###### N,i = 5,1 #####\n",
      "M: 118.490265\n",
      "det: 7.154248e-05\n",
      "Validation loss mlp/pin: 1.464004/1.501628\n",
      "\n",
      "Epoch 716/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577263/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479318/0.981417\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492497/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178004\n",
      "det: 0.072251916\n",
      "Validation loss mlp/pin: 0.612655/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.9586034\n",
      "det: 0.022033375\n",
      "Validation loss mlp/pin: 0.491405/1.023221\n",
      "###### N,i = 5,1 #####\n",
      "M: 108.99521\n",
      "det: 7.1531205e-05\n",
      "Validation loss mlp/pin: 1.464004/1.501628\n",
      "\n",
      "Epoch 717/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577258/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479314/0.981414\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492497/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780076\n",
      "det: 0.072252326\n",
      "Validation loss mlp/pin: 0.612650/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.407568\n",
      "det: 0.022033174\n",
      "Validation loss mlp/pin: 0.491401/1.023218\n",
      "###### N,i = 5,1 #####\n",
      "M: 77.535095\n",
      "det: 7.1537936e-05\n",
      "Validation loss mlp/pin: 1.464004/1.501628\n",
      "\n",
      "Epoch 718/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577253/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479311/0.981411\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492497/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178011\n",
      "det: 0.07225271\n",
      "Validation loss mlp/pin: 0.612645/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.714114\n",
      "det: 0.02203301\n",
      "Validation loss mlp/pin: 0.491398/1.023215\n",
      "###### N,i = 5,1 #####\n",
      "M: 195.20224\n",
      "det: 7.154649e-05\n",
      "Validation loss mlp/pin: 1.464003/1.501628\n",
      "\n",
      "Epoch 719/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577248/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479307/0.981409\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492497/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780148\n",
      "det: 0.07225309\n",
      "Validation loss mlp/pin: 0.612640/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.404742\n",
      "det: 0.022032838\n",
      "Validation loss mlp/pin: 0.491394/1.023211\n",
      "###### N,i = 5,1 #####\n",
      "M: 159.19052\n",
      "det: 7.155248e-05\n",
      "Validation loss mlp/pin: 1.464003/1.501628\n",
      "\n",
      "Epoch 720/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577243/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479303/0.981406\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492496/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178018\n",
      "det: 0.07225347\n",
      "Validation loss mlp/pin: 0.612635/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.685337\n",
      "det: 0.022032663\n",
      "Validation loss mlp/pin: 0.491390/1.023209\n",
      "###### N,i = 5,1 #####\n",
      "M: 81.52194\n",
      "det: 7.156887e-05\n",
      "Validation loss mlp/pin: 1.464003/1.501628\n",
      "\n",
      "Epoch 721/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577238/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479300/0.981403\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492496/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780214\n",
      "det: 0.07225385\n",
      "Validation loss mlp/pin: 0.612630/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.800731\n",
      "det: 0.022032486\n",
      "Validation loss mlp/pin: 0.491387/1.023206\n",
      "###### N,i = 5,1 #####\n",
      "M: 149.50302\n",
      "det: 7.155648e-05\n",
      "Validation loss mlp/pin: 1.464002/1.501628\n",
      "\n",
      "Epoch 722/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577233/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479297/0.981400\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492496/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780252\n",
      "det: 0.07225422\n",
      "Validation loss mlp/pin: 0.612624/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.536947\n",
      "det: 0.022032326\n",
      "Validation loss mlp/pin: 0.491383/1.023203\n",
      "###### N,i = 5,1 #####\n",
      "M: 91.23389\n",
      "det: 7.155812e-05\n",
      "Validation loss mlp/pin: 1.464002/1.501628\n",
      "\n",
      "Epoch 723/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577228/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479293/0.981398\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492495/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780286\n",
      "det: 0.07225459\n",
      "Validation loss mlp/pin: 0.612619/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.618378\n",
      "det: 0.022032142\n",
      "Validation loss mlp/pin: 0.491380/1.023200\n",
      "###### N,i = 5,1 #####\n",
      "M: 99.8779\n",
      "det: 7.156806e-05\n",
      "Validation loss mlp/pin: 1.464002/1.501628\n",
      "\n",
      "Epoch 724/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577223/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479290/0.981395\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492495/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780314\n",
      "det: 0.07225495\n",
      "Validation loss mlp/pin: 0.612614/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.3690753\n",
      "det: 0.022031972\n",
      "Validation loss mlp/pin: 0.491376/1.023197\n",
      "###### N,i = 5,1 #####\n",
      "M: 184.36386\n",
      "det: 7.157401e-05\n",
      "Validation loss mlp/pin: 1.464001/1.501628\n",
      "\n",
      "Epoch 725/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577218/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479286/0.981392\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492495/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178035\n",
      "det: 0.07225531\n",
      "Validation loss mlp/pin: 0.612609/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.946545\n",
      "det: 0.022031825\n",
      "Validation loss mlp/pin: 0.491373/1.023194\n",
      "###### N,i = 5,1 #####\n",
      "M: 76.55406\n",
      "det: 7.157633e-05\n",
      "Validation loss mlp/pin: 1.464001/1.501628\n",
      "\n",
      "Epoch 726/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577214/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479283/0.981390\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492494/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780386\n",
      "det: 0.072255656\n",
      "Validation loss mlp/pin: 0.612605/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.477879\n",
      "det: 0.022031652\n",
      "Validation loss mlp/pin: 0.491369/1.023191\n",
      "###### N,i = 5,1 #####\n",
      "M: 117.46607\n",
      "det: 7.158403e-05\n",
      "Validation loss mlp/pin: 1.464001/1.501628\n",
      "\n",
      "Epoch 727/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577209/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479279/0.981387\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492494/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178042\n",
      "det: 0.072256\n",
      "Validation loss mlp/pin: 0.612600/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.428709\n",
      "det: 0.02203147\n",
      "Validation loss mlp/pin: 0.491366/1.023189\n",
      "###### N,i = 5,1 #####\n",
      "M: 127.99201\n",
      "det: 7.1584225e-05\n",
      "Validation loss mlp/pin: 1.464001/1.501628\n",
      "\n",
      "Epoch 728/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577204/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479276/0.981384\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492494/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178045\n",
      "det: 0.07225636\n",
      "Validation loss mlp/pin: 0.612595/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.080784\n",
      "det: 0.0220313\n",
      "Validation loss mlp/pin: 0.491362/1.023186\n",
      "###### N,i = 5,1 #####\n",
      "M: 114.68034\n",
      "det: 7.1594004e-05\n",
      "Validation loss mlp/pin: 1.464001/1.501628\n",
      "\n",
      "Epoch 729/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577200/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479273/0.981382\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492493/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178048\n",
      "det: 0.07225672\n",
      "Validation loss mlp/pin: 0.612591/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.016038\n",
      "det: 0.022031141\n",
      "Validation loss mlp/pin: 0.491359/1.023183\n",
      "###### N,i = 5,1 #####\n",
      "M: 133.13971\n",
      "det: 7.158264e-05\n",
      "Validation loss mlp/pin: 1.464000/1.501628\n",
      "\n",
      "Epoch 730/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577195/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479270/0.981379\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492493/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178052\n",
      "det: 0.07225704\n",
      "Validation loss mlp/pin: 0.612586/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.9517617\n",
      "det: 0.022030992\n",
      "Validation loss mlp/pin: 0.491356/1.023180\n",
      "###### N,i = 5,1 #####\n",
      "M: 161.50127\n",
      "det: 7.160176e-05\n",
      "Validation loss mlp/pin: 1.464000/1.501628\n",
      "\n",
      "Epoch 731/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577191/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479267/0.981377\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492493/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178055\n",
      "det: 0.0722574\n",
      "Validation loss mlp/pin: 0.612581/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.459964\n",
      "det: 0.022030829\n",
      "Validation loss mlp/pin: 0.491352/1.023178\n",
      "###### N,i = 5,1 #####\n",
      "M: 80.09923\n",
      "det: 7.160532e-05\n",
      "Validation loss mlp/pin: 1.464000/1.501629\n",
      "\n",
      "Epoch 732/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577186/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479263/0.981374\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492493/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780577\n",
      "det: 0.07225773\n",
      "Validation loss mlp/pin: 0.612577/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.0948744\n",
      "det: 0.02203067\n",
      "Validation loss mlp/pin: 0.491349/1.023175\n",
      "###### N,i = 5,1 #####\n",
      "M: 89.59898\n",
      "det: 7.160827e-05\n",
      "Validation loss mlp/pin: 1.464000/1.501628\n",
      "\n",
      "Epoch 733/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577182/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479261/0.981372\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492492/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178061\n",
      "det: 0.072258085\n",
      "Validation loss mlp/pin: 0.612572/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 18.788902\n",
      "det: 0.022030506\n",
      "Validation loss mlp/pin: 0.491346/1.023172\n",
      "###### N,i = 5,1 #####\n",
      "M: 119.043976\n",
      "det: 7.161293e-05\n",
      "Validation loss mlp/pin: 1.463999/1.501628\n",
      "\n",
      "Epoch 734/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577178/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479257/0.981370\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492492/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178064\n",
      "det: 0.07225842\n",
      "Validation loss mlp/pin: 0.612568/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.209426\n",
      "det: 0.022030346\n",
      "Validation loss mlp/pin: 0.491343/1.023170\n",
      "###### N,i = 5,1 #####\n",
      "M: 73.55308\n",
      "det: 7.161815e-05\n",
      "Validation loss mlp/pin: 1.463999/1.501628\n",
      "\n",
      "Epoch 735/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577173/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479254/0.981367\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492492/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178067\n",
      "det: 0.07225877\n",
      "Validation loss mlp/pin: 0.612563/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.702561\n",
      "det: 0.022030197\n",
      "Validation loss mlp/pin: 0.491340/1.023167\n",
      "###### N,i = 5,1 #####\n",
      "M: 192.57867\n",
      "det: 7.160365e-05\n",
      "Validation loss mlp/pin: 1.463999/1.501628\n",
      "\n",
      "Epoch 736/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577169/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479251/0.981365\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492491/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17807\n",
      "det: 0.07225912\n",
      "Validation loss mlp/pin: 0.612559/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.260073\n",
      "det: 0.02203004\n",
      "Validation loss mlp/pin: 0.491337/1.023165\n",
      "###### N,i = 5,1 #####\n",
      "M: 105.29757\n",
      "det: 7.1631235e-05\n",
      "Validation loss mlp/pin: 1.463998/1.501628\n",
      "\n",
      "Epoch 737/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577165/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479249/0.981363\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492491/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178073\n",
      "det: 0.07225945\n",
      "Validation loss mlp/pin: 0.612554/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.075705\n",
      "det: 0.0220299\n",
      "Validation loss mlp/pin: 0.491333/1.023162\n",
      "###### N,i = 5,1 #####\n",
      "M: 129.24086\n",
      "det: 7.1626324e-05\n",
      "Validation loss mlp/pin: 1.463998/1.501628\n",
      "\n",
      "Epoch 738/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577161/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479245/0.981360\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492491/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780763\n",
      "det: 0.07225975\n",
      "Validation loss mlp/pin: 0.612550/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.027093\n",
      "det: 0.022029763\n",
      "Validation loss mlp/pin: 0.491330/1.023160\n",
      "###### N,i = 5,1 #####\n",
      "M: 90.699936\n",
      "det: 7.162179e-05\n",
      "Validation loss mlp/pin: 1.463998/1.501628\n",
      "\n",
      "Epoch 739/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577156/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479242/0.981358\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492490/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178079\n",
      "det: 0.072260074\n",
      "Validation loss mlp/pin: 0.612546/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.108196\n",
      "det: 0.022029607\n",
      "Validation loss mlp/pin: 0.491327/1.023158\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.57124\n",
      "det: 7.163959e-05\n",
      "Validation loss mlp/pin: 1.463998/1.501628\n",
      "\n",
      "Epoch 740/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577152/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479240/0.981356\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492490/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178082\n",
      "det: 0.0722604\n",
      "Validation loss mlp/pin: 0.612541/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.108204\n",
      "det: 0.02202948\n",
      "Validation loss mlp/pin: 0.491324/1.023155\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.58005\n",
      "det: 7.1628136e-05\n",
      "Validation loss mlp/pin: 1.463997/1.501628\n",
      "\n",
      "Epoch 741/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577148/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479237/0.981354\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492490/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178085\n",
      "det: 0.07226069\n",
      "Validation loss mlp/pin: 0.612537/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.764397\n",
      "det: 0.022029309\n",
      "Validation loss mlp/pin: 0.491321/1.023153\n",
      "###### N,i = 5,1 #####\n",
      "M: 87.40669\n",
      "det: 7.164508e-05\n",
      "Validation loss mlp/pin: 1.463997/1.501628\n",
      "\n",
      "Epoch 742/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577144/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479234/0.981351\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492490/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780877\n",
      "det: 0.07226098\n",
      "Validation loss mlp/pin: 0.612533/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.857\n",
      "det: 0.022029174\n",
      "Validation loss mlp/pin: 0.491319/1.023150\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.67845\n",
      "det: 7.1642266e-05\n",
      "Validation loss mlp/pin: 1.463997/1.501628\n",
      "\n",
      "Epoch 743/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577140/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479231/0.981349\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492490/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780906\n",
      "det: 0.07226129\n",
      "Validation loss mlp/pin: 0.612529/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.490487\n",
      "det: 0.022029052\n",
      "Validation loss mlp/pin: 0.491316/1.023148\n",
      "###### N,i = 5,1 #####\n",
      "M: 83.47299\n",
      "det: 7.163882e-05\n",
      "Validation loss mlp/pin: 1.463997/1.501628\n",
      "\n",
      "Epoch 744/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577136/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479228/0.981347\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492489/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178093\n",
      "det: 0.072261564\n",
      "Validation loss mlp/pin: 0.612525/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.5343075\n",
      "det: 0.022028914\n",
      "Validation loss mlp/pin: 0.491313/1.023146\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.683105\n",
      "det: 7.1648545e-05\n",
      "Validation loss mlp/pin: 1.463997/1.501628\n",
      "\n",
      "Epoch 745/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577132/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479226/0.981345\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492489/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780953\n",
      "det: 0.07226187\n",
      "Validation loss mlp/pin: 0.612521/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.795395\n",
      "det: 0.022028774\n",
      "Validation loss mlp/pin: 0.491310/1.023144\n",
      "###### N,i = 5,1 #####\n",
      "M: 134.08496\n",
      "det: 7.166565e-05\n",
      "Validation loss mlp/pin: 1.463996/1.501628\n",
      "\n",
      "Epoch 746/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577128/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479223/0.981343\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492489/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1780977\n",
      "det: 0.07226216\n",
      "Validation loss mlp/pin: 0.612517/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.210659\n",
      "det: 0.022028646\n",
      "Validation loss mlp/pin: 0.491307/1.023141\n",
      "###### N,i = 5,1 #####\n",
      "M: 83.16298\n",
      "det: 7.165365e-05\n",
      "Validation loss mlp/pin: 1.463996/1.501628\n",
      "\n",
      "Epoch 747/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577125/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479220/0.981341\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492489/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781006\n",
      "det: 0.072262436\n",
      "Validation loss mlp/pin: 0.612513/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.308235\n",
      "det: 0.022028523\n",
      "Validation loss mlp/pin: 0.491304/1.023139\n",
      "###### N,i = 5,1 #####\n",
      "M: 70.60838\n",
      "det: 7.165711e-05\n",
      "Validation loss mlp/pin: 1.463996/1.501628\n",
      "\n",
      "Epoch 748/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577121/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479218/0.981339\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492488/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178104\n",
      "det: 0.07226273\n",
      "Validation loss mlp/pin: 0.612509/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.255739\n",
      "det: 0.022028381\n",
      "Validation loss mlp/pin: 0.491302/1.023137\n",
      "###### N,i = 5,1 #####\n",
      "M: 79.922935\n",
      "det: 7.1668976e-05\n",
      "Validation loss mlp/pin: 1.463996/1.501628\n",
      "\n",
      "Epoch 749/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577117/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479215/0.981337\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492488/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781063\n",
      "det: 0.072263\n",
      "Validation loss mlp/pin: 0.612505/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.624357\n",
      "det: 0.02202828\n",
      "Validation loss mlp/pin: 0.491299/1.023135\n",
      "###### N,i = 5,1 #####\n",
      "M: 168.26413\n",
      "det: 7.1666254e-05\n",
      "Validation loss mlp/pin: 1.463995/1.501628\n",
      "\n",
      "Epoch 750/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577114/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479212/0.981335\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492487/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178109\n",
      "det: 0.072263315\n",
      "Validation loss mlp/pin: 0.612502/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.544938\n",
      "det: 0.022028124\n",
      "Validation loss mlp/pin: 0.491296/1.023133\n",
      "###### N,i = 5,1 #####\n",
      "M: 175.20154\n",
      "det: 7.167329e-05\n",
      "Validation loss mlp/pin: 1.463995/1.501628\n",
      "\n",
      "Epoch 751/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577110/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479210/0.981333\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492487/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781116\n",
      "det: 0.072263606\n",
      "Validation loss mlp/pin: 0.612498/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.031692\n",
      "det: 0.022028053\n",
      "Validation loss mlp/pin: 0.491294/1.023131\n",
      "###### N,i = 5,1 #####\n",
      "M: 118.258835\n",
      "det: 7.1666494e-05\n",
      "Validation loss mlp/pin: 1.463995/1.501628\n",
      "\n",
      "Epoch 752/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577106/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479207/0.981331\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492487/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178114\n",
      "det: 0.072263874\n",
      "Validation loss mlp/pin: 0.612494/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.03171\n",
      "det: 0.022027915\n",
      "Validation loss mlp/pin: 0.491291/1.023129\n",
      "###### N,i = 5,1 #####\n",
      "M: 159.66156\n",
      "det: 7.169213e-05\n",
      "Validation loss mlp/pin: 1.463995/1.501628\n",
      "\n",
      "Epoch 753/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577103/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479204/0.981329\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492487/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781163\n",
      "det: 0.07226415\n",
      "Validation loss mlp/pin: 0.612491/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.397312\n",
      "det: 0.02202781\n",
      "Validation loss mlp/pin: 0.491288/1.023127\n",
      "###### N,i = 5,1 #####\n",
      "M: 122.47672\n",
      "det: 7.1681745e-05\n",
      "Validation loss mlp/pin: 1.463995/1.501628\n",
      "\n",
      "Epoch 754/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577099/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479202/0.981327\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492486/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781187\n",
      "det: 0.07226442\n",
      "Validation loss mlp/pin: 0.612487/2.617973\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.5590053\n",
      "det: 0.022027707\n",
      "Validation loss mlp/pin: 0.491286/1.023124\n",
      "###### N,i = 5,1 #####\n",
      "M: 79.15698\n",
      "det: 7.168521e-05\n",
      "Validation loss mlp/pin: 1.463994/1.501628\n",
      "\n",
      "Epoch 755/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577096/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479199/0.981325\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492486/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781216\n",
      "det: 0.07226468\n",
      "Validation loss mlp/pin: 0.612483/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.352055\n",
      "det: 0.022027582\n",
      "Validation loss mlp/pin: 0.491283/1.023122\n",
      "###### N,i = 5,1 #####\n",
      "M: 67.5467\n",
      "det: 7.168295e-05\n",
      "Validation loss mlp/pin: 1.463994/1.501628\n",
      "\n",
      "Epoch 756/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577092/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479197/0.981323\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492486/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178124\n",
      "det: 0.07226491\n",
      "Validation loss mlp/pin: 0.612480/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.541207\n",
      "det: 0.022027442\n",
      "Validation loss mlp/pin: 0.491281/1.023120\n",
      "###### N,i = 5,1 #####\n",
      "M: 117.03266\n",
      "det: 7.1688526e-05\n",
      "Validation loss mlp/pin: 1.463994/1.501628\n",
      "\n",
      "Epoch 757/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577089/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479195/0.981321\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492486/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781263\n",
      "det: 0.07226519\n",
      "Validation loss mlp/pin: 0.612476/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.3369913\n",
      "det: 0.022027329\n",
      "Validation loss mlp/pin: 0.491278/1.023118\n",
      "###### N,i = 5,1 #####\n",
      "M: 70.75377\n",
      "det: 7.169022e-05\n",
      "Validation loss mlp/pin: 1.463994/1.501628\n",
      "\n",
      "Epoch 758/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577085/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479192/0.981319\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492486/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781287\n",
      "det: 0.072265446\n",
      "Validation loss mlp/pin: 0.612473/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.3370075\n",
      "det: 0.022027219\n",
      "Validation loss mlp/pin: 0.491275/1.023116\n",
      "###### N,i = 5,1 #####\n",
      "M: 93.560425\n",
      "det: 7.1692826e-05\n",
      "Validation loss mlp/pin: 1.463994/1.501628\n",
      "\n",
      "Epoch 759/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577082/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479190/0.981317\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492485/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178131\n",
      "det: 0.072265714\n",
      "Validation loss mlp/pin: 0.612469/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.875642\n",
      "det: 0.02202711\n",
      "Validation loss mlp/pin: 0.491273/1.023114\n",
      "###### N,i = 5,1 #####\n",
      "M: 140.81383\n",
      "det: 7.169077e-05\n",
      "Validation loss mlp/pin: 1.463993/1.501628\n",
      "\n",
      "Epoch 760/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577078/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479187/0.981316\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492485/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781335\n",
      "det: 0.07226595\n",
      "Validation loss mlp/pin: 0.612466/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.54424\n",
      "det: 0.022026999\n",
      "Validation loss mlp/pin: 0.491271/1.023112\n",
      "###### N,i = 5,1 #####\n",
      "M: 88.5393\n",
      "det: 7.169943e-05\n",
      "Validation loss mlp/pin: 1.463993/1.501629\n",
      "\n",
      "Epoch 761/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577075/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479185/0.981314\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492485/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781354\n",
      "det: 0.07226622\n",
      "Validation loss mlp/pin: 0.612462/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.87463\n",
      "det: 0.022026887\n",
      "Validation loss mlp/pin: 0.491268/1.023110\n",
      "###### N,i = 5,1 #####\n",
      "M: 79.42657\n",
      "det: 7.169687e-05\n",
      "Validation loss mlp/pin: 1.463993/1.501628\n",
      "\n",
      "Epoch 762/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577072/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479183/0.981312\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492485/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178138\n",
      "det: 0.07226647\n",
      "Validation loss mlp/pin: 0.612459/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.897305\n",
      "det: 0.022026788\n",
      "Validation loss mlp/pin: 0.491266/1.023108\n",
      "###### N,i = 5,1 #####\n",
      "M: 114.82141\n",
      "det: 7.170069e-05\n",
      "Validation loss mlp/pin: 1.463993/1.501629\n",
      "\n",
      "Epoch 763/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577069/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479180/0.981310\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492485/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781397\n",
      "det: 0.0722667\n",
      "Validation loss mlp/pin: 0.612456/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.794389\n",
      "det: 0.022026675\n",
      "Validation loss mlp/pin: 0.491263/1.023106\n",
      "###### N,i = 5,1 #####\n",
      "M: 62.77494\n",
      "det: 7.17008e-05\n",
      "Validation loss mlp/pin: 1.463993/1.501628\n",
      "\n",
      "Epoch 764/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577065/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479178/0.981308\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492485/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781425\n",
      "det: 0.07226693\n",
      "Validation loss mlp/pin: 0.612452/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.425955\n",
      "det: 0.022026578\n",
      "Validation loss mlp/pin: 0.491261/1.023104\n",
      "###### N,i = 5,1 #####\n",
      "M: 97.29697\n",
      "det: 7.171168e-05\n",
      "Validation loss mlp/pin: 1.463992/1.501628\n",
      "\n",
      "Epoch 765/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577062/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479176/0.981306\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492484/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781445\n",
      "det: 0.072267175\n",
      "Validation loss mlp/pin: 0.612449/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.383471\n",
      "det: 0.022026451\n",
      "Validation loss mlp/pin: 0.491259/1.023103\n",
      "###### N,i = 5,1 #####\n",
      "M: 85.47632\n",
      "det: 7.171017e-05\n",
      "Validation loss mlp/pin: 1.463992/1.501628\n",
      "\n",
      "Epoch 766/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577059/2.588986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479174/0.981305\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492484/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178147\n",
      "det: 0.07226741\n",
      "Validation loss mlp/pin: 0.612446/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.15446\n",
      "det: 0.022026353\n",
      "Validation loss mlp/pin: 0.491256/1.023101\n",
      "###### N,i = 5,1 #####\n",
      "M: 78.01194\n",
      "det: 7.171927e-05\n",
      "Validation loss mlp/pin: 1.463992/1.501628\n",
      "\n",
      "Epoch 767/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577056/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479171/0.981303\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492484/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178149\n",
      "det: 0.072267644\n",
      "Validation loss mlp/pin: 0.612442/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.521727\n",
      "det: 0.022026252\n",
      "Validation loss mlp/pin: 0.491254/1.023099\n",
      "###### N,i = 5,1 #####\n",
      "M: 58.604103\n",
      "det: 7.172152e-05\n",
      "Validation loss mlp/pin: 1.463992/1.501628\n",
      "\n",
      "Epoch 768/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577053/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479169/0.981301\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492484/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178151\n",
      "det: 0.07226788\n",
      "Validation loss mlp/pin: 0.612439/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.520777\n",
      "det: 0.022026174\n",
      "Validation loss mlp/pin: 0.491252/1.023097\n",
      "###### N,i = 5,1 #####\n",
      "M: 126.1747\n",
      "det: 7.1719616e-05\n",
      "Validation loss mlp/pin: 1.463992/1.501628\n",
      "\n",
      "Epoch 769/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577050/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479167/0.981300\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492483/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178153\n",
      "det: 0.072268106\n",
      "Validation loss mlp/pin: 0.612436/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.850152\n",
      "det: 0.022026062\n",
      "Validation loss mlp/pin: 0.491250/1.023095\n",
      "###### N,i = 5,1 #####\n",
      "M: 111.029434\n",
      "det: 7.173284e-05\n",
      "Validation loss mlp/pin: 1.463992/1.501628\n",
      "\n",
      "Epoch 770/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577047/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479165/0.981298\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492483/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781554\n",
      "det: 0.07226834\n",
      "Validation loss mlp/pin: 0.612433/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 18.107876\n",
      "det: 0.022025954\n",
      "Validation loss mlp/pin: 0.491248/1.023093\n",
      "###### N,i = 5,1 #####\n",
      "M: 109.22711\n",
      "det: 7.172653e-05\n",
      "Validation loss mlp/pin: 1.463992/1.501628\n",
      "\n",
      "Epoch 771/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577043/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479163/0.981296\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492483/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178158\n",
      "det: 0.072268575\n",
      "Validation loss mlp/pin: 0.612430/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.522198\n",
      "det: 0.022025874\n",
      "Validation loss mlp/pin: 0.491245/1.023091\n",
      "###### N,i = 5,1 #####\n",
      "M: 109.222176\n",
      "det: 7.173357e-05\n",
      "Validation loss mlp/pin: 1.463991/1.501628\n",
      "\n",
      "Epoch 772/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577041/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479161/0.981295\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492483/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178159\n",
      "det: 0.07226879\n",
      "Validation loss mlp/pin: 0.612427/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 18.124966\n",
      "det: 0.022025758\n",
      "Validation loss mlp/pin: 0.491243/1.023090\n",
      "###### N,i = 5,1 #####\n",
      "M: 93.331985\n",
      "det: 7.173651e-05\n",
      "Validation loss mlp/pin: 1.463991/1.501628\n",
      "\n",
      "Epoch 773/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577038/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479159/0.981293\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492483/1.534731\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781616\n",
      "det: 0.07226903\n",
      "Validation loss mlp/pin: 0.612424/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 18.125006\n",
      "det: 0.022025686\n",
      "Validation loss mlp/pin: 0.491241/1.023088\n",
      "###### N,i = 5,1 #####\n",
      "M: 140.77597\n",
      "det: 7.17343e-05\n",
      "Validation loss mlp/pin: 1.463991/1.501628\n",
      "\n",
      "Epoch 774/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577035/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479157/0.981291\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492482/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781635\n",
      "det: 0.07226924\n",
      "Validation loss mlp/pin: 0.612421/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.194029\n",
      "det: 0.022025593\n",
      "Validation loss mlp/pin: 0.491239/1.023086\n",
      "###### N,i = 5,1 #####\n",
      "M: 96.19423\n",
      "det: 7.173316e-05\n",
      "Validation loss mlp/pin: 1.463991/1.501628\n",
      "\n",
      "Epoch 775/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577032/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479155/0.981290\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492482/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781654\n",
      "det: 0.07226946\n",
      "Validation loss mlp/pin: 0.612418/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.795759\n",
      "det: 0.022025514\n",
      "Validation loss mlp/pin: 0.491237/1.023084\n",
      "###### N,i = 5,1 #####\n",
      "M: 96.26718\n",
      "det: 7.174278e-05\n",
      "Validation loss mlp/pin: 1.463991/1.501628\n",
      "\n",
      "Epoch 776/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577029/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479153/0.981288\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492482/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781673\n",
      "det: 0.07226966\n",
      "Validation loss mlp/pin: 0.612415/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.893421\n",
      "det: 0.022025391\n",
      "Validation loss mlp/pin: 0.491235/1.023083\n",
      "###### N,i = 5,1 #####\n",
      "M: 116.82851\n",
      "det: 7.174256e-05\n",
      "Validation loss mlp/pin: 1.463991/1.501628\n",
      "\n",
      "Epoch 777/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577026/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479151/0.981286\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492482/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781693\n",
      "det: 0.07226989\n",
      "Validation loss mlp/pin: 0.612412/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.819616\n",
      "det: 0.022025324\n",
      "Validation loss mlp/pin: 0.491233/1.023081\n",
      "###### N,i = 5,1 #####\n",
      "M: 96.24962\n",
      "det: 7.174514e-05\n",
      "Validation loss mlp/pin: 1.463990/1.501628\n",
      "\n",
      "Epoch 778/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577023/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479149/0.981285\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492482/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178171\n",
      "det: 0.072270095\n",
      "Validation loss mlp/pin: 0.612409/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.3583703\n",
      "det: 0.022025224\n",
      "Validation loss mlp/pin: 0.491231/1.023079\n",
      "###### N,i = 5,1 #####\n",
      "M: 113.35842\n",
      "det: 7.174733e-05\n",
      "Validation loss mlp/pin: 1.463990/1.501628\n",
      "\n",
      "Epoch 779/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577021/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479147/0.981283\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492481/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178173\n",
      "det: 0.07227028\n",
      "Validation loss mlp/pin: 0.612406/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.939201\n",
      "det: 0.022025138\n",
      "Validation loss mlp/pin: 0.491229/1.023078\n",
      "###### N,i = 5,1 #####\n",
      "M: 180.35373\n",
      "det: 7.1752045e-05\n",
      "Validation loss mlp/pin: 1.463990/1.501628\n",
      "\n",
      "Epoch 780/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577018/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479145/0.981282\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492481/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178175\n",
      "det: 0.07227047\n",
      "Validation loss mlp/pin: 0.612403/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.5414176\n",
      "det: 0.022025045\n",
      "Validation loss mlp/pin: 0.491227/1.023076\n",
      "###### N,i = 5,1 #####\n",
      "M: 167.10149\n",
      "det: 7.174718e-05\n",
      "Validation loss mlp/pin: 1.463990/1.501628\n",
      "\n",
      "Epoch 781/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577015/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479143/0.981280\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492481/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178177\n",
      "det: 0.07227067\n",
      "Validation loss mlp/pin: 0.612401/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.541748\n",
      "det: 0.02202496\n",
      "Validation loss mlp/pin: 0.491225/1.023075\n",
      "###### N,i = 5,1 #####\n",
      "M: 82.87802\n",
      "det: 7.175435e-05\n",
      "Validation loss mlp/pin: 1.463990/1.501628\n",
      "\n",
      "Epoch 782/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577013/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479141/0.981279\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492481/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178179\n",
      "det: 0.07227087\n",
      "Validation loss mlp/pin: 0.612398/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.700686\n",
      "det: 0.022024862\n",
      "Validation loss mlp/pin: 0.491223/1.023073\n",
      "###### N,i = 5,1 #####\n",
      "M: 123.11586\n",
      "det: 7.174542e-05\n",
      "Validation loss mlp/pin: 1.463989/1.501628\n",
      "\n",
      "Epoch 783/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577010/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479139/0.981277\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492481/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781807\n",
      "det: 0.07227107\n",
      "Validation loss mlp/pin: 0.612395/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 5.28536\n",
      "det: 0.022024782\n",
      "Validation loss mlp/pin: 0.491221/1.023071\n",
      "###### N,i = 5,1 #####\n",
      "M: 123.10025\n",
      "det: 7.176414e-05\n",
      "Validation loss mlp/pin: 1.463989/1.501629\n",
      "\n",
      "Epoch 784/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577007/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479137/0.981276\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492480/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178182\n",
      "det: 0.07227129\n",
      "Validation loss mlp/pin: 0.612392/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.196873\n",
      "det: 0.022024713\n",
      "Validation loss mlp/pin: 0.491219/1.023070\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.15859\n",
      "det: 7.1759525e-05\n",
      "Validation loss mlp/pin: 1.463989/1.501628\n",
      "\n",
      "Epoch 785/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577004/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479135/0.981274\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492480/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178184\n",
      "det: 0.07227148\n",
      "Validation loss mlp/pin: 0.612390/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.967283\n",
      "det: 0.02202461\n",
      "Validation loss mlp/pin: 0.491217/1.023068\n",
      "###### N,i = 5,1 #####\n",
      "M: 133.70363\n",
      "det: 7.1758215e-05\n",
      "Validation loss mlp/pin: 1.463989/1.501628\n",
      "\n",
      "Epoch 786/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.577002/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479134/0.981273\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492480/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178186\n",
      "det: 0.07227166\n",
      "Validation loss mlp/pin: 0.612387/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.006855\n",
      "det: 0.022024533\n",
      "Validation loss mlp/pin: 0.491215/1.023067\n",
      "###### N,i = 5,1 #####\n",
      "M: 137.74582\n",
      "det: 7.1752525e-05\n",
      "Validation loss mlp/pin: 1.463989/1.501628\n",
      "\n",
      "Epoch 787/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576999/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479132/0.981271\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492480/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178188\n",
      "det: 0.07227187\n",
      "Validation loss mlp/pin: 0.612384/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.165033\n",
      "det: 0.022024436\n",
      "Validation loss mlp/pin: 0.491213/1.023065\n",
      "###### N,i = 5,1 #####\n",
      "M: 63.302567\n",
      "det: 7.177294e-05\n",
      "Validation loss mlp/pin: 1.463989/1.501628\n",
      "\n",
      "Epoch 788/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576997/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479130/0.981270\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492480/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781893\n",
      "det: 0.07227203\n",
      "Validation loss mlp/pin: 0.612382/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.469442\n",
      "det: 0.022024358\n",
      "Validation loss mlp/pin: 0.491211/1.023064\n",
      "###### N,i = 5,1 #####\n",
      "M: 56.28989\n",
      "det: 7.176849e-05\n",
      "Validation loss mlp/pin: 1.463989/1.501628\n",
      "\n",
      "Epoch 789/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576994/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479128/0.981269\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492480/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178191\n",
      "det: 0.072272226\n",
      "Validation loss mlp/pin: 0.612379/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.943598\n",
      "det: 0.022024276\n",
      "Validation loss mlp/pin: 0.491210/1.023062\n",
      "###### N,i = 5,1 #####\n",
      "M: 83.835045\n",
      "det: 7.1770286e-05\n",
      "Validation loss mlp/pin: 1.463989/1.501628\n",
      "\n",
      "Epoch 790/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576991/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479127/0.981267\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492480/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781926\n",
      "det: 0.07227242\n",
      "Validation loss mlp/pin: 0.612376/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.383667\n",
      "det: 0.02202417\n",
      "Validation loss mlp/pin: 0.491208/1.023061\n",
      "###### N,i = 5,1 #####\n",
      "M: 71.898346\n",
      "det: 7.177523e-05\n",
      "Validation loss mlp/pin: 1.463988/1.501628\n",
      "\n",
      "Epoch 791/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576989/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479125/0.981266\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492479/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1781945\n",
      "det: 0.0722726\n",
      "Validation loss mlp/pin: 0.612374/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.187943\n",
      "det: 0.022024076\n",
      "Validation loss mlp/pin: 0.491206/1.023059\n",
      "###### N,i = 5,1 #####\n",
      "M: 159.27075\n",
      "det: 7.17745e-05\n",
      "Validation loss mlp/pin: 1.463988/1.501628\n",
      "\n",
      "Epoch 792/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576986/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479123/0.981265\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492479/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178196\n",
      "det: 0.072272815\n",
      "Validation loss mlp/pin: 0.612371/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.2391205\n",
      "det: 0.022023983\n",
      "Validation loss mlp/pin: 0.491204/1.023058\n",
      "###### N,i = 5,1 #####\n",
      "M: 102.82521\n",
      "det: 7.1770715e-05\n",
      "Validation loss mlp/pin: 1.463988/1.501628\n",
      "\n",
      "Epoch 793/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576984/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479121/0.981263\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492479/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178198\n",
      "det: 0.07227301\n",
      "Validation loss mlp/pin: 0.612369/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.540713\n",
      "det: 0.022023916\n",
      "Validation loss mlp/pin: 0.491202/1.023056\n",
      "###### N,i = 5,1 #####\n",
      "M: 172.2406\n",
      "det: 7.177126e-05\n",
      "Validation loss mlp/pin: 1.463988/1.501628\n",
      "\n",
      "Epoch 794/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576982/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479120/0.981262\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492479/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782\n",
      "det: 0.07227321\n",
      "Validation loss mlp/pin: 0.612366/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 18.763153\n",
      "det: 0.022023827\n",
      "Validation loss mlp/pin: 0.491201/1.023055\n",
      "###### N,i = 5,1 #####\n",
      "M: 122.4118\n",
      "det: 7.17862e-05\n",
      "Validation loss mlp/pin: 1.463988/1.501628\n",
      "\n",
      "Epoch 795/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576979/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479118/0.981261\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492479/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178201\n",
      "det: 0.072273366\n",
      "Validation loss mlp/pin: 0.612364/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 18.763206\n",
      "det: 0.022023734\n",
      "Validation loss mlp/pin: 0.491199/1.023054\n",
      "###### N,i = 5,1 #####\n",
      "M: 121.4745\n",
      "det: 7.177879e-05\n",
      "Validation loss mlp/pin: 1.463988/1.501628\n",
      "\n",
      "Epoch 796/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576977/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479116/0.981260\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492478/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782026\n",
      "det: 0.072273545\n",
      "Validation loss mlp/pin: 0.612361/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.3086605\n",
      "det: 0.022023676\n",
      "Validation loss mlp/pin: 0.491197/1.023052\n",
      "###### N,i = 5,1 #####\n",
      "M: 95.92339\n",
      "det: 7.1787326e-05\n",
      "Validation loss mlp/pin: 1.463988/1.501628\n",
      "\n",
      "Epoch 797/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576975/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479115/0.981258\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492479/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782045\n",
      "det: 0.07227375\n",
      "Validation loss mlp/pin: 0.612359/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.17638\n",
      "det: 0.02202355\n",
      "Validation loss mlp/pin: 0.491196/1.023051\n",
      "###### N,i = 5,1 #####\n",
      "M: 192.46585\n",
      "det: 7.178537e-05\n",
      "Validation loss mlp/pin: 1.463987/1.501628\n",
      "\n",
      "Epoch 798/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576972/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479113/0.981257\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492478/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782064\n",
      "det: 0.07227394\n",
      "Validation loss mlp/pin: 0.612357/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.176393\n",
      "det: 0.022023477\n",
      "Validation loss mlp/pin: 0.491194/1.023049\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.81133\n",
      "det: 7.179223e-05\n",
      "Validation loss mlp/pin: 1.463987/1.501628\n",
      "\n",
      "Epoch 799/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576970/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479112/0.981256\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492478/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178208\n",
      "det: 0.0722741\n",
      "Validation loss mlp/pin: 0.612354/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.176404\n",
      "det: 0.022023426\n",
      "Validation loss mlp/pin: 0.491192/1.023048\n",
      "###### N,i = 5,1 #####\n",
      "M: 105.97996\n",
      "det: 7.178523e-05\n",
      "Validation loss mlp/pin: 1.463987/1.501628\n",
      "\n",
      "Epoch 800/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576968/2.588986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479110/0.981254\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492478/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782093\n",
      "det: 0.07227429\n",
      "Validation loss mlp/pin: 0.612352/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.9169755\n",
      "det: 0.0220233\n",
      "Validation loss mlp/pin: 0.491191/1.023047\n",
      "###### N,i = 5,1 #####\n",
      "M: 110.49589\n",
      "det: 7.178958e-05\n",
      "Validation loss mlp/pin: 1.463987/1.501628\n",
      "\n",
      "Epoch 801/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576966/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479108/0.981253\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492478/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178211\n",
      "det: 0.07227444\n",
      "Validation loss mlp/pin: 0.612350/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.151552\n",
      "det: 0.02202323\n",
      "Validation loss mlp/pin: 0.491189/1.023046\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.273834\n",
      "det: 7.179088e-05\n",
      "Validation loss mlp/pin: 1.463987/1.501628\n",
      "\n",
      "Epoch 802/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576964/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479107/0.981252\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492478/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782126\n",
      "det: 0.0722746\n",
      "Validation loss mlp/pin: 0.612348/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.963878\n",
      "det: 0.022023149\n",
      "Validation loss mlp/pin: 0.491188/1.023044\n",
      "###### N,i = 5,1 #####\n",
      "M: 193.14438\n",
      "det: 7.1801325e-05\n",
      "Validation loss mlp/pin: 1.463987/1.501628\n",
      "\n",
      "Epoch 803/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576961/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479105/0.981251\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492478/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178214\n",
      "det: 0.072274804\n",
      "Validation loss mlp/pin: 0.612345/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.4293566\n",
      "det: 0.02202307\n",
      "Validation loss mlp/pin: 0.491186/1.023043\n",
      "###### N,i = 5,1 #####\n",
      "M: 118.06005\n",
      "det: 7.180007e-05\n",
      "Validation loss mlp/pin: 1.463987/1.501628\n",
      "\n",
      "Epoch 804/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576959/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479104/0.981249\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492477/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782155\n",
      "det: 0.07227496\n",
      "Validation loss mlp/pin: 0.612343/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.652933\n",
      "det: 0.022022987\n",
      "Validation loss mlp/pin: 0.491184/1.023041\n",
      "###### N,i = 5,1 #####\n",
      "M: 165.13602\n",
      "det: 7.1795876e-05\n",
      "Validation loss mlp/pin: 1.463987/1.501628\n",
      "\n",
      "Epoch 805/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576957/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479102/0.981248\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492477/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178217\n",
      "det: 0.072275124\n",
      "Validation loss mlp/pin: 0.612341/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.652962\n",
      "det: 0.022022892\n",
      "Validation loss mlp/pin: 0.491183/1.023040\n",
      "###### N,i = 5,1 #####\n",
      "M: 198.189\n",
      "det: 7.1806375e-05\n",
      "Validation loss mlp/pin: 1.463987/1.501628\n",
      "\n",
      "Epoch 806/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576955/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479101/0.981247\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492477/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178219\n",
      "det: 0.07227528\n",
      "Validation loss mlp/pin: 0.612339/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.652983\n",
      "det: 0.022022817\n",
      "Validation loss mlp/pin: 0.491181/1.023039\n",
      "###### N,i = 5,1 #####\n",
      "M: 174.6947\n",
      "det: 7.180684e-05\n",
      "Validation loss mlp/pin: 1.463986/1.501628\n",
      "\n",
      "Epoch 807/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576953/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479099/0.981246\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492477/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782203\n",
      "det: 0.07227543\n",
      "Validation loss mlp/pin: 0.612336/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.6215515\n",
      "det: 0.022022735\n",
      "Validation loss mlp/pin: 0.491180/1.023038\n",
      "###### N,i = 5,1 #####\n",
      "M: 73.09418\n",
      "det: 7.179602e-05\n",
      "Validation loss mlp/pin: 1.463987/1.501628\n",
      "\n",
      "Epoch 808/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576951/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479098/0.981245\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492477/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178221\n",
      "det: 0.072275564\n",
      "Validation loss mlp/pin: 0.612334/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.466037\n",
      "det: 0.022022655\n",
      "Validation loss mlp/pin: 0.491178/1.023037\n",
      "###### N,i = 5,1 #####\n",
      "M: 177.51648\n",
      "det: 7.1810835e-05\n",
      "Validation loss mlp/pin: 1.463986/1.501628\n",
      "\n",
      "Epoch 809/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576949/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479096/0.981244\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492477/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178223\n",
      "det: 0.07227571\n",
      "Validation loss mlp/pin: 0.612332/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.466042\n",
      "det: 0.022022594\n",
      "Validation loss mlp/pin: 0.491177/1.023036\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.95556\n",
      "det: 7.181023e-05\n",
      "Validation loss mlp/pin: 1.463986/1.501628\n",
      "\n",
      "Epoch 810/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576947/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479095/0.981242\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492477/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782246\n",
      "det: 0.07227586\n",
      "Validation loss mlp/pin: 0.612330/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.989709\n",
      "det: 0.022022495\n",
      "Validation loss mlp/pin: 0.491175/1.023034\n",
      "###### N,i = 5,1 #####\n",
      "M: 122.67268\n",
      "det: 7.180024e-05\n",
      "Validation loss mlp/pin: 1.463986/1.501628\n",
      "\n",
      "Epoch 811/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576945/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479093/0.981241\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492476/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178226\n",
      "det: 0.07227602\n",
      "Validation loss mlp/pin: 0.612328/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.748808\n",
      "det: 0.022022404\n",
      "Validation loss mlp/pin: 0.491174/1.023033\n",
      "###### N,i = 5,1 #####\n",
      "M: 77.15897\n",
      "det: 7.180914e-05\n",
      "Validation loss mlp/pin: 1.463986/1.501628\n",
      "\n",
      "Epoch 812/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576943/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479092/0.981240\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492476/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178227\n",
      "det: 0.072276175\n",
      "Validation loss mlp/pin: 0.612326/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.607111\n",
      "det: 0.022022335\n",
      "Validation loss mlp/pin: 0.491172/1.023032\n",
      "###### N,i = 5,1 #####\n",
      "M: 87.488075\n",
      "det: 7.1818555e-05\n",
      "Validation loss mlp/pin: 1.463986/1.501628\n",
      "\n",
      "Epoch 813/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576941/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479091/0.981239\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492476/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782284\n",
      "det: 0.07227634\n",
      "Validation loss mlp/pin: 0.612324/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.607147\n",
      "det: 0.02202225\n",
      "Validation loss mlp/pin: 0.491171/1.023031\n",
      "###### N,i = 5,1 #####\n",
      "M: 148.78668\n",
      "det: 7.181743e-05\n",
      "Validation loss mlp/pin: 1.463986/1.501628\n",
      "\n",
      "Epoch 814/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576939/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479089/0.981238\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492476/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782303\n",
      "det: 0.07227649\n",
      "Validation loss mlp/pin: 0.612322/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.6454735\n",
      "det: 0.022022171\n",
      "Validation loss mlp/pin: 0.491169/1.023029\n",
      "###### N,i = 5,1 #####\n",
      "M: 94.193085\n",
      "det: 7.182571e-05\n",
      "Validation loss mlp/pin: 1.463986/1.501628\n",
      "\n",
      "Epoch 815/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576937/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479088/0.981237\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492476/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782312\n",
      "det: 0.07227663\n",
      "Validation loss mlp/pin: 0.612321/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.19551\n",
      "det: 0.022022072\n",
      "Validation loss mlp/pin: 0.491168/1.023028\n",
      "###### N,i = 5,1 #####\n",
      "M: 147.57594\n",
      "det: 7.1815106e-05\n",
      "Validation loss mlp/pin: 1.463986/1.501628\n",
      "\n",
      "Epoch 816/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576935/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479086/0.981236\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492476/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178233\n",
      "det: 0.072276786\n",
      "Validation loss mlp/pin: 0.612319/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.854339\n",
      "det: 0.022022001\n",
      "Validation loss mlp/pin: 0.491167/1.023027\n",
      "###### N,i = 5,1 #####\n",
      "M: 84.14271\n",
      "det: 7.1817296e-05\n",
      "Validation loss mlp/pin: 1.463986/1.501628\n",
      "\n",
      "Epoch 817/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576934/2.588986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479085/0.981235\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492476/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178234\n",
      "det: 0.07227694\n",
      "Validation loss mlp/pin: 0.612317/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.854361\n",
      "det: 0.02202192\n",
      "Validation loss mlp/pin: 0.491165/1.023026\n",
      "###### N,i = 5,1 #####\n",
      "M: 142.74388\n",
      "det: 7.182196e-05\n",
      "Validation loss mlp/pin: 1.463985/1.501628\n",
      "\n",
      "Epoch 818/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576932/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479084/0.981234\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492476/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782355\n",
      "det: 0.07227708\n",
      "Validation loss mlp/pin: 0.612315/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.854384\n",
      "det: 0.022021832\n",
      "Validation loss mlp/pin: 0.491164/1.023025\n",
      "###### N,i = 5,1 #####\n",
      "M: 142.7492\n",
      "det: 7.181684e-05\n",
      "Validation loss mlp/pin: 1.463985/1.501628\n",
      "\n",
      "Epoch 819/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576930/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479082/0.981233\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492475/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178237\n",
      "det: 0.07227724\n",
      "Validation loss mlp/pin: 0.612313/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.854404\n",
      "det: 0.022021767\n",
      "Validation loss mlp/pin: 0.491163/1.023024\n",
      "###### N,i = 5,1 #####\n",
      "M: 83.71121\n",
      "det: 7.1822855e-05\n",
      "Validation loss mlp/pin: 1.463985/1.501628\n",
      "\n",
      "Epoch 820/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576928/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479081/0.981232\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492475/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782384\n",
      "det: 0.07227739\n",
      "Validation loss mlp/pin: 0.612312/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.561733\n",
      "det: 0.022021683\n",
      "Validation loss mlp/pin: 0.491161/1.023023\n",
      "###### N,i = 5,1 #####\n",
      "M: 69.77804\n",
      "det: 7.1838745e-05\n",
      "Validation loss mlp/pin: 1.463985/1.501628\n",
      "\n",
      "Epoch 821/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576927/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479080/0.981231\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492475/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782393\n",
      "det: 0.07227753\n",
      "Validation loss mlp/pin: 0.612310/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.266621\n",
      "det: 0.022021605\n",
      "Validation loss mlp/pin: 0.491160/1.023022\n",
      "###### N,i = 5,1 #####\n",
      "M: 119.31172\n",
      "det: 7.1826136e-05\n",
      "Validation loss mlp/pin: 1.463985/1.501628\n",
      "\n",
      "Epoch 822/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576925/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479079/0.981230\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492475/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17824\n",
      "det: 0.07227767\n",
      "Validation loss mlp/pin: 0.612308/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.735264\n",
      "det: 0.022021517\n",
      "Validation loss mlp/pin: 0.491158/1.023021\n",
      "###### N,i = 5,1 #####\n",
      "M: 119.30884\n",
      "det: 7.1829934e-05\n",
      "Validation loss mlp/pin: 1.463985/1.501628\n",
      "\n",
      "Epoch 823/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576923/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479077/0.981229\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492475/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782417\n",
      "det: 0.072277814\n",
      "Validation loss mlp/pin: 0.612306/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.735277\n",
      "det: 0.02202146\n",
      "Validation loss mlp/pin: 0.491157/1.023020\n",
      "###### N,i = 5,1 #####\n",
      "M: 111.22364\n",
      "det: 7.1837865e-05\n",
      "Validation loss mlp/pin: 1.463985/1.501628\n",
      "\n",
      "Epoch 824/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576922/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479076/0.981228\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492475/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782427\n",
      "det: 0.072277956\n",
      "Validation loss mlp/pin: 0.612305/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.116322\n",
      "det: 0.022021381\n",
      "Validation loss mlp/pin: 0.491156/1.023019\n",
      "###### N,i = 5,1 #####\n",
      "M: 153.14111\n",
      "det: 7.1838695e-05\n",
      "Validation loss mlp/pin: 1.463985/1.501628\n",
      "\n",
      "Epoch 825/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576920/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479075/0.981227\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492475/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178244\n",
      "det: 0.07227809\n",
      "Validation loss mlp/pin: 0.612303/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.967641\n",
      "det: 0.022021327\n",
      "Validation loss mlp/pin: 0.491155/1.023018\n",
      "###### N,i = 5,1 #####\n",
      "M: 140.25955\n",
      "det: 7.1835464e-05\n",
      "Validation loss mlp/pin: 1.463985/1.501628\n",
      "\n",
      "Epoch 826/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576918/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479074/0.981226\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492475/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782455\n",
      "det: 0.07227822\n",
      "Validation loss mlp/pin: 0.612301/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.490835\n",
      "det: 0.022021249\n",
      "Validation loss mlp/pin: 0.491153/1.023017\n",
      "###### N,i = 5,1 #####\n",
      "M: 89.2249\n",
      "det: 7.182892e-05\n",
      "Validation loss mlp/pin: 1.463985/1.501628\n",
      "\n",
      "Epoch 827/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576917/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479073/0.981226\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492474/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782465\n",
      "det: 0.07227835\n",
      "Validation loss mlp/pin: 0.612300/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.884732\n",
      "det: 0.022021174\n",
      "Validation loss mlp/pin: 0.491152/1.023016\n",
      "###### N,i = 5,1 #####\n",
      "M: 105.30565\n",
      "det: 7.183751e-05\n",
      "Validation loss mlp/pin: 1.463984/1.501628\n",
      "\n",
      "Epoch 828/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576915/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479071/0.981225\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492474/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782475\n",
      "det: 0.0722785\n",
      "Validation loss mlp/pin: 0.612298/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.221928\n",
      "det: 0.0220211\n",
      "Validation loss mlp/pin: 0.491151/1.023015\n",
      "###### N,i = 5,1 #####\n",
      "M: 135.57489\n",
      "det: 7.18509e-05\n",
      "Validation loss mlp/pin: 1.463984/1.501628\n",
      "\n",
      "Epoch 829/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576914/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479070/0.981224\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492474/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178249\n",
      "det: 0.07227862\n",
      "Validation loss mlp/pin: 0.612296/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.88476\n",
      "det: 0.02202105\n",
      "Validation loss mlp/pin: 0.491150/1.023014\n",
      "###### N,i = 5,1 #####\n",
      "M: 145.80069\n",
      "det: 7.184388e-05\n",
      "Validation loss mlp/pin: 1.463984/1.501628\n",
      "\n",
      "Epoch 830/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576912/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479069/0.981223\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492474/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782503\n",
      "det: 0.07227874\n",
      "Validation loss mlp/pin: 0.612295/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.221981\n",
      "det: 0.022020962\n",
      "Validation loss mlp/pin: 0.491148/1.023013\n",
      "###### N,i = 5,1 #####\n",
      "M: 68.83671\n",
      "det: 7.18406e-05\n",
      "Validation loss mlp/pin: 1.463984/1.501628\n",
      "\n",
      "Epoch 831/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576911/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479068/0.981222\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492474/1.534730\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782513\n",
      "det: 0.07227885\n",
      "Validation loss mlp/pin: 0.612293/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.0768623\n",
      "det: 0.022020878\n",
      "Validation loss mlp/pin: 0.491147/1.023012\n",
      "###### N,i = 5,1 #####\n",
      "M: 135.74808\n",
      "det: 7.184733e-05\n",
      "Validation loss mlp/pin: 1.463984/1.501628\n",
      "\n",
      "Epoch 832/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576909/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479067/0.981221\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492474/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782527\n",
      "det: 0.07227899\n",
      "Validation loss mlp/pin: 0.612292/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.076873\n",
      "det: 0.022020824\n",
      "Validation loss mlp/pin: 0.491146/1.023011\n",
      "###### N,i = 5,1 #####\n",
      "M: 85.61015\n",
      "det: 7.1837596e-05\n",
      "Validation loss mlp/pin: 1.463984/1.501628\n",
      "\n",
      "Epoch 833/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576907/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479065/0.981220\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492474/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782537\n",
      "det: 0.07227912\n",
      "Validation loss mlp/pin: 0.612290/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.40983\n",
      "det: 0.022020763\n",
      "Validation loss mlp/pin: 0.491145/1.023010\n",
      "###### N,i = 5,1 #####\n",
      "M: 87.88052\n",
      "det: 7.1847215e-05\n",
      "Validation loss mlp/pin: 1.463984/1.501628\n",
      "\n",
      "Epoch 834/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576906/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479064/0.981219\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492474/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782546\n",
      "det: 0.072279245\n",
      "Validation loss mlp/pin: 0.612288/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.41062\n",
      "det: 0.022020716\n",
      "Validation loss mlp/pin: 0.491144/1.023009\n",
      "###### N,i = 5,1 #####\n",
      "M: 79.32644\n",
      "det: 7.184894e-05\n",
      "Validation loss mlp/pin: 1.463984/1.501628\n",
      "\n",
      "Epoch 835/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576904/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479063/0.981219\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492473/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782556\n",
      "det: 0.07227938\n",
      "Validation loss mlp/pin: 0.612287/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.410639\n",
      "det: 0.02202063\n",
      "Validation loss mlp/pin: 0.491143/1.023009\n",
      "###### N,i = 5,1 #####\n",
      "M: 164.09752\n",
      "det: 7.183738e-05\n",
      "Validation loss mlp/pin: 1.463984/1.501628\n",
      "\n",
      "Epoch 836/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576903/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479062/0.981218\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492473/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782565\n",
      "det: 0.072279505\n",
      "Validation loss mlp/pin: 0.612285/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.958816\n",
      "det: 0.022020567\n",
      "Validation loss mlp/pin: 0.491141/1.023008\n",
      "###### N,i = 5,1 #####\n",
      "M: 75.859955\n",
      "det: 7.184199e-05\n",
      "Validation loss mlp/pin: 1.463984/1.501628\n",
      "\n",
      "Epoch 837/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576901/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479061/0.981217\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492473/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782575\n",
      "det: 0.07227961\n",
      "Validation loss mlp/pin: 0.612283/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.9588175\n",
      "det: 0.022020504\n",
      "Validation loss mlp/pin: 0.491140/1.023007\n",
      "###### N,i = 5,1 #####\n",
      "M: 224.7052\n",
      "det: 7.184482e-05\n",
      "Validation loss mlp/pin: 1.463983/1.501628\n",
      "\n",
      "Epoch 838/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576900/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479060/0.981216\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492473/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178259\n",
      "det: 0.07227972\n",
      "Validation loss mlp/pin: 0.612282/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.410694\n",
      "det: 0.022020461\n",
      "Validation loss mlp/pin: 0.491139/1.023006\n",
      "###### N,i = 5,1 #####\n",
      "M: 178.90857\n",
      "det: 7.185114e-05\n",
      "Validation loss mlp/pin: 1.463983/1.501628\n",
      "\n",
      "Epoch 839/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576898/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479059/0.981215\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492473/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17826\n",
      "det: 0.07227985\n",
      "Validation loss mlp/pin: 0.612280/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.410713\n",
      "det: 0.022020385\n",
      "Validation loss mlp/pin: 0.491138/1.023005\n",
      "###### N,i = 5,1 #####\n",
      "M: 237.61195\n",
      "det: 7.184733e-05\n",
      "Validation loss mlp/pin: 1.463983/1.501628\n",
      "\n",
      "Epoch 840/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576897/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479058/0.981214\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492473/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178261\n",
      "det: 0.07227995\n",
      "Validation loss mlp/pin: 0.612279/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.410734\n",
      "det: 0.022020306\n",
      "Validation loss mlp/pin: 0.491137/1.023003\n",
      "###### N,i = 5,1 #####\n",
      "M: 66.77413\n",
      "det: 7.1865885e-05\n",
      "Validation loss mlp/pin: 1.463983/1.501628\n",
      "\n",
      "Epoch 841/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576895/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479057/0.981213\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492473/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178262\n",
      "det: 0.07228008\n",
      "Validation loss mlp/pin: 0.612277/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.41075\n",
      "det: 0.02202025\n",
      "Validation loss mlp/pin: 0.491136/1.023003\n",
      "###### N,i = 5,1 #####\n",
      "M: 126.65416\n",
      "det: 7.186608e-05\n",
      "Validation loss mlp/pin: 1.463983/1.501628\n",
      "\n",
      "Epoch 842/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576893/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479056/0.981212\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492473/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178263\n",
      "det: 0.07228019\n",
      "Validation loss mlp/pin: 0.612276/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.410767\n",
      "det: 0.022020204\n",
      "Validation loss mlp/pin: 0.491135/1.023002\n",
      "###### N,i = 5,1 #####\n",
      "M: 145.53477\n",
      "det: 7.185953e-05\n",
      "Validation loss mlp/pin: 1.463983/1.501628\n",
      "\n",
      "Epoch 843/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576892/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479055/0.981211\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492473/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782646\n",
      "det: 0.0722803\n",
      "Validation loss mlp/pin: 0.612274/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.958829\n",
      "det: 0.022020152\n",
      "Validation loss mlp/pin: 0.491134/1.023001\n",
      "###### N,i = 5,1 #####\n",
      "M: 85.48337\n",
      "det: 7.1855626e-05\n",
      "Validation loss mlp/pin: 1.463983/1.501628\n",
      "\n",
      "Epoch 844/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576891/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479054/0.981210\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492472/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178265\n",
      "det: 0.0722804\n",
      "Validation loss mlp/pin: 0.612273/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.958832\n",
      "det: 0.022020057\n",
      "Validation loss mlp/pin: 0.491133/1.023000\n",
      "###### N,i = 5,1 #####\n",
      "M: 61.070248\n",
      "det: 7.18623e-05\n",
      "Validation loss mlp/pin: 1.463983/1.501628\n",
      "\n",
      "Epoch 845/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576889/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479053/0.981210\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492472/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178266\n",
      "det: 0.07228049\n",
      "Validation loss mlp/pin: 0.612271/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.9588327\n",
      "det: 0.022020018\n",
      "Validation loss mlp/pin: 0.491132/1.022999\n",
      "###### N,i = 5,1 #####\n",
      "M: 146.45912\n",
      "det: 7.186646e-05\n",
      "Validation loss mlp/pin: 1.463983/1.501628\n",
      "\n",
      "Epoch 846/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576887/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479052/0.981209\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492472/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178267\n",
      "det: 0.072280586\n",
      "Validation loss mlp/pin: 0.612269/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.44866\n",
      "det: 0.022019977\n",
      "Validation loss mlp/pin: 0.491131/1.022998\n",
      "###### N,i = 5,1 #####\n",
      "M: 79.317825\n",
      "det: 7.1853705e-05\n",
      "Validation loss mlp/pin: 1.463983/1.501628\n",
      "\n",
      "Epoch 847/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576886/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479051/0.981208\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492472/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178268\n",
      "det: 0.072280705\n",
      "Validation loss mlp/pin: 0.612268/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 19.785975\n",
      "det: 0.022019906\n",
      "Validation loss mlp/pin: 0.491130/1.022997\n",
      "###### N,i = 5,1 #####\n",
      "M: 184.71313\n",
      "det: 7.187223e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 848/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576885/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479050/0.981207\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492472/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782694\n",
      "det: 0.07228081\n",
      "Validation loss mlp/pin: 0.612266/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.448397\n",
      "det: 0.022019856\n",
      "Validation loss mlp/pin: 0.491129/1.022996\n",
      "###### N,i = 5,1 #####\n",
      "M: 184.73491\n",
      "det: 7.185535e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 849/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576883/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479049/0.981206\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492472/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782703\n",
      "det: 0.07228091\n",
      "Validation loss mlp/pin: 0.612265/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 19.803402\n",
      "det: 0.022019811\n",
      "Validation loss mlp/pin: 0.491128/1.022995\n",
      "###### N,i = 5,1 #####\n",
      "M: 98.383224\n",
      "det: 7.1869945e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 850/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576882/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479048/0.981205\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492472/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782713\n",
      "det: 0.072281025\n",
      "Validation loss mlp/pin: 0.612264/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 19.786068\n",
      "det: 0.022019748\n",
      "Validation loss mlp/pin: 0.491127/1.022994\n",
      "###### N,i = 5,1 #####\n",
      "M: 109.24982\n",
      "det: 7.186407e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 851/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576880/2.588986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479047/0.981204\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492472/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782722\n",
      "det: 0.07228108\n",
      "Validation loss mlp/pin: 0.612262/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.448414\n",
      "det: 0.02201969\n",
      "Validation loss mlp/pin: 0.491126/1.022993\n",
      "###### N,i = 5,1 #####\n",
      "M: 82.46686\n",
      "det: 7.186672e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 852/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576879/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479046/0.981203\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492472/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178273\n",
      "det: 0.0722812\n",
      "Validation loss mlp/pin: 0.612260/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 20.122139\n",
      "det: 0.022019664\n",
      "Validation loss mlp/pin: 0.491125/1.022992\n",
      "###### N,i = 5,1 #####\n",
      "M: 78.64507\n",
      "det: 7.18681e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 853/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576877/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479045/0.981203\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492472/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782746\n",
      "det: 0.07228129\n",
      "Validation loss mlp/pin: 0.612259/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 20.12217\n",
      "det: 0.022019621\n",
      "Validation loss mlp/pin: 0.491124/1.022991\n",
      "###### N,i = 5,1 #####\n",
      "M: 104.7012\n",
      "det: 7.186783e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 854/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576876/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479044/0.981202\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492472/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782756\n",
      "det: 0.07228137\n",
      "Validation loss mlp/pin: 0.612257/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 20.1222\n",
      "det: 0.022019546\n",
      "Validation loss mlp/pin: 0.491123/1.022990\n",
      "###### N,i = 5,1 #####\n",
      "M: 98.61383\n",
      "det: 7.187476e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 855/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576875/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479043/0.981201\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492472/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782765\n",
      "det: 0.07228146\n",
      "Validation loss mlp/pin: 0.612256/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.836111\n",
      "det: 0.022019515\n",
      "Validation loss mlp/pin: 0.491122/1.022990\n",
      "###### N,i = 5,1 #####\n",
      "M: 100.566025\n",
      "det: 7.188015e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 856/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576873/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479042/0.981200\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492471/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178277\n",
      "det: 0.072281554\n",
      "Validation loss mlp/pin: 0.612255/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.836124\n",
      "det: 0.022019481\n",
      "Validation loss mlp/pin: 0.491121/1.022989\n",
      "###### N,i = 5,1 #####\n",
      "M: 100.56494\n",
      "det: 7.188205e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 857/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576872/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479041/0.981199\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492472/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782784\n",
      "det: 0.072281644\n",
      "Validation loss mlp/pin: 0.612253/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.273827\n",
      "det: 0.022019416\n",
      "Validation loss mlp/pin: 0.491120/1.022988\n",
      "###### N,i = 5,1 #####\n",
      "M: 120.79074\n",
      "det: 7.187925e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 858/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576870/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479040/0.981199\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492471/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178279\n",
      "det: 0.072281726\n",
      "Validation loss mlp/pin: 0.612252/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.149379\n",
      "det: 0.022019383\n",
      "Validation loss mlp/pin: 0.491119/1.022987\n",
      "###### N,i = 5,1 #####\n",
      "M: 100.57356\n",
      "det: 7.187017e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 859/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576869/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479039/0.981198\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492471/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17828\n",
      "det: 0.072281815\n",
      "Validation loss mlp/pin: 0.612250/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.185753\n",
      "det: 0.02201936\n",
      "Validation loss mlp/pin: 0.491118/1.022986\n",
      "###### N,i = 5,1 #####\n",
      "M: 79.132454\n",
      "det: 7.187583e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 860/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576868/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479039/0.981197\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492471/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178281\n",
      "det: 0.07228187\n",
      "Validation loss mlp/pin: 0.612249/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 6.507275\n",
      "det: 0.02201932\n",
      "Validation loss mlp/pin: 0.491117/1.022985\n",
      "###### N,i = 5,1 #####\n",
      "M: 110.67796\n",
      "det: 7.187568e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 861/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576866/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479038/0.981196\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492471/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782813\n",
      "det: 0.072281934\n",
      "Validation loss mlp/pin: 0.612247/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.724209\n",
      "det: 0.022019288\n",
      "Validation loss mlp/pin: 0.491116/1.022984\n",
      "###### N,i = 5,1 #####\n",
      "M: 122.3338\n",
      "det: 7.187195e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 862/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576865/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479037/0.981195\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492471/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782827\n",
      "det: 0.07228205\n",
      "Validation loss mlp/pin: 0.612246/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.17881\n",
      "det: 0.022019222\n",
      "Validation loss mlp/pin: 0.491115/1.022983\n",
      "###### N,i = 5,1 #####\n",
      "M: 121.88362\n",
      "det: 7.1888695e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 863/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576863/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479036/0.981194\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492471/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782837\n",
      "det: 0.07228212\n",
      "Validation loss mlp/pin: 0.612245/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.703867\n",
      "det: 0.022019206\n",
      "Validation loss mlp/pin: 0.491115/1.022982\n",
      "###### N,i = 5,1 #####\n",
      "M: 73.58887\n",
      "det: 7.1876726e-05\n",
      "Validation loss mlp/pin: 1.463982/1.501628\n",
      "\n",
      "Epoch 864/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576862/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479035/0.981193\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492471/1.534729\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782846\n",
      "det: 0.07228219\n",
      "Validation loss mlp/pin: 0.612243/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.892189\n",
      "det: 0.022019178\n",
      "Validation loss mlp/pin: 0.491114/1.022981\n",
      "###### N,i = 5,1 #####\n",
      "M: 68.77814\n",
      "det: 7.187572e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 865/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576860/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479034/0.981193\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492471/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782856\n",
      "det: 0.072282284\n",
      "Validation loss mlp/pin: 0.612242/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.7038765\n",
      "det: 0.022019146\n",
      "Validation loss mlp/pin: 0.491113/1.022981\n",
      "###### N,i = 5,1 #####\n",
      "M: 92.73333\n",
      "det: 7.1884446e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 866/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576859/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479034/0.981192\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492471/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782866\n",
      "det: 0.07228236\n",
      "Validation loss mlp/pin: 0.612240/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.8922024\n",
      "det: 0.02201912\n",
      "Validation loss mlp/pin: 0.491112/1.022980\n",
      "###### N,i = 5,1 #####\n",
      "M: 105.284134\n",
      "det: 7.1878545e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 867/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576858/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479033/0.981191\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492471/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782866\n",
      "det: 0.072282426\n",
      "Validation loss mlp/pin: 0.612239/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.187588\n",
      "det: 0.022019101\n",
      "Validation loss mlp/pin: 0.491111/1.022979\n",
      "###### N,i = 5,1 #####\n",
      "M: 82.8921\n",
      "det: 7.1886054e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 868/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576856/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479032/0.981190\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492471/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178288\n",
      "det: 0.0722825\n",
      "Validation loss mlp/pin: 0.612237/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.8922133\n",
      "det: 0.022019062\n",
      "Validation loss mlp/pin: 0.491110/1.022978\n",
      "###### N,i = 5,1 #####\n",
      "M: 77.62409\n",
      "det: 7.18865e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 869/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576855/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479031/0.981190\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782885\n",
      "det: 0.07228257\n",
      "Validation loss mlp/pin: 0.612236/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.187602\n",
      "det: 0.02201905\n",
      "Validation loss mlp/pin: 0.491110/1.022977\n",
      "###### N,i = 5,1 #####\n",
      "M: 164.64545\n",
      "det: 7.188408e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 870/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576854/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479030/0.981189\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782894\n",
      "det: 0.07228263\n",
      "Validation loss mlp/pin: 0.612234/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 7.892225\n",
      "det: 0.022019027\n",
      "Validation loss mlp/pin: 0.491109/1.022976\n",
      "###### N,i = 5,1 #####\n",
      "M: 75.637955\n",
      "det: 7.189225e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 871/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576852/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479030/0.981188\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782904\n",
      "det: 0.07228271\n",
      "Validation loss mlp/pin: 0.612233/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.187558\n",
      "det: 0.022018995\n",
      "Validation loss mlp/pin: 0.491108/1.022976\n",
      "###### N,i = 5,1 #####\n",
      "M: 121.39976\n",
      "det: 7.189325e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 872/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576851/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479029/0.981187\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178291\n",
      "det: 0.072282754\n",
      "Validation loss mlp/pin: 0.612232/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.187559\n",
      "det: 0.02201897\n",
      "Validation loss mlp/pin: 0.491107/1.022975\n",
      "###### N,i = 5,1 #####\n",
      "M: 80.116684\n",
      "det: 7.189115e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 873/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576850/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479028/0.981187\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178292\n",
      "det: 0.072282836\n",
      "Validation loss mlp/pin: 0.612230/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.1875596\n",
      "det: 0.022018949\n",
      "Validation loss mlp/pin: 0.491106/1.022974\n",
      "###### N,i = 5,1 #####\n",
      "M: 87.7673\n",
      "det: 7.189124e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 874/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576848/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479027/0.981186\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178293\n",
      "det: 0.0722829\n",
      "Validation loss mlp/pin: 0.612229/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.575609\n",
      "det: 0.022018928\n",
      "Validation loss mlp/pin: 0.491106/1.022973\n",
      "###### N,i = 5,1 #####\n",
      "M: 80.118195\n",
      "det: 7.188892e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 875/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576847/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479027/0.981185\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178293\n",
      "det: 0.07228297\n",
      "Validation loss mlp/pin: 0.612227/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.575616\n",
      "det: 0.02201893\n",
      "Validation loss mlp/pin: 0.491105/1.022973\n",
      "###### N,i = 5,1 #####\n",
      "M: 100.109146\n",
      "det: 7.190333e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 876/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576846/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479026/0.981184\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178294\n",
      "det: 0.07228301\n",
      "Validation loss mlp/pin: 0.612226/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.636793\n",
      "det: 0.022018893\n",
      "Validation loss mlp/pin: 0.491104/1.022972\n",
      "###### N,i = 5,1 #####\n",
      "M: 67.49317\n",
      "det: 7.189528e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 877/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576844/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479025/0.981184\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178295\n",
      "det: 0.07228309\n",
      "Validation loss mlp/pin: 0.612225/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.704859\n",
      "det: 0.022018878\n",
      "Validation loss mlp/pin: 0.491103/1.022971\n",
      "###### N,i = 5,1 #####\n",
      "M: 117.34875\n",
      "det: 7.1886185e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 878/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576843/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479024/0.981183\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178296\n",
      "det: 0.07228314\n",
      "Validation loss mlp/pin: 0.612223/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.022025\n",
      "det: 0.022018846\n",
      "Validation loss mlp/pin: 0.491102/1.022970\n",
      "###### N,i = 5,1 #####\n",
      "M: 96.959656\n",
      "det: 7.190621e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 879/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576842/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479024/0.981182\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782966\n",
      "det: 0.07228319\n",
      "Validation loss mlp/pin: 0.612222/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.410592\n",
      "det: 0.022018826\n",
      "Validation loss mlp/pin: 0.491102/1.022970\n",
      "###### N,i = 5,1 #####\n",
      "M: 76.13387\n",
      "det: 7.190024e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 880/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576840/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479023/0.981182\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782975\n",
      "det: 0.07228328\n",
      "Validation loss mlp/pin: 0.612221/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.022044\n",
      "det: 0.022018807\n",
      "Validation loss mlp/pin: 0.491101/1.022969\n",
      "###### N,i = 5,1 #####\n",
      "M: 142.55927\n",
      "det: 7.188881e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 881/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576839/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479022/0.981181\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1782985\n",
      "det: 0.07228336\n",
      "Validation loss mlp/pin: 0.612219/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.4105926\n",
      "det: 0.022018816\n",
      "Validation loss mlp/pin: 0.491100/1.022968\n",
      "###### N,i = 5,1 #####\n",
      "M: 134.5798\n",
      "det: 7.189482e-05\n",
      "Validation loss mlp/pin: 1.463981/1.501628\n",
      "\n",
      "Epoch 882/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576837/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479022/0.981181\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178299\n",
      "det: 0.07228342\n",
      "Validation loss mlp/pin: 0.612218/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.410594\n",
      "det: 0.022018803\n",
      "Validation loss mlp/pin: 0.491100/1.022968\n",
      "###### N,i = 5,1 #####\n",
      "M: 88.733284\n",
      "det: 7.190799e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 883/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576836/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479021/0.981180\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783\n",
      "det: 0.07228347\n",
      "Validation loss mlp/pin: 0.612217/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.124886\n",
      "det: 0.022018796\n",
      "Validation loss mlp/pin: 0.491099/1.022967\n",
      "###### N,i = 5,1 #####\n",
      "M: 81.36891\n",
      "det: 7.19017e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 884/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576835/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479020/0.981179\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492470/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178301\n",
      "det: 0.07228353\n",
      "Validation loss mlp/pin: 0.612215/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.12489\n",
      "det: 0.022018775\n",
      "Validation loss mlp/pin: 0.491098/1.022966\n",
      "###### N,i = 5,1 #####\n",
      "M: 88.42389\n",
      "det: 7.190181e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 885/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576834/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479020/0.981179\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783013\n",
      "det: 0.07228362\n",
      "Validation loss mlp/pin: 0.612214/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.401429\n",
      "det: 0.022018751\n",
      "Validation loss mlp/pin: 0.491097/1.022966\n",
      "###### N,i = 5,1 #####\n",
      "M: 88.42738\n",
      "det: 7.189631e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 886/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576832/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479019/0.981178\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178302\n",
      "det: 0.072283655\n",
      "Validation loss mlp/pin: 0.612213/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.229877\n",
      "det: 0.022018736\n",
      "Validation loss mlp/pin: 0.491097/1.022965\n",
      "###### N,i = 5,1 #####\n",
      "M: 88.304924\n",
      "det: 7.190276e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 887/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576831/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479018/0.981177\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178303\n",
      "det: 0.07228371\n",
      "Validation loss mlp/pin: 0.612211/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.175247\n",
      "det: 0.022018716\n",
      "Validation loss mlp/pin: 0.491096/1.022964\n",
      "###### N,i = 5,1 #####\n",
      "M: 69.58218\n",
      "det: 7.191367e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 888/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576830/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479018/0.981177\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783037\n",
      "det: 0.07228377\n",
      "Validation loss mlp/pin: 0.612210/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.556017\n",
      "det: 0.022018721\n",
      "Validation loss mlp/pin: 0.491095/1.022964\n",
      "###### N,i = 5,1 #####\n",
      "M: 98.67595\n",
      "det: 7.190482e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 889/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576829/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479017/0.981176\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178304\n",
      "det: 0.07228382\n",
      "Validation loss mlp/pin: 0.612209/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 14.556023\n",
      "det: 0.02201871\n",
      "Validation loss mlp/pin: 0.491095/1.022963\n",
      "###### N,i = 5,1 #####\n",
      "M: 87.04609\n",
      "det: 7.190469e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 890/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576827/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479016/0.981175\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783047\n",
      "det: 0.07228385\n",
      "Validation loss mlp/pin: 0.612208/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.723482\n",
      "det: 0.02201868\n",
      "Validation loss mlp/pin: 0.491094/1.022962\n",
      "###### N,i = 5,1 #####\n",
      "M: 181.81506\n",
      "det: 7.1913826e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 891/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576826/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479015/0.981175\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178305\n",
      "det: 0.07228387\n",
      "Validation loss mlp/pin: 0.612206/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 19.49236\n",
      "det: 0.022018673\n",
      "Validation loss mlp/pin: 0.491093/1.022962\n",
      "###### N,i = 5,1 #####\n",
      "M: 166.73209\n",
      "det: 7.190491e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 892/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576825/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479015/0.981174\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783056\n",
      "det: 0.07228394\n",
      "Validation loss mlp/pin: 0.612205/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 15.398746\n",
      "det: 0.022018654\n",
      "Validation loss mlp/pin: 0.491092/1.022961\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.14494\n",
      "det: 7.191055e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 893/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576824/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479014/0.981174\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783066\n",
      "det: 0.07228398\n",
      "Validation loss mlp/pin: 0.612204/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.397725\n",
      "det: 0.022018652\n",
      "Validation loss mlp/pin: 0.491092/1.022961\n",
      "###### N,i = 5,1 #####\n",
      "M: 108.57043\n",
      "det: 7.1910996e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 894/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576823/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479014/0.981173\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783066\n",
      "det: 0.07228403\n",
      "Validation loss mlp/pin: 0.612203/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.397729\n",
      "det: 0.022018641\n",
      "Validation loss mlp/pin: 0.491091/1.022960\n",
      "###### N,i = 5,1 #####\n",
      "M: 150.44257\n",
      "det: 7.19011e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 895/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576822/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479013/0.981173\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783075\n",
      "det: 0.07228409\n",
      "Validation loss mlp/pin: 0.612202/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.397732\n",
      "det: 0.022018617\n",
      "Validation loss mlp/pin: 0.491091/1.022960\n",
      "###### N,i = 5,1 #####\n",
      "M: 83.89264\n",
      "det: 7.1907714e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 896/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576821/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479012/0.981173\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178309\n",
      "det: 0.07228414\n",
      "Validation loss mlp/pin: 0.612201/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.397735\n",
      "det: 0.022018598\n",
      "Validation loss mlp/pin: 0.491090/1.022959\n",
      "###### N,i = 5,1 #####\n",
      "M: 178.93567\n",
      "det: 7.191181e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 897/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576820/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479012/0.981172\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783094\n",
      "det: 0.07228419\n",
      "Validation loss mlp/pin: 0.612200/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.863054\n",
      "det: 0.022018591\n",
      "Validation loss mlp/pin: 0.491089/1.022959\n",
      "###### N,i = 5,1 #####\n",
      "M: 167.9892\n",
      "det: 7.1915405e-05\n",
      "Validation loss mlp/pin: 1.463980/1.501628\n",
      "\n",
      "Epoch 898/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576819/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479011/0.981172\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783104\n",
      "det: 0.07228424\n",
      "Validation loss mlp/pin: 0.612199/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.295273\n",
      "det: 0.022018583\n",
      "Validation loss mlp/pin: 0.491089/1.022958\n",
      "###### N,i = 5,1 #####\n",
      "M: 194.37213\n",
      "det: 7.1912524e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 899/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576818/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479011/0.981171\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783104\n",
      "det: 0.07228428\n",
      "Validation loss mlp/pin: 0.612198/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.295276\n",
      "det: 0.022018563\n",
      "Validation loss mlp/pin: 0.491088/1.022958\n",
      "###### N,i = 5,1 #####\n",
      "M: 143.2243\n",
      "det: 7.1915056e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 900/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576817/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479010/0.981171\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492469/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783113\n",
      "det: 0.07228432\n",
      "Validation loss mlp/pin: 0.612197/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.295278\n",
      "det: 0.022018548\n",
      "Validation loss mlp/pin: 0.491088/1.022957\n",
      "###### N,i = 5,1 #####\n",
      "M: 71.38519\n",
      "det: 7.1912116e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 901/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576816/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479009/0.981170\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783123\n",
      "det: 0.07228436\n",
      "Validation loss mlp/pin: 0.612196/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.863071\n",
      "det: 0.022018543\n",
      "Validation loss mlp/pin: 0.491087/1.022957\n",
      "###### N,i = 5,1 #####\n",
      "M: 123.6337\n",
      "det: 7.1908e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 902/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576815/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479009/0.981170\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178313\n",
      "det: 0.072284415\n",
      "Validation loss mlp/pin: 0.612195/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.863075\n",
      "det: 0.022018528\n",
      "Validation loss mlp/pin: 0.491086/1.022957\n",
      "###### N,i = 5,1 #####\n",
      "M: 123.87999\n",
      "det: 7.190954e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 903/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576814/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479008/0.981170\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783133\n",
      "det: 0.07228445\n",
      "Validation loss mlp/pin: 0.612194/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.397754\n",
      "det: 0.022018524\n",
      "Validation loss mlp/pin: 0.491086/1.022956\n",
      "###### N,i = 5,1 #####\n",
      "M: 123.87454\n",
      "det: 7.191612e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 904/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576813/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479008/0.981169\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178314\n",
      "det: 0.0722845\n",
      "Validation loss mlp/pin: 0.612193/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.397758\n",
      "det: 0.022018487\n",
      "Validation loss mlp/pin: 0.491085/1.022955\n",
      "###### N,i = 5,1 #####\n",
      "M: 155.19392\n",
      "det: 7.1911345e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 905/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576812/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479007/0.981169\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783147\n",
      "det: 0.07228453\n",
      "Validation loss mlp/pin: 0.612192/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 8.397759\n",
      "det: 0.022018483\n",
      "Validation loss mlp/pin: 0.491085/1.022955\n",
      "###### N,i = 5,1 #####\n",
      "M: 148.19363\n",
      "det: 7.1915165e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 906/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576812/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479007/0.981168\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178315\n",
      "det: 0.072284564\n",
      "Validation loss mlp/pin: 0.612191/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.295289\n",
      "det: 0.022018477\n",
      "Validation loss mlp/pin: 0.491084/1.022955\n",
      "###### N,i = 5,1 #####\n",
      "M: 65.805504\n",
      "det: 7.1927745e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 907/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576811/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479006/0.981168\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783156\n",
      "det: 0.0722846\n",
      "Validation loss mlp/pin: 0.612191/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.295289\n",
      "det: 0.02201847\n",
      "Validation loss mlp/pin: 0.491084/1.022955\n",
      "###### N,i = 5,1 #####\n",
      "M: 137.59645\n",
      "det: 7.192023e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 908/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576810/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479006/0.981168\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178316\n",
      "det: 0.072284624\n",
      "Validation loss mlp/pin: 0.612190/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.295294\n",
      "det: 0.02201846\n",
      "Validation loss mlp/pin: 0.491083/1.022954\n",
      "###### N,i = 5,1 #####\n",
      "M: 100.76734\n",
      "det: 7.191189e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 909/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576809/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479005/0.981168\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783166\n",
      "det: 0.072284676\n",
      "Validation loss mlp/pin: 0.612189/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.295293\n",
      "det: 0.022018448\n",
      "Validation loss mlp/pin: 0.491083/1.022954\n",
      "###### N,i = 5,1 #####\n",
      "M: 162.41139\n",
      "det: 7.191677e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 910/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576808/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479005/0.981167\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783175\n",
      "det: 0.0722847\n",
      "Validation loss mlp/pin: 0.612188/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.077503\n",
      "det: 0.022018414\n",
      "Validation loss mlp/pin: 0.491082/1.022954\n",
      "###### N,i = 5,1 #####\n",
      "M: 67.58269\n",
      "det: 7.1926115e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 911/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576808/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479004/0.981167\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178318\n",
      "det: 0.07228473\n",
      "Validation loss mlp/pin: 0.612188/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.077505\n",
      "det: 0.022018421\n",
      "Validation loss mlp/pin: 0.491081/1.022953\n",
      "###### N,i = 5,1 #####\n",
      "M: 120.23093\n",
      "det: 7.192069e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 912/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576807/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479003/0.981167\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178318\n",
      "det: 0.072284766\n",
      "Validation loss mlp/pin: 0.612187/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.07751\n",
      "det: 0.022018416\n",
      "Validation loss mlp/pin: 0.491081/1.022953\n",
      "###### N,i = 5,1 #####\n",
      "M: 89.944374\n",
      "det: 7.192796e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 913/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576806/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479003/0.981167\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178319\n",
      "det: 0.07228478\n",
      "Validation loss mlp/pin: 0.612186/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.07752\n",
      "det: 0.022018377\n",
      "Validation loss mlp/pin: 0.491080/1.022953\n",
      "###### N,i = 5,1 #####\n",
      "M: 53.164627\n",
      "det: 7.192453e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 914/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576806/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479002/0.981166\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783195\n",
      "det: 0.072284825\n",
      "Validation loss mlp/pin: 0.612185/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.349936\n",
      "det: 0.022018373\n",
      "Validation loss mlp/pin: 0.491080/1.022953\n",
      "###### N,i = 5,1 #####\n",
      "M: 148.3214\n",
      "det: 7.1931594e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 915/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576805/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479002/0.981166\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.17832\n",
      "det: 0.07228485\n",
      "Validation loss mlp/pin: 0.612185/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.077532\n",
      "det: 0.022018384\n",
      "Validation loss mlp/pin: 0.491079/1.022952\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.197945\n",
      "det: 7.192064e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 916/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576804/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479001/0.981166\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783204\n",
      "det: 0.07228489\n",
      "Validation loss mlp/pin: 0.612184/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.304758\n",
      "det: 0.022018364\n",
      "Validation loss mlp/pin: 0.491079/1.022952\n",
      "###### N,i = 5,1 #####\n",
      "M: 111.999985\n",
      "det: 7.192754e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 917/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576804/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479001/0.981166\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178321\n",
      "det: 0.07228491\n",
      "Validation loss mlp/pin: 0.612184/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.304762\n",
      "det: 0.022018362\n",
      "Validation loss mlp/pin: 0.491078/1.022952\n",
      "###### N,i = 5,1 #####\n",
      "M: 138.58414\n",
      "det: 7.190897e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 918/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576803/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479000/0.981165\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178322\n",
      "det: 0.072284944\n",
      "Validation loss mlp/pin: 0.612183/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 16.077553\n",
      "det: 0.022018347\n",
      "Validation loss mlp/pin: 0.491078/1.022951\n",
      "###### N,i = 5,1 #####\n",
      "M: 56.699924\n",
      "det: 7.193204e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 919/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576803/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479000/0.981165\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783223\n",
      "det: 0.07228498\n",
      "Validation loss mlp/pin: 0.612183/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.3047695\n",
      "det: 0.022018334\n",
      "Validation loss mlp/pin: 0.491077/1.022951\n",
      "###### N,i = 5,1 #####\n",
      "M: 188.2377\n",
      "det: 7.1933384e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 920/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576802/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.479000/0.981165\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178323\n",
      "det: 0.07228501\n",
      "Validation loss mlp/pin: 0.612182/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.34997\n",
      "det: 0.022018328\n",
      "Validation loss mlp/pin: 0.491077/1.022951\n",
      "###### N,i = 5,1 #####\n",
      "M: 126.57873\n",
      "det: 7.1930284e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 921/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576802/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.478999/0.981165\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492467/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783237\n",
      "det: 0.07228505\n",
      "Validation loss mlp/pin: 0.612182/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 17.349974\n",
      "det: 0.022018317\n",
      "Validation loss mlp/pin: 0.491076/1.022951\n",
      "###### N,i = 5,1 #####\n",
      "M: 112.36774\n",
      "det: 7.193353e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 922/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576802/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.478999/0.981164\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492467/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783237\n",
      "det: 0.072285056\n",
      "Validation loss mlp/pin: 0.612182/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.726929\n",
      "det: 0.022018295\n",
      "Validation loss mlp/pin: 0.491076/1.022951\n",
      "###### N,i = 5,1 #####\n",
      "M: 126.57968\n",
      "det: 7.1929404e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 923/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576801/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.478998/0.981164\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492468/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783247\n",
      "det: 0.07228508\n",
      "Validation loss mlp/pin: 0.612181/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.726934\n",
      "det: 0.022018282\n",
      "Validation loss mlp/pin: 0.491075/1.022951\n",
      "###### N,i = 5,1 #####\n",
      "M: 103.19615\n",
      "det: 7.192388e-05\n",
      "Validation loss mlp/pin: 1.463978/1.501628\n",
      "\n",
      "Epoch 924/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576801/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.478998/0.981164\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492467/1.534728\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178325\n",
      "det: 0.07228513\n",
      "Validation loss mlp/pin: 0.612181/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.886961\n",
      "det: 0.02201828\n",
      "Validation loss mlp/pin: 0.491075/1.022951\n",
      "###### N,i = 5,1 #####\n",
      "M: 158.17694\n",
      "det: 7.193325e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 925/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576801/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.478997/0.981164\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492467/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783257\n",
      "det: 0.07228514\n",
      "Validation loss mlp/pin: 0.612180/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 10.886967\n",
      "det: 0.022018258\n",
      "Validation loss mlp/pin: 0.491075/1.022950\n",
      "###### N,i = 5,1 #####\n",
      "M: 185.26602\n",
      "det: 7.1926865e-05\n",
      "Validation loss mlp/pin: 1.463978/1.501628\n",
      "\n",
      "Epoch 926/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576800/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.478997/0.981164\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492467/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178326\n",
      "det: 0.0722852\n",
      "Validation loss mlp/pin: 0.612180/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.436096\n",
      "det: 0.022018237\n",
      "Validation loss mlp/pin: 0.491074/1.022950\n",
      "###### N,i = 5,1 #####\n",
      "M: 70.69206\n",
      "det: 7.192876e-05\n",
      "Validation loss mlp/pin: 1.463979/1.501628\n",
      "\n",
      "Epoch 927/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576800/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.478997/0.981164\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492467/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178327\n",
      "det: 0.07228521\n",
      "Validation loss mlp/pin: 0.612180/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 13.436099\n",
      "det: 0.022018243\n",
      "Validation loss mlp/pin: 0.491074/1.022950\n",
      "###### N,i = 5,1 #####\n",
      "M: 93.328575\n",
      "det: 7.192805e-05\n",
      "Validation loss mlp/pin: 1.463978/1.501628\n",
      "\n",
      "Epoch 928/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576800/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.478996/0.981164\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492467/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178327\n",
      "det: 0.07228523\n",
      "Validation loss mlp/pin: 0.612180/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 9.897235\n",
      "det: 0.022018246\n",
      "Validation loss mlp/pin: 0.491073/1.022950\n",
      "###### N,i = 5,1 #####\n",
      "M: 44.1783\n",
      "det: 7.192409e-05\n",
      "Validation loss mlp/pin: 1.463978/1.501628\n",
      "\n",
      "Epoch 929/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576800/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.478996/0.981164\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492467/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783276\n",
      "det: 0.07228527\n",
      "Validation loss mlp/pin: 0.612179/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 12.918558\n",
      "det: 0.022018224\n",
      "Validation loss mlp/pin: 0.491073/1.022950\n",
      "###### N,i = 5,1 #####\n",
      "M: 86.13776\n",
      "det: 7.1920185e-05\n",
      "Validation loss mlp/pin: 1.463978/1.501628\n",
      "\n",
      "Epoch 930/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576799/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.478995/0.981164\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492467/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.1783285\n",
      "det: 0.07228531\n",
      "Validation loss mlp/pin: 0.612179/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 4.122592\n",
      "det: 0.022018231\n",
      "Validation loss mlp/pin: 0.491072/1.022950\n",
      "###### N,i = 5,1 #####\n",
      "M: 63.777554\n",
      "det: 7.192521e-05\n",
      "Validation loss mlp/pin: 1.463978/1.501628\n",
      "\n",
      "Epoch 931/1000\n",
      "###### N,i = 3,1 #####\n",
      "Training loss mlp/pin: 0.576799/2.588986\n",
      "###### N,i = 4,1 #####\n",
      "Training loss mlp/pin: 0.478995/0.981164\n",
      "###### N,i = 5,1 #####\n",
      "Training loss mlp/pin: 1.492467/1.534727\n",
      "###### N,i = 3,1 #####\n",
      "M: 4.178329\n",
      "det: 0.07228534\n",
      "Validation loss mlp/pin: 0.612179/2.617974\n",
      "###### N,i = 4,1 #####\n",
      "M: 11.660919\n",
      "det: 0.022018207\n",
      "Validation loss mlp/pin: 0.491072/1.022950\n",
      "###### N,i = 5,1 #####\n",
      "M: 200.55455\n",
      "det: 7.192917e-05\n",
      "Validation loss mlp/pin: 1.463978/1.501628\n",
      "No more learning! Stopping...\n"
     ]
    }
   ],
   "source": [
    "# Train the model for 100 epochs \n",
    "T = 1000\n",
    "tstart = 1\n",
    "V = 1\n",
    "ES = 10\n",
    "for N in Nkeys:\n",
    "    for i in modelkeys:\n",
    "        mlp[N][i].train()\n",
    "        pin[N][i].train()\n",
    "for t in range(tstart,T+tstart):\n",
    "    if t%V==0: print(f\"\\nEpoch {t:>03d}/{T+tstart-1:^3d}\")\n",
    "    for N in Nkeys:\n",
    "        for i in modelkeys:\n",
    "            loss_mlp = 0\n",
    "            loss_pin = 0\n",
    "            for n,(x,y) in enumerate(trainloader_dict[N]):\n",
    "                loss_mlp += train(mlp[N][i],optimizer_mlp[N][i],x,y)\n",
    "                loss_pin += train(pin[N][i],optimizer_pin[N][i],x,y)\n",
    "            #loss_mlp = train(mlp[N][i],optimizer_mlp[N][i],xtrain_dict[N],ytrain_dict[N])\n",
    "            #loss_pin = train(pin[N][i],optimizer_pin[N][i],xtrain_dict[N],ytrain_dict[N])\n",
    "            losses_train_mlp[N][i].append(loss_mlp/(float(M)/float(BS)))\n",
    "            losses_train_pin[N][i].append(loss_pin/(float(M)/float(BS)))\n",
    "            if t%V==0:\n",
    "                print('###### N,i = '+str(N)+','+i+' #####')\n",
    "                print(f\"Training loss mlp/pin: {loss_mlp/(float(M)/float(BS)):^.6f}/{loss_pin/(float(M)/float(BS)):^.6f}\") #,end=\"\\r\" \n",
    "                \n",
    "    if t%V == 0:\n",
    "        for N in Nkeys:\n",
    "            for i in modelkeys:\n",
    "                print('###### N,i = '+str(N)+','+i+' #####')\n",
    "                mlp[N][i].eval()\n",
    "                pin[N][i].eval()\n",
    "                if i=='1':\n",
    "                    mis,detmlp,detpin = Mmod(mlp[N][i],pin[N][i])\n",
    "                    M_dict[N].append(mis.detach().numpy())\n",
    "                    det_dict[N].append(detmlp.detach().numpy())\n",
    "                    print('M:',M_dict[N][-1])\n",
    "                    print('det:',det_dict[N][-1])\n",
    "                with torch.no_grad():\n",
    "                    yhat = mlp[N][i](xval_dict[N])\n",
    "                    loss_mlp = criterion(yhat,yval_dict[N].view(-1,1)).item()\n",
    "                    yhat = pin[N][i](xval_dict[N])\n",
    "                    loss_pin = criterion(yhat,yval_dict[N].view(-1,1)).item()\n",
    "                    losses_val_mlp[N][i].append(loss_mlp)\n",
    "                    losses_val_pin[N][i].append(loss_pin)\n",
    "                    lrdecay_mlp[N][i].step()\n",
    "                    lrdecay_pin[N][i].step()\n",
    "                    print(f\"Validation loss mlp/pin: {loss_mlp:^.6f}/{loss_pin:^.6f}\") #,end=\"\\r\"\n",
    "    if (t/V)>(ES+1):\n",
    "        tobreak = True\n",
    "        for N in Nkeys:\n",
    "            for i in modelkeys:\n",
    "                if not earlyStop(losses_val_mlp[N][i],ES) or not earlyStop(losses_val_pin[N][i],ES): tobreak = False\n",
    "        if(tobreak): \n",
    "            print('No more learning! Stopping...')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N in Nkeys:\n",
    "    for i in modelkeys:\n",
    "        \n",
    "        fig, ax1 = plt.subplots()\n",
    "        plt.title('N = '+str(N))\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.semilogy()\n",
    "        ax1.plot(np.arange(0,t),losses_train_mlp[N][i],label=\"Train MLP\",color='blue')\n",
    "        ax1.plot(np.arange(0,t,V),losses_val_mlp[N][i],label=\"Validation MLP\",color='blue',linestyle='--')\n",
    "        ax1.plot(np.arange(0,t),losses_train_pin[N][i],label=\"Train PIN\",color='red')\n",
    "        ax1.plot(np.arange(0,t,V),losses_val_pin[N][i],label=\"Validation PIN\",color='red',linestyle='--')\n",
    "        ax1.tick_params(axis='y')\n",
    "\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.semilogy()\n",
    "        \n",
    "        ax2.set_ylabel('Det[W W^T]',color='green')  # we already handled the x-label with ax1\n",
    "        ax2.plot(np.arange(0,t,V),M_dict[N],color='green')\n",
    "        ax2.tick_params(axis='y')\n",
    "        plt.legend()\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T03:08:13.717910Z",
     "start_time": "2020-11-25T03:08:12.344530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nwkamp/.local/lib/python3.6/site-packages/torch/tensor.py:447: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEGCAYAAACJnEVTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAYEElEQVR4nO3dfZRV1Z3m8e8jgkRFUUAlFE6RxFE0KGK1pMdESIgdZLLEmaGjNulAYIWZ+JZpNQ3RP2S601k6mbzI0uiwogNMFNqh20h86TRtqGb1GGwL4xDwpa22UYtBLYmhm0Eilfzmj7tLbvAWVbfuW1Xt57MWq87ZZ597f/csfWrXuefso4jAzMzycFSjCzAzs/px6JuZZcShb2aWEYe+mVlGHPpmZhk5utEFHMnYsWOjubm50WWYmQ0qW7dufSsixpXaNqBDv7m5mba2tkaXYWY2qEh6padtPr1jZpYRh76ZWUYc+mZmGRnQ5/TNzCp18OBBOjo6OHDgQKNLqbqRI0fS1NTE8OHD+7yPQ9/MhrSOjg5GjRpFc3MzkhpdTtVEBHv27KGjo4NJkyb1eT+f3jGzIe3AgQOMGTNmSAU+gCTGjBlT9l8wDn0zG/KGWuB368/ncuibmWXEoW9m1ovjjz/+iNt37tzJRz/60bJec+HChaxfv76SsvrFX+Sa9dPy5bXpa1ZLHumbmfXRvn37mDVrFtOmTWPKlCk8/PDD723r6upi/vz5TJ48mXnz5rF//34Atm7dyowZM7jgggv4zGc+w+7duxtVPuDQNzPrs5EjR/LQQw/xzDPPsGnTJm688Ua6Hzn74osvcvXVV/P8889zwgkn8L3vfY+DBw9y3XXXsX79erZu3cqiRYu45ZZbGvoZfHrHrIhPw9iRRAQ333wzmzdv5qijjmLXrl288cYbAEycOJGLLroIgM9//vOsWLGC2bNns337di655BIAfv3rXzN+/PiG1Q8OfTOzPrv//vvp7Oxk69atDB8+nObm5veukz/88klJRATnnHMOP/3pTxtRbkk+vWNm1kd79+7llFNOYfjw4WzatIlXXjk0g/Grr776Xrg/8MADfPzjH+fMM8+ks7PzvfaDBw+yY8eOhtTerdfQl3SfpDclbS9q+6akFyRtk/SQpNFF274mqV3Si5I+U9Q+O7W1S1pW/Y9iZlZb8+fPp62tjSlTprBmzRrOOuus97adeeaZ3HXXXUyePJm3336bL3/5y4wYMYL169ezdOlSzjvvPKZOncqTTz7ZwE/Qt9M7q4A7gTVFbRuBr0VEl6Tbga8BSyWdDVwJnAN8EPgbSf867XMXcAnQATwtaUNEPFedj2FmVjv79u0DYOzYsT2eqnnhhRdKtk+dOpXNmze/r33VqlVVq68cvY70I2Iz8IvD2v46IrrS6hagKS3PBdZFxK8i4p+AduDC9K89Il6OiHeBdamvmZnVUTXO6S8CHk/LE4DXirZ1pLae2t9H0hJJbZLaOjs7q1CemZl1qyj0Jd0CdAH3V6cciIiVEdESES3jxpV8rq+ZmfVTvy/ZlLQQ+CwwK7rvToBdwMSibk2pjSO0m5lZnfRrpC9pNvDHwGURsb9o0wbgSknHSJoEnAH8PfA0cIakSZJGUPiyd0NlpZuZWbl6HelLWgvMBMZK6gBupXC1zjHAxnRDwpaI+E8RsUPSg8BzFE77XBMRv06vcy3wY2AYcF9ENPZiVTOzDPUa+hFxVYnme4/Q/8+APyvR/hjwWFnVmZlVW7Xn2ujD60li/vz5/OAHPwAKk7ONHz+e6dOn88gjj7Bq1Sra2tq48847f2u/5uZmRo0ahSROO+001qxZw2mnnVZRub4j18ysxo477ji2b9/OO++8A8DGjRuZMKHkBYzvs2nTJrZt20ZLSwvf+MY3Kq7FoW9mVgdz5szh0UcfBWDt2rVcdVWpkyg9u/jii2lvb6+4Doe+mVkdXHnllaxbt44DBw6wbds2pk+fXtb+jzzyCFOmTKm4Ds+yaWZWB+eeey47d+5k7dq1zJkzp8/7ffKTn2TYsGGce+65fP3rX6+4Doe+mVmdXHbZZdx00020trayZ8+ePu2zadMmxo4dW7UaHPpmZnWyaNEiRo8ezZQpU2htbW1IDQ59M8tLAx+P1tTUxPXXX19y26pVq/jhD3/43vqWLVtqUoND38ysxrqnZi42c+ZMZs6cCcDChQtZuHDh+/rs3Lmz6rX46h0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuJLNs0sKw2YWZlhw4YxZcoUurq6mDx5MqtXr+bYY4/l+OOPZ9++fezcuZNJkyaxYsUKrrvuOgCuvfZaWlpaSl7KWQmP9M3MauwDH/gAzz77LNu3b2fEiBHcc8897+tzyimncMcdd/Duu+/WtBaP9G3wKXeo1sA7MM0O94lPfIJt27a9r33cuHFcdNFFrF69mi996Us1e3+Hvg15znwbKLq6unj88ceZPXt2ye1Lly7l0ksvZdGiRTWrwaFvZlZj77zzDlOnTgUKI/3FixeX7PehD32I6dOn88ADD9SsFoe+mVmNdZ/T74ubb76ZefPmMWPGjJrU4i9yzcwGkLPOOouzzz6bH/3oRzV5fY/0zSwrg+E7nltuuYXzzz+/Jq/t0Lehr5yHVaSpbs2qqdTUysXtzc3NbN++/b328847j9/85jc1qcWnd8zMMtJr6Eu6T9KbkrYXtZ0saaOkl9LPk1K7JK2Q1C5pm6RpRfssSP1fkrSgNh/HzMyOpC8j/VXA4ReVLgOeiIgzgCfSOsClwBnp3xLgbij8kgBuBaYDFwK3dv+iMDOrtYhodAk10Z/P1es5/YjYLKn5sOa5wMy0vBpoBZam9jVRqGSLpNGSxqe+GyPiFwCSNlL4RbK27IrNBqFyvjwcDF80DiYjR45kz549jBkzBkmNLqdqIoI9e/YwcuTIsvbr7xe5p0bE7rT8OnBqWp4AvFbUryO19dT+PpKWUPgrgdNPP72f5ZmZFTQ1NdHR0UFnZ2ejS6m6kSNH0tTUVNY+FV+9ExEhqWp/O0XESmAlQEtLy9D8m8zM6mb48OFMmjSp0WUMGP29eueNdNqG9PPN1L4LmFjUrym19dRuZmZ11N/Q3wB0X4GzAHi4qP0L6SqejwF702mgHwO/J+mk9AXu76U2MzOro15P70haS+GL2LGSOihchXMb8KCkxcArwOdS98eAOUA7sB/4IkBE/ELSnwJPp35/0v2lrhngby/N6qQvV+9c1cOmWSX6BnBND69zH3BfWdWZmVlV+Y5cM7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLih6iYFfMDV2yI80jfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjFYW+pD+StEPSdklrJY2UNEnSU5LaJf25pBGp7zFpvT1tb67GBzAzs77r9+MSJU0ArgfOjoh3JD0IXAnMAb4TEesk3QMsBu5OP9+OiI9IuhK4Hbii4k9gNsQsX16bvmZQ+TNyjwY+IOkgcCywG/gU8Adp+2pgOYXQn5uWAdYDd0pSRESFNZg1hp+na4NQv0/vRMQu4L8Br1II+73AVuCXEdGVunUAE9LyBOC1tG9X6j/m8NeVtERSm6S2zs7O/pZnZmYl9Dv0JZ1EYfQ+CfggcBwwu9KCImJlRLRERMu4ceMqfTkzMytSyRe5nwb+KSI6I+Ig8JfARcBoSd2njZqAXWl5FzARIG0/EdhTwfubmVmZKgn9V4GPSTpWkoBZwHPAJmBe6rMAeDgtb0jrpO0/8fl8M7P6quSc/lMUvpB9Bvh5eq2VwFLgBkntFM7Z35t2uRcYk9pvAJZVULeZmfVDRVfvRMStwK2HNb8MXFii7wHg9yt5PzMzq4zvyDUzy0il1+mb1d3y1pmNLsFs0HLoW+34dlGzAcend8zMMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiB+XaFYPra197ztzZq2qMPNI38wsJx7pmw1i5Tx73s+pN6hwpC9ptKT1kl6Q9Lyk35V0sqSNkl5KP09KfSVphaR2SdskTavORzAzs76q9PTOHcBfRcRZwHnA88Ay4ImIOAN4Iq0DXAqckf4tAe6u8L3NzKxM/Q59SScCFwP3AkTEuxHxS2AusDp1Ww1cnpbnAmuiYAswWtL4flduZmZlq2SkPwnoBP6HpJ9J+r6k44BTI2J36vM6cGpangC8VrR/R2r7LZKWSGqT1NbZ2VlBeWZmdrhKQv9oYBpwd0ScD/w/Dp3KASAiAohyXjQiVkZES0S0jBs3roLyzMzscJWEfgfQERFPpfX1FH4JvNF92ib9fDNt3wVMLNq/KbWZmVmd9PuSzYh4XdJrks6MiBeBWcBz6d8C4Lb08+G0ywbgWknrgOnA3qLTQJa55a0zG12CWRYqvU7/OuB+SSOAl4EvUvjr4UFJi4FXgM+lvo8Bc4B2YH/qa2ZmdVRR6EfEs0BLiU2zSvQN4JpK3s/MzCrjaRjMzDLi0Dczy4hD38wsI55wzWyg8TTMVkMe6ZuZZcShb2aWEYe+mVlGHPpmZhnxF7lWHj9+yWxQ80jfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4z4kk2rGT8Ny2zg8UjfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLSMU3Z0kaBrQBuyLis5ImAeuAMcBW4A8j4l1JxwBrgAuAPcAVEbGz0vc3y1o5D1FnZo2KsMGkGiP9rwDPF63fDnwnIj4CvA0sTu2LgbdT+3dSPzMzq6OKQl9SE/Bvge+ndQGfAtanLquBy9Py3LRO2j4r9Tczszqp9PTOd4E/Bkal9THALyOiK613ABPS8gTgNYCI6JK0N/V/q/gFJS0BlgCcfvrpFZZnZt3KfdKln4w5NPV7pC/ps8CbEbG1ivUQESsjoiUiWsaNG1fNlzYzy14lI/2LgMskzQFGAicAdwCjJR2dRvtNwK7UfxcwEeiQdDRwIoUvdM3MrE76PdKPiK9FRFNENANXAj+JiPnAJmBe6rYAeDgtb0jrpO0/iYjo7/ubmVn5anGd/lLgBkntFM7Z35va7wXGpPYbgGU1eG8zMzuCqjxEJSJagda0/DJwYYk+B4Dfr8b7WeP4wShmg5vvyDUzy4gfl2iWi7Lu3gXfwTs0eaRvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYR35FrZT4tY2aNirABp5z/LvzElUHDI30zs4x4pG9mJZUzo+rymlVh1eaRvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRnz1jvm5t2YZ8UjfzCwjDn0zs4w49M3MMuLQNzPLSL9DX9JESZskPSdph6SvpPaTJW2U9FL6eVJql6QVktolbZM0rVofwszM+qaSq3e6gBsj4hlJo4CtkjYCC4EnIuI2ScuAZcBS4FLgjPRvOnB3+mlmg51n5Bw0+h36EbEb2J2W/0XS88AEYC6H5t9dDbRSCP25wJqICGCLpNGSxqfXMbNBzJOzDR5VOacvqRk4H3gKOLUoyF8HTk3LE4DXinbrSG2Hv9YSSW2S2jo7O6tRnpmZJRXfnCXpeOAvgP8cEf8s6b1tERGSopzXi4iVwEqAlpaWsva1Q/wXtA1YPhXUUBWN9CUNpxD490fEX6bmNySNT9vHA2+m9l3AxKLdm1KbmZnVSSVX7wi4F3g+Ir5dtGkDsCAtLwAeLmr/QrqK52PAXp/PNzOrr0pO71wE/CHwc0nPprabgduAByUtBl4BPpe2PQbMAdqB/cAXK3hvMzPrh0qu3vk7QD1snlWifwDX9Pf9zMyscr4j18wsIw59M7OMOPTNzDLi0Dczy4hD38wsI35copkNXL57t+o80jczy4hD38wsIz69Y2Z1VdY0zDNby3jh5bXpO8R4pG9mlhGP9Ieq1tZGV2BWsZr9VZAxj/TNzDLikb6Z5afcc/pD6DsAj/TNzDLi0Dczy4hP75iZ9WYIXQ7qkb6ZWUY80jczq6YB/leBQ9/MbDCo0i8Ih76ZDQm+katvHPpmlp1yfkFADX9J+PSO9WSAXxBgZoOEQ9/MrBdD6dSRL9k0M8tI3Uf6kmYDdwDDgO9HxG31rmFQ8qyZZoPCQP+roK6hL2kYcBdwCdABPC1pQ0Q8V886zMwGgkb8gqj3SP9CoD0iXgaQtA6YC2QZ+v5y1sz6qrwrjv5Lj1vqHfoTgNeK1juA6cUdJC0BlqTVfZJerFNtRzIWeKvRRQwQPhaH+Fgc4mNxyEA4Fv+qpw0D7uqdiFgJrGx0HcUktUVES6PrGAh8LA7xsTjEx+KQgX4s6n31zi5gYtF6U2ozM7M6qHfoPw2cIWmSpBHAlcCGOtdgZpatup7eiYguSdcCP6ZwyeZ9EbGjnjX004A63dRgPhaH+Fgc4mNxyIA+FoqIRtdgZmZ14jtyzcwy4tA3M8uIQ78ESSdL2ijppfTzpCP0PUFSh6Q761ljvfTlWEiaKumnknZI2ibpikbUWiuSZkt6UVK7pGUlth8j6c/T9qckNde/ytrrw3G4QdJz6b+BJyT1eK34UNDb8Sjq9x8khaQBcRmnQ7+0ZcATEXEG8ERa78mfApvrUlVj9OVY7Ae+EBHnALOB70oaXccaa6Zo6pBLgbOBqySdfVi3xcDbEfER4DvA7fWtsvb6eBx+BrRExLnAeuC/1rfK+unj8UDSKOArwFP1rbBnDv3S5gKr0/Jq4PJSnSRdAJwK/HWd6mqEXo9FRPxDRLyUlv8v8CYwrm4V1tZ7U4dExLtA99QhxYqP0XpgliTVscZ66PU4RMSmiNifVrdQuA9nqOrLfxdQGBTeDhyoZ3FH4tAv7dSI2J2WX6cQ7L9F0lHAt4Cb6llYA/R6LIpJuhAYAfxjrQurk1JTh0zoqU9EdAF7gTF1qa5++nIcii0GHq9pRY3V6/GQNA2YGBGP1rOw3gy4aRjqRdLfAKeV2HRL8UpEhKRS17VeDTwWER2DfVBXhWPR/Trjgf8JLIiI31S3ShssJH0eaAFmNLqWRkmDwm8DCxtcyvtkG/oR8emetkl6Q9L4iNidguzNEt1+F/iEpKuB44ERkvZFxJHO/w9IVTgWSDoBeBS4JSK21KjURujL1CHdfTokHQ2cCOypT3l106cpVCR9msJgYUZE/KpOtTVCb8djFPBRoDUNCk8DNki6LCLa6lZlCT69U9oGYEFaXgA8fHiHiJgfEadHRDOFUzxrBmPg90GvxyJNqfEQhWOwvo611UNfpg4pPkbzgJ/E0LvrsdfjIOl84L8Dl0VEycHBEHLE4xEReyNibEQ0p4zYQuG4NDTwwaHfk9uASyS9BHw6rSOpRdL3G1pZ/fXlWHwOuBhYKOnZ9G9qY8qtrnSOvnvqkOeBByNih6Q/kXRZ6nYvMEZSO3ADR77aa1Dq43H4JoW/ev9X+m9gyM6r1cfjMSB5GgYzs4x4pG9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvg1JaVbDbxWt3yRpeVpeLmm/pFOKtu+r0vteXmrirTL2H51u+DOrCYe+DVW/Av69pLE9bH8LuLEG73s5hVkX+2s0hSk+zGrCoW9DVReFZ5X+UQ/b7wOukHTykV5E0lWSfi5pu6Tbi9r3FS3Pk7RK0r8BLgO+mW5O+rCkVkl3pPXtaUK67r82bip6je1pHv7bgA+n/t/s30c365lD34ayu4D5kk4ssW0fheD/Sk87S/oghWlxPwVMBX5HUslptgEi4kkKt+J/NSKmRkT3TKPHRsRUCiP4+3qpeRnwj2n/r/bS16xsDn0bsiLin4E1wPU9dFkBLEgPuijld4DWiOhMt93fT2G6iXKtTfVsBk4YKg+YscHJoW9D3XcpzO1+3OEbIuKXwAPANf143eL5S0aW0bd7vYvf/v+vt9cwqwqHvg1pEfEL4EEKwV/Kt4H/SOlpxv8emCFpbHo83lXA36Ztb0ianOZN/3dF+/wLhWl1i10BIOnjwN6I2AvsBKal9mnApCPsb1Y1Dn3LwbeAklfxRMRbFKaFPqbEtt0UzrFvAv4PsDUiuqeWXgY8AjwJ7C7abR3wVUk/k/Th1HZA0s+Aezj0y+cvgJMl7aAwW+M/pPfcA/zv9MWuv8i1qvMsm2Y1JKkVuGkgzKNuBh7pm5llxSN9M7OMeKRvZpYRh76ZWUYc+mZmGXHom5llxKFvZpaR/w+Dy9bJGaMXngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's take a look at how our model performs\n",
    "for N in Nkeys:\n",
    "    for i in modelkeys:\n",
    "        print(N,i)\n",
    "\n",
    "        out_mlp = mlp[N][i](xval_dict[N]).squeeze()\n",
    "        out_pin = pin[N][i](xval_dict[N]).squeeze()\n",
    "\n",
    "        yval = yval_dict[N].resize(len(yval_dict[N]))\n",
    "\n",
    "        frac_error_mlp = torch.div((out_mlp-yval),yval)\n",
    "        frac_error_pin = torch.div((out_pin-yval),yval)\n",
    "\n",
    "        plt.hist(frac_error_mlp.detach().numpy(),bins=30,range=(-0.5,0.5),alpha=0.5,color='red',label=\"MLP\")\n",
    "        plt.hist(frac_error_pin.detach().numpy(),bins=30,range=(-0.5,0.5),alpha=0.5,color='blue',label=\"PIN\")\n",
    "        plt.xlim(-0.5,0.5)\n",
    "        plt.legend(title=\"label\")\n",
    "        #plt.yscale(\"log\")\n",
    "        plt.xlabel(\"NN output\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.hist(out_mlp.detach().numpy(),bins=30,range=(0,10),alpha=0.5,color='red',label=\"MLP\")\n",
    "        plt.hist(out_pin.detach().numpy(),bins=30,range=(0,10),alpha=0.5,color='blue',label=\"PIN\")\n",
    "        plt.hist(yval,bins=30,range=(0,10),alpha=0.5,color='green',label=\"Truth\")\n",
    "        plt.xlim(0,10)\n",
    "        plt.legend(title=\"label\")\n",
    "        #plt.yscale(\"log\")\n",
    "        plt.xlabel(\"y\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T03:08:13.722920Z",
     "start_time": "2020-11-25T03:08:13.719574Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4235, -0.2009, -0.3073],\n",
      "        [ 1.0615,  0.8942,  0.9755],\n",
      "        [-0.2403, -0.5735, -0.3854]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.4008,  0.0898, -0.5642],\n",
      "        [-0.4435,  0.6373,  0.0867],\n",
      "        [-0.2191,  0.0064, -0.5555],\n",
      "        [ 0.5653,  1.6549, -0.6441],\n",
      "        [-0.0465, -0.4075, -0.1029],\n",
      "        [-0.1824, -0.4255, -0.1551],\n",
      "        [ 0.3513,  0.0244, -0.4185],\n",
      "        [ 0.4928,  0.0887, -0.4676],\n",
      "        [ 0.1538,  0.7978, -0.9007],\n",
      "        [-0.0957, -0.4913,  0.4784]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0411, -0.3104,  0.0016, -0.3091],\n",
      "        [ 0.3797,  0.6169,  0.7694,  0.9682],\n",
      "        [ 1.0032,  0.7526,  0.5648,  0.3400],\n",
      "        [ 0.2565, -0.4616, -0.4119, -0.0318]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0805, -0.2171, -0.0384,  0.1146],\n",
      "        [ 0.1432,  0.4669,  0.4274, -0.3439],\n",
      "        [-0.3243,  1.5178,  1.1092, -0.1559],\n",
      "        [ 0.2888,  0.1196, -0.1364,  0.1287],\n",
      "        [-0.3464, -0.1862, -0.0145,  0.4206],\n",
      "        [-0.3058, -0.2077, -0.2683,  0.3004],\n",
      "        [ 0.4179, -0.3412, -0.3851, -0.2846],\n",
      "        [-0.4689, -0.4082,  0.1923,  0.4167],\n",
      "        [ 0.4716,  0.4263,  0.4302,  0.2551],\n",
      "        [-0.2325,  0.7601,  0.7510,  0.1167]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.5959, -0.3930, -0.3597, -0.3400, -0.3615],\n",
      "        [-0.2336, -0.0025, -0.1875,  0.4998, -0.1048],\n",
      "        [ 0.9406,  0.8632,  0.8416,  0.8506,  0.8979],\n",
      "        [-0.1553,  0.0818, -0.0470, -0.4904,  0.2835],\n",
      "        [ 0.0557, -0.2426, -0.2209, -0.1818, -0.4451]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0445, -0.2144,  0.1215,  0.1173, -0.2023],\n",
      "        [ 0.1115, -0.0350, -0.1079,  0.1985,  0.2925],\n",
      "        [-0.2437, -0.4248,  1.5110, -0.2197,  0.1917],\n",
      "        [ 0.2206,  0.0848, -0.2834, -0.1625, -0.1668],\n",
      "        [-0.4439,  0.0924, -0.3465, -0.2788,  0.2303],\n",
      "        [ 0.0502, -0.3785, -0.2324,  0.4279, -0.0382],\n",
      "        [-0.8201, -0.2782,  1.9876, -0.3688,  0.0939],\n",
      "        [ 0.2827, -0.3774,  0.6907, -0.0506,  0.1996],\n",
      "        [-0.3902,  0.1849,  0.3889, -0.3333,  0.4409],\n",
      "        [ 0.1015,  0.2974,  0.5415, -0.4561, -0.1136]], requires_grad=True)\n",
      "N: 3\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "N: 4\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "N: 5\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "# Now we will print the weights of the hidden layer\n",
    "for N in Nkeys:\n",
    "    for key in modelkeys:\n",
    "        modules = list(mlp[N][key].modules())\n",
    "        print(modules[0].mlp[0].weight)\n",
    "        print(modules[0].mlp[2].weight)\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "rm_mlp = {N:{key:[] for key in modelkeys} for N in Nkeys}\n",
    "rm_pin = {N:{key:[] for key in modelkeys} for N in Nkeys}\n",
    "\n",
    "for N in Nkeys:\n",
    "    print('N:',N)\n",
    "    for i in range(1000):\n",
    "        if(i%100==0): print(i)\n",
    "        test = np.random.random(N)\n",
    "        test_permuted = test[torch.randperm(N)]\n",
    "        tests = torch.from_numpy(np.array([test,test_permuted]))\n",
    "\n",
    "        #test_permuted = np.array([np.array(p) for p in list(permutations(test))[1:3]])\n",
    "        y = f(np.array([test,test_permuted]))\n",
    "        for key in modelkeys:\n",
    "            yhat_mlp = np.array([mlp[N][key](t.float()).detach().numpy() for t in tests])\n",
    "            rm_mlp[N][key].append((np.max(yhat_mlp) - np.min(yhat_mlp))/y[0])\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for N in Nkeys:\n",
    "    for key in modelkeys:\n",
    "        plt.hist(rm_mlp[N][key],bins=20,range=(0,0.1),alpha=1.0,label=str(N)+' '+key,histtype='step')\n",
    "plt.legend()\n",
    "#plt.semilogy()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
